{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "S2kue_J3ls55",
        "pDJllF_IIzKf",
        "P4PpCJX5855K",
        "t0_CY1LSEsfI",
        "rQT8TtiuFS9j",
        "OyME1mZ5FUrl",
        "yDAPVn0mFWWU",
        "n9oj1SUTFYWm",
        "Mye0KNDdFZm4",
        "7RHcSo4-Fa_a",
        "kAWPmqdjFcjw"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This module is resposible for \n",
        "\n",
        "*   Finding the most similar documents to topics using ALBERT\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bsUFwbEJEOhd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuu6z-ZZoZHq"
      },
      "source": [
        "## Configurations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbkcv3irn-mi"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf6N4pe_oSu6"
      },
      "source": [
        "import logging\n",
        "#logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tBIYWabuTES",
        "outputId": "03bd4d88-86c8-49d6-92ef-dd2a7ed67efe"
      },
      "source": [
        "pip install sentence-transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.1.0.tar.gz (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 3.6 MB/s \n",
            "\u001b[?25hCollecting transformers<5.0.0,>=4.6.0\n",
            "  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 11.5 MB/s \n",
            "\u001b[?25hCollecting tokenizers>=0.10.3\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 34.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.62.3)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.9.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.10.0+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 34.4 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 39.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 40.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (4.8.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.1.0-py3-none-any.whl size=121000 sha256=e6ab236a86720ee5d064573c65361d66e78f19385a9ee0fba766ae2f376a0ac4\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/f0/bb/ed1add84da70092ea526466eadc2bfb197c4bcb8d4fa5f7bad\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers, sentencepiece, sentence-transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.19 pyyaml-6.0 sacremoses-0.0.46 sentence-transformers-2.1.0 sentencepiece-0.1.96 tokenizers-0.10.3 transformers-4.11.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOZnc3w7CA9Y"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gensim\n",
        "from sklearn.model_selection import train_test_split\n",
        "import multiprocessing\n",
        "from collections import OrderedDict\n",
        "\n",
        "import gensim.models.doc2vec\n",
        "assert gensim.models.doc2vec.FAST_VERSION > -1, \"This will be painfully slow otherwise\"\n",
        "\n",
        "from gensim.models.doc2vec import Doc2Vec\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import collections\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxGpI5Zq6IQl",
        "outputId": "91ff4f2b-8a1f-43ad-d3e7-a431cc42b2df"
      },
      "source": [
        "pip install testfixtures"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting testfixtures\n",
            "  Downloading testfixtures-6.18.3-py2.py3-none-any.whl (95 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▍                            | 10 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 20 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 30 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 40 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 51 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 61 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 81 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 92 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 95 kB 2.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: testfixtures\n",
            "Successfully installed testfixtures-6.18.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0FG4Qzc_bYD"
      },
      "source": [
        "#'/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Processed-Merged-Dataset-99-08-28.csv'\n",
        "\n",
        "inputFileName = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Balenced-Dataset-00-06-26.csv'\n",
        "\n",
        "\n",
        "outputLabelledTTDS= '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Balenced-Dataset-00-06-26.csv'\n",
        "outputDocsFileName = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/DocsReadyForD2V-00-06-26.csv'\n",
        "\n",
        "d2vModelFNmPos = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModelPositive-00-06-26.model'\n",
        "d2vModelFNtPos = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModelPositive-00-06-26.txt' \n",
        "\n",
        "d2vModelFNmNeg = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModelNegative-00-06-26.model'\n",
        "d2vModelFNtNeg = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModelNegative-00-06-26.txt' \n",
        "\n",
        "csvTopic8 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Topics_8.csv'\n",
        "csvTopic20 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Topics_20.csv'\n",
        "csvTopic40 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Topics_40.csv'\n",
        "csvTopic80 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Topics_80.csv'\n",
        "csvTopic50 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Topics_50.csv'\n",
        "csvTopic60 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Topics_60.csv'\n",
        "csvTopic65 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Topics_65.csv'\n",
        "csvTopic70 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Topics_70.csv'\n",
        "\n",
        "\n",
        "d2vModelFNm0 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModel0-00-06-23.model'\n",
        "d2vModelFNt0 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModel0-00-06-23.txt' \n",
        "\n",
        "d2vModelFNm1 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModel1-00-06-23.model'\n",
        "d2vModelFNt1 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModel1-00-06-23.txt' \n",
        "\n",
        "d2vModelFNm2 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModel2-00-06-23.model'\n",
        "d2vModelFNt2 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModel2-00-06-23.txt' \n",
        "\n",
        "d2vModelFNm3 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModel3-00-06-23.model'\n",
        "d2vModelFNt3 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModel3-00-06-23.txt' \n",
        "\n",
        "csvTopic8MostSimilar = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/SimilarDocsByAlbert/Topics_8_MostSimilar_AL.csv'\n",
        "csvTopic20MostSimilar = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/SimilarDocsByAlbert/Topics_20_MostSimilar_AL.csv'\n",
        "csvTopic40MostSimilar = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/SimilarDocsByAlbert/Topics_40_MostSimilar_AL.csv'\n",
        "csvTopic50MostSimilar = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/SimilarDocsByAlbert/Topics_50_MostSimilar_AL.csv'\n",
        "csvTopic60MostSimilar = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/SimilarDocsByAlbert/Topics_60_MostSimilar_AL.csv'\n",
        "csvTopic65MostSimilar = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/SimilarDocsByAlbert/Topics_65_MostSimilar_AL.csv'\n",
        "csvTopic70MostSimilar = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/SimilarDocsByAlbert/Topics_70_MostSimilar_AL.csv'\n",
        "csvTopic80MostSimilar = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/SimilarDocsByAlbert/Topics_80_MostSimilar_AL.csv'\n",
        "#SimilarDocsByProposedMethod-Albert-Albert\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiSEEeOX5UxO"
      },
      "source": [
        "# Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-ztS1ZQ_5Xz",
        "outputId": "cd95558a-9a02-49ea-ba39-02eb40d5afa7"
      },
      "source": [
        "#No need in local\n",
        "from google.colab import drive\n",
        "drive.mount('/MYDRIVE', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /MYDRIVE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmK-tAmXydXh"
      },
      "source": [
        "# Prepair Dataset (Dividing into Test and Train)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9N4Y2ry_9yW"
      },
      "source": [
        "dfReviews = pd.DataFrame()\n",
        "dfReviews = pd.read_csv(inputFileName, encoding = 'utf-8', header = 0 )\n",
        "dfReviews.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhzbLnooKzgZ"
      },
      "source": [
        "dfReviews.loc[dfReviews[\"Text\"] == 'finish cuba straight round']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8nnJXkPMdqe"
      },
      "source": [
        "print(dfReviews.index[dfReviews[\"Text\"] == 'finish cuba straight round'].tolist() )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5k6XdrymFqu",
        "outputId": "844a33c4-b115-4cda-dcc0-4c4e47936abb"
      },
      "source": [
        "inputFileName"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Balenced-Dataset-00-06-26.csv'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKonEE_yHIW2"
      },
      "source": [
        "dfReviews.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0b20GkvxEm1"
      },
      "source": [
        "dfReviews = dfReviews.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pL4BWFkNxJdr"
      },
      "source": [
        "dfReviews.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQFrAAjUHpAu"
      },
      "source": [
        "len (dfReviews.loc[dfReviews[\"Sentiment\"] == 0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RcaSW8uISBH"
      },
      "source": [
        "len (dfReviews.loc[dfReviews[\"Sentiment\"] == 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leTzHA-2aH88"
      },
      "source": [
        "dfReviews[4] = 'train'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8bMsPoClaLT"
      },
      "source": [
        "dfReviews.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFWPmH-nleBf"
      },
      "source": [
        "dfReviews.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWjQ6aA7bDwI"
      },
      "source": [
        "testNumber=113320\n",
        "trainNumber=453280"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCylZNA_sOF1"
      },
      "source": [
        "dfReviews.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2kue_J3ls55"
      },
      "source": [
        "# Preparing test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDJllF_IIzKf"
      },
      "source": [
        "# Making embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6q0tLIMsuTFD"
      },
      "source": [
        "dfPositiveReviews = dfReviews[dfReviews[\"Sentiment\"] == 1]\n",
        "print(len(dfPositiveReviews))\n",
        "dfNegativeReviews = dfReviews[dfReviews[\"Sentiment\"] == 0]\n",
        "print(len(dfNegativeReviews))\n",
        "\n",
        "allPositiveReviews = list()\n",
        "for line in dfPositiveReviews[\"Text\"]:\n",
        "  allPositiveReviews.append( str(line) )\n",
        "\n",
        "\n",
        "allNegativeReviews = list()\n",
        "for line in dfNegativeReviews[\"Text\"]:\n",
        "  allNegativeReviews.append( str(line) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9z55MhtYuTFF",
        "outputId": "1f47d3c9-458c-45a8-b04c-6d9d92797344"
      },
      "source": [
        "%time\n",
        "#model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
        "positiveModel = SentenceTransformer(\"/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/paraphrase-albert-small-v2\")\n",
        "negativeModel = SentenceTransformer(\"/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/paraphrase-albert-small-v2\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 4.77 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Z-8G2nm9cnD",
        "outputId": "f8f52c7b-f199-4121-a566-ecdc97fb5e01"
      },
      "source": [
        "import scipy\n",
        "#test\n",
        "embedder = SentenceTransformer(\"/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/paraphrase-albert-small-v2\")\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "\n",
        "#embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Corpus with example sentences\n",
        "corpus = ['A man is eating food.',\n",
        "          'A man is eating a piece of bread.',\n",
        "          'The girl is carrying a baby.',\n",
        "          'A man is riding a horse.',\n",
        "          'A woman is playing violin.',\n",
        "          'Two men pushed carts through the woods.',\n",
        "          'A man is riding a white horse on an enclosed ground.',\n",
        "          'A monkey is playing drums.',\n",
        "          'A cheetah is running behind its prey.'\n",
        "          ]\n",
        "corpus_embeddings = embedder.encode(corpus, convert_to_tensor=True)\n",
        "\n",
        "# Query sentences:\n",
        "queries = ['man', 'pasta', 'white']\n",
        "\n",
        "\n",
        "# Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
        "top_k = min(5, len(corpus))\n",
        "for query in queries:\n",
        "    query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
        "\n",
        "    # We use cosine-similarity and torch.topk to find the highest 5 scores\n",
        "    cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
        "    top_results = torch.topk(cos_scores, k=top_k)\n",
        "\n",
        "    print(\"\\n\\n======================\\n\\n\")\n",
        "    print(\"Query:\", query)\n",
        "    print(\"\\nTop 5 most similar sentences in corpus:\")\n",
        "\n",
        "    for score, idx in zip(top_results[0], top_results[1]):\n",
        "        print(corpus[idx], \"(Score: {:.4f})\".format(score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "======================\n",
            "\n",
            "\n",
            "Query: man\n",
            "\n",
            "Top 5 most similar sentences in corpus:\n",
            "A man is eating a piece of bread. (Score: 0.2442)\n",
            "A man is eating food. (Score: 0.2376)\n",
            "A man is riding a horse. (Score: 0.1594)\n",
            "Two men pushed carts through the woods. (Score: 0.1338)\n",
            "A man is riding a white horse on an enclosed ground. (Score: 0.1142)\n",
            "\n",
            "\n",
            "======================\n",
            "\n",
            "\n",
            "Query: pasta\n",
            "\n",
            "Top 5 most similar sentences in corpus:\n",
            "A man is eating a piece of bread. (Score: 0.2294)\n",
            "A man is eating food. (Score: 0.2096)\n",
            "A monkey is playing drums. (Score: 0.0746)\n",
            "A man is riding a white horse on an enclosed ground. (Score: 0.0097)\n",
            "The girl is carrying a baby. (Score: 0.0070)\n",
            "\n",
            "\n",
            "======================\n",
            "\n",
            "\n",
            "Query: white\n",
            "\n",
            "Top 5 most similar sentences in corpus:\n",
            "A man is riding a white horse on an enclosed ground. (Score: 0.1994)\n",
            "A cheetah is running behind its prey. (Score: 0.1750)\n",
            "A monkey is playing drums. (Score: 0.0129)\n",
            "A woman is playing violin. (Score: 0.0034)\n",
            "Two men pushed carts through the woods. (Score: -0.0380)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SNrASSqAfL-",
        "outputId": "bbc80da6-8f90-4b42-f6a3-a093cf065302"
      },
      "source": [
        "import scipy\n",
        "#test\n",
        "embedder = SentenceTransformer(\"/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/nli-roberta-base-v2\")\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "\n",
        "#embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Corpus with example sentences\n",
        "corpus = ['A man is eating food.',\n",
        "          'A man is eating a piece of bread.',\n",
        "          'The girl is carrying a baby.',\n",
        "          'A man is riding a horse.',\n",
        "          'A woman is playing violin.',\n",
        "          'Two men pushed carts through the woods.',\n",
        "          'A man is riding a white horse on an enclosed ground.',\n",
        "          'A monkey is playing drums.',\n",
        "          'A cheetah is running behind its prey.'\n",
        "          ]\n",
        "corpus_embeddings = embedder.encode(corpus, convert_to_tensor=True)\n",
        "\n",
        "# Query sentences:\n",
        "queries = ['man', 'pasta', 'white']\n",
        "\n",
        "\n",
        "# Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
        "top_k = min(5, len(corpus))\n",
        "for query in queries:\n",
        "    query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
        "\n",
        "    # We use cosine-similarity and torch.topk to find the highest 5 scores\n",
        "    cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
        "    top_results = torch.topk(cos_scores, k=top_k)\n",
        "\n",
        "    print(\"\\n\\n======================\\n\\n\")\n",
        "    print(\"Query:\", query)\n",
        "    print(\"\\nTop 5 most similar sentences in corpus:\")\n",
        "\n",
        "    for score, idx in zip(top_results[0], top_results[1]):\n",
        "        print(corpus[idx], \"(Score: {:.4f})\".format(score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "======================\n",
            "\n",
            "\n",
            "Query: man\n",
            "\n",
            "Top 5 most similar sentences in corpus:\n",
            "A man is eating food. (Score: 0.3803)\n",
            "A man is riding a horse. (Score: 0.3799)\n",
            "A man is riding a white horse on an enclosed ground. (Score: 0.3169)\n",
            "Two men pushed carts through the woods. (Score: 0.2267)\n",
            "A man is eating a piece of bread. (Score: 0.2052)\n",
            "\n",
            "\n",
            "======================\n",
            "\n",
            "\n",
            "Query: pasta\n",
            "\n",
            "Top 5 most similar sentences in corpus:\n",
            "A man is eating a piece of bread. (Score: 0.2869)\n",
            "A man is eating food. (Score: 0.2812)\n",
            "A cheetah is running behind its prey. (Score: 0.1438)\n",
            "A woman is playing violin. (Score: 0.0281)\n",
            "A monkey is playing drums. (Score: 0.0135)\n",
            "\n",
            "\n",
            "======================\n",
            "\n",
            "\n",
            "Query: white\n",
            "\n",
            "Top 5 most similar sentences in corpus:\n",
            "A man is riding a white horse on an enclosed ground. (Score: 0.2028)\n",
            "Two men pushed carts through the woods. (Score: 0.1438)\n",
            "A woman is playing violin. (Score: 0.1108)\n",
            "A cheetah is running behind its prey. (Score: 0.0951)\n",
            "The girl is carrying a baby. (Score: 0.0758)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9sJopKsuTFN",
        "outputId": "6fef5ab0-028f-49c3-fa9d-8622389f3930"
      },
      "source": [
        "%time\n",
        "positiveEmbeddings = positiveModel.encode(allPositiveReviews, convert_to_numpy=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 2 µs, sys: 2 µs, total: 4 µs\n",
            "Wall time: 8.34 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UA5QMloruTFO",
        "outputId": "3a72bf88-0de2-4633-b06d-ca2e39ddc1d8"
      },
      "source": [
        "%time\n",
        "negativeEmbeddings = negativeModel.encode(allNegativeReviews, convert_to_numpy=True)\n",
        "\n",
        "print(positiveEmbeddings.shape)\n",
        "\n",
        "print(negativeEmbeddings.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 4 µs, sys: 1e+03 ns, total: 5 µs\n",
            "Wall time: 8.82 µs\n",
            "(283300, 768)\n",
            "(283300, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVfCNShf8zHs"
      },
      "source": [
        "# Save embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krU14g_GuTFQ",
        "outputId": "632bd130-a942-44f1-fc7c-5805c36cb7be"
      },
      "source": [
        "%time\n",
        "\n",
        "import os\n",
        "import csv\n",
        "import pickle\n",
        "embedding_positive_path = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Positive-Embeddings-Albert.pkl'\n",
        "embedding_negative_path = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Negative-Embeddings-Albert.pkl'\n",
        "print(\"Store file on disc\")\n",
        "with open(embedding_positive_path, \"wb\") as fOutPositive:\n",
        "    pickle.dump({'sentences': allPositiveReviews, 'embeddings': positiveEmbeddings}, fOutPositive)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
            "Wall time: 8.82 µs\n",
            "Store file on disc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikg_YDBWuTFS",
        "outputId": "28b6ec96-3c0a-438e-a81e-9add78934fac"
      },
      "source": [
        "%time\n",
        "\n",
        "with open(embedding_negative_path, \"wb\") as fOutNegative:\n",
        "    pickle.dump({'sentences': allNegativeReviews, 'embeddings': negativeEmbeddings}, fOutNegative)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 5.72 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4PpCJX5855K"
      },
      "source": [
        "# Load Pretrained embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmaJLRyL8-tL"
      },
      "source": [
        "print(\"Load positive pre-computed embeddings from disc\")\n",
        "with open(embedding_positive_path, \"rb\") as fInp:\n",
        "    cache_data = pickle.load(fInp)\n",
        "    positiveSentences = cache_data['sentences']\n",
        "    positiveEmbeddings = cache_data['embeddings']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_q2Drekc-K3p"
      },
      "source": [
        "print(\"Load negtive pre-computed embeddings from disc\")\n",
        "with open(embedding_negative_path, \"rb\") as fInn:\n",
        "    cache_data = pickle.load(fInn)\n",
        "    negativeSentences = cache_data['sentences']\n",
        "    negativeEmbeddings = cache_data['embeddings']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xTX52eC94Wr"
      },
      "source": [
        "# Find similarities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0_CY1LSEsfI"
      },
      "source": [
        "# Find the most similar docs tn = 8\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFrNxoZUGJoV",
        "outputId": "90433af5-fd16-46aa-bcef-6bf2d6e8774b"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "\n",
        "top_k = min(1000, len(allPositiveReviews))\n",
        "\n",
        "\n",
        "\n",
        "dfTopic8 = pd.read_csv(csvTopic8)\n",
        "print(dfTopic8.shape)\n",
        "dfTopic8 = dfTopic8.dropna()\n",
        "dfSimTopic8 = pd.DataFrame()\n",
        "keywordsTopic8 = []\n",
        "\n",
        "keywordsTopic8 = dfTopic8['Keywords']\n",
        "\n",
        "dfSimTopicPos = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorPos = np.zeros(768)\n",
        "\n",
        "dfSimTopicNeg = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorNeg = np.zeros(768)\n",
        "\n",
        "\n",
        "\n",
        "for item in keywordsTopic8 :\n",
        "  item = item.replace('[','')\n",
        "  item = item.replace(']','') \n",
        "  item = item.replace(\"'\",'')\n",
        "  item = item.replace(\",\",'')\n",
        "  inferred_docvecPos = positiveModel.encode(item, convert_to_numpy=True)\n",
        "  inferred_docvecNeg = negativeModel.encode(item, convert_to_numpy=True)\n",
        "\n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecPos, positiveEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    #dfSimTopicPos = dfSimTopicPos.append({\"docid\": idx, \"SimilarityScore\": score, \"Text\":allPositiveReviews[idx], \"Sentiment\":\"1\"}, ignore_index = True)\n",
        "    dfSimTopicPos = dfSimTopicPos.append({\"docid\":  dfReviews.index[dfReviews[\"Text\"] == allPositiveReviews[idx]].tolist()[0], \n",
        "                                          \"SimilarityScore\": score, \"Text\":allPositiveReviews[idx], \n",
        "                                          \"Sentiment\":\"1\"}, ignore_index = True)\n",
        "        \n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecNeg, negativeEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    #dfSimTopicNeg = dfSimTopicNeg.append({\"docid\": idx + 283300, \"SimilarityScore\": score, \"Text\":allNegativeReviews[idx], \"Sentiment\":\"0\"}, ignore_index = True)\n",
        "    dfSimTopicNeg = dfSimTopicNeg.append({\"docid\": dfReviews.index[dfReviews[\"Text\"] == allNegativeReviews[idx]].tolist()[0] , \n",
        "                                          \"SimilarityScore\": score, \"Text\":allNegativeReviews[idx], \n",
        "                                          \"Sentiment\":\"0\"}, ignore_index = True)\n",
        "\n",
        "  #end of for\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Number of unique Positive documents\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "dfSimTopicNeg.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "\n",
        "print(\"Number of unique Positive documents after droping duplicates\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents after droping duplicates\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "#Sampling 1000 positive and 1000 negatives\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos = dfSimTopicPos.iloc[0:1000, :]\n",
        "dfSimTopicNeg = dfSimTopicNeg.iloc[0:1000, :]\n",
        "\n",
        "#end Sampling 1000 positive and 1000 negatives\n",
        "\n",
        "\n",
        "print(\"Max Positive:\" , max(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Max Negatives:\" , max(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Min Positive:\" , min(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Min Negatives:\" , min(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Mean Positive:\", dfSimTopicPos[\"SimilarityScore\"].mean())\n",
        "print(\"Mean Negative:\", dfSimTopicNeg[\"SimilarityScore\"].mean())\n",
        "\n",
        "print(\"Std Positive:\",dfSimTopicPos[\"SimilarityScore\"].std())\n",
        "print(\"Std Negative:\",dfSimTopicNeg[\"SimilarityScore\"].std())\n",
        "\n",
        "\n",
        "print(\"len Positive:\" , len(dfSimTopicPos))\n",
        "print(\"len Negatives:\" , len(dfSimTopicNeg))\n",
        "\n",
        "dfAll8 = dfSimTopicNeg.append(dfSimTopicPos)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(8, 4)\n",
            "Number of unique Positive documents 2591\n",
            "Number of unique Negative documents 2184\n",
            "Number of unique Positive documents after droping duplicates 2591\n",
            "Number of unique Negative documents after droping duplicates 2184\n",
            "Max Positive: tensor(0.7563)\n",
            "Max Negatives: tensor(0.7533)\n",
            "Min Positive: tensor(0.6339)\n",
            "Min Negatives: tensor(0.6099)\n",
            "Mean Positive: 0.6580868530273437\n",
            "Mean Negative: 0.6381397705078125\n",
            "Std Positive: 0.021493892926386524\n",
            "Std Negative: 0.022935224590933195\n",
            "len Positive: 1000\n",
            "len Negatives: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8ZYoAm1gD5u"
      },
      "source": [
        "dfAll8.to_csv(csvTopic8MostSimilar, header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQT8TtiuFS9j"
      },
      "source": [
        "# Find the most similar docs tn = 20"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Di2OwCl9mS-Q",
        "outputId": "ccdc59e9-5750-4ddb-b673-5ae8e0eccbc7"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "\n",
        "top_k = min(200, len(allPositiveReviews))\n",
        "\n",
        "dfTopic20 = pd.read_csv(csvTopic20)\n",
        "print(dfTopic20.shape)\n",
        "dfTopic20 = dfTopic20.dropna()\n",
        "dfSimTopic20 = pd.DataFrame()\n",
        "keywordsTopic20 = []\n",
        "\n",
        "keywordsTopic20 = dfTopic20['Keywords']\n",
        "\n",
        "dfSimTopicPos = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorPos = np.zeros(768)\n",
        "\n",
        "dfSimTopicNeg = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorNeg = np.zeros(768)\n",
        "\n",
        "\n",
        "\n",
        "for item in keywordsTopic20 :\n",
        "  item = item.replace('[','')\n",
        "  item = item.replace(']','') \n",
        "  item = item.replace(\"'\",'')\n",
        "  item = item.replace(\",\",'')\n",
        "  inferred_docvecPos = positiveModel.encode(item, convert_to_numpy=True)\n",
        "  inferred_docvecNeg = negativeModel.encode(item, convert_to_numpy=True)\n",
        "\n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecPos, positiveEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicPos = dfSimTopicPos.append({\"docid\": dfReviews.index[dfReviews[\"Text\"] == allPositiveReviews[idx]].tolist()[0]\n",
        ", \"SimilarityScore\": score, \"Text\":allPositiveReviews[idx], \"Sentiment\":\"1\"}, ignore_index = True)\n",
        "        \n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecNeg, negativeEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicNeg = dfSimTopicNeg.append({\"docid\": dfReviews.index[dfReviews[\"Text\"] == allNegativeReviews[idx]].tolist()[0], \n",
        "                                          \"SimilarityScore\": score, \"Text\":allNegativeReviews[idx], \n",
        "                                          \"Sentiment\":\"0\"}, ignore_index = True)\n",
        "\n",
        "\n",
        "\n",
        "  #end of for\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Number of unique Positive documents\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "dfSimTopicNeg.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "\n",
        "print(\"Number of unique Positive documents after droping duplicates\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents after droping duplicates\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "#Sampling 1000 positive and 1000 negatives\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos = dfSimTopicPos.iloc[0:1000, :]\n",
        "dfSimTopicNeg = dfSimTopicNeg.iloc[0:1000, :]\n",
        "\n",
        "#end Sampling 1000 positive and 1000 negatives\n",
        "\n",
        "\n",
        "print(\"Max Positive:\" , max(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Max Negatives:\" , max(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Min Positive:\" , min(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Min Negatives:\" , min(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Mean Positive:\", dfSimTopicPos[\"SimilarityScore\"].mean())\n",
        "print(\"Mean Positive:\", dfSimTopicNeg[\"SimilarityScore\"].mean())\n",
        "\n",
        "print(\"Std Positive:\",dfSimTopicPos[\"SimilarityScore\"].std())\n",
        "print(\"Std Negative:\",dfSimTopicNeg[\"SimilarityScore\"].std())\n",
        "\n",
        "\n",
        "print(\"len Positive:\" , len(dfSimTopicPos))\n",
        "print(\"len Negatives:\" , len(dfSimTopicNeg))\n",
        "\n",
        "dfAll20 = dfSimTopicNeg.append(dfSimTopicPos)\n",
        "dfAll20.to_csv(csvTopic20MostSimilar, header=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(20, 4)\n",
            "Number of unique Positive documents 1737\n",
            "Number of unique Negative documents 1419\n",
            "Number of unique Positive documents after droping duplicates 1737\n",
            "Number of unique Negative documents after droping duplicates 1419\n",
            "Max Positive: tensor(0.7488)\n",
            "Max Negatives: tensor(0.7412)\n",
            "Min Positive: tensor(0.6174)\n",
            "Min Negatives: tensor(0.5589)\n",
            "Mean Positive: 0.6544489135742187\n",
            "Mean Positive: 0.6315431518554687\n",
            "Std Positive: 0.021716908927940735\n",
            "Std Negative: 0.03311594336001533\n",
            "len Positive: 1000\n",
            "len Negatives: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyME1mZ5FUrl"
      },
      "source": [
        "# Find the most similar docs tn = 40"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJOS7VAImqiz",
        "outputId": "28336c29-3901-4317-ed11-495053aa28e6"
      },
      "source": [
        "\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "\n",
        "top_k = min(200, len(allPositiveReviews))\n",
        "dfTopic40 = pd.read_csv(csvTopic40)\n",
        "print(dfTopic40.shape)\n",
        "dfTopic40 = dfTopic40.dropna()\n",
        "dfSimTopic40 = pd.DataFrame()\n",
        "keywordsTopic40 = []\n",
        "\n",
        "keywordsTopic40 = dfTopic40['Keywords']\n",
        "\n",
        "dfSimTopicPos = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorPos = np.zeros(768)\n",
        "\n",
        "dfSimTopicNeg = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorNeg = np.zeros(768)\n",
        "\n",
        "\n",
        "\n",
        "for item in keywordsTopic40 :\n",
        "  item = item.replace('[','')\n",
        "  item = item.replace(']','') \n",
        "  item = item.replace(\"'\",'')\n",
        "  item = item.replace(\",\",'')\n",
        "  inferred_docvecPos = positiveModel.encode(item, convert_to_numpy=True)\n",
        "  inferred_docvecNeg = negativeModel.encode(item, convert_to_numpy=True)\n",
        "\n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecPos, positiveEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicPos = dfSimTopicPos.append({\"docid\": dfReviews.index[dfReviews[\"Text\"] == allPositiveReviews[idx]].tolist()[0], \n",
        "                                          \"SimilarityScore\": score, \n",
        "                                          \"Text\":allPositiveReviews[idx], \"Sentiment\":\"1\"}, ignore_index = True)\n",
        "        \n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecNeg, negativeEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicNeg = dfSimTopicNeg.append({\"docid\": dfReviews.index[dfReviews[\"Text\"] == allNegativeReviews[idx]].tolist()[0], \n",
        "                                          \"SimilarityScore\": score, \n",
        "                                          \"Text\":allNegativeReviews[idx], \"Sentiment\":\"0\"}, ignore_index = True)\n",
        "\n",
        "\n",
        "  #end of for\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Number of unique Positive documents\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "dfSimTopicNeg.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "\n",
        "print(\"Number of unique Positive documents after droping duplicates\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents after droping duplicates\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "#Sampling 1000 positive and 1000 negatives\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos = dfSimTopicPos.iloc[0:1000, :]\n",
        "dfSimTopicNeg = dfSimTopicNeg.iloc[0:1000, :]\n",
        "\n",
        "#end Sampling 1000 positive and 1000 negatives\n",
        "\n",
        "\n",
        "print(\"Max Positive:\" , max(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Max Negatives:\" , max(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Min Positive:\" , min(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Min Negatives:\" , min(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Mean Positive:\", dfSimTopicPos[\"SimilarityScore\"].mean())\n",
        "print(\"Mean Positive:\", dfSimTopicNeg[\"SimilarityScore\"].mean())\n",
        "\n",
        "print(\"Std Positive:\",dfSimTopicPos[\"SimilarityScore\"].std())\n",
        "print(\"Std Negative:\",dfSimTopicNeg[\"SimilarityScore\"].std())\n",
        "\n",
        "\n",
        "print(\"len Positive:\" , len(dfSimTopicPos))\n",
        "print(\"len Negatives:\" , len(dfSimTopicNeg))\n",
        "\n",
        "dfAll40 = dfSimTopicNeg.append(dfSimTopicPos)\n",
        "dfAll40.to_csv(csvTopic40MostSimilar, header=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(40, 4)\n",
            "Number of unique Positive documents 3413\n",
            "Number of unique Negative documents 2740\n",
            "Number of unique Positive documents after droping duplicates 3413\n",
            "Number of unique Negative documents after droping duplicates 2740\n",
            "Max Positive: tensor(0.7486)\n",
            "Max Negatives: tensor(0.7661)\n",
            "Min Positive: tensor(0.6275)\n",
            "Min Negatives: tensor(0.5974)\n",
            "Mean Positive: 0.6618399658203125\n",
            "Mean Positive: 0.6446107177734375\n",
            "Std Positive: 0.022341007998002264\n",
            "Std Negative: 0.030526419274347075\n",
            "len Positive: 1000\n",
            "len Negatives: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDAPVn0mFWWU"
      },
      "source": [
        "# Find the most similar docs tn = 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7aDWFX-nB3f",
        "outputId": "e8141623-ebd7-4e36-eb28-b5e7d280f945"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "\n",
        "top_k = min(200, len(allPositiveReviews))\n",
        "\n",
        "dfTopic50 = pd.read_csv(csvTopic50)\n",
        "print(dfTopic50.shape)\n",
        "dfTopic50 = dfTopic50.dropna()\n",
        "dfSimTopic50 = pd.DataFrame()\n",
        "keywordsTopic50 = []\n",
        "\n",
        "keywordsTopic50 = dfTopic50['Keywords']\n",
        "\n",
        "dfSimTopicPos = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorPos = np.zeros(768)\n",
        "\n",
        "dfSimTopicNeg = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorNeg = np.zeros(768)\n",
        "\n",
        "\n",
        "\n",
        "for item in keywordsTopic50 :\n",
        "  item = item.replace('[','')\n",
        "  item = item.replace(']','') \n",
        "  item = item.replace(\"'\",'')\n",
        "  item = item.replace(\",\",'')\n",
        "  inferred_docvecPos = positiveModel.encode(item, convert_to_numpy=True)\n",
        "  inferred_docvecNeg = negativeModel.encode(item, convert_to_numpy=True)\n",
        "\n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecPos, positiveEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicPos = dfSimTopicPos.append({\"docid\": dfReviews.index[dfReviews[\"Text\"] == allPositiveReviews[idx]].tolist()[0],\n",
        "                                          \"SimilarityScore\": score, \n",
        "                                          \"Text\":allPositiveReviews[idx], \"Sentiment\":\"1\"}, ignore_index = True)\n",
        "        \n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecNeg, negativeEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicNeg = dfSimTopicNeg.append({\"docid\": dfReviews.index[dfReviews[\"Text\"] == allNegativeReviews[idx]].tolist()[0], \n",
        "                                          \"SimilarityScore\": score, \"Text\":allNegativeReviews[idx], \n",
        "                                          \"Sentiment\":\"0\"}, ignore_index = True)\n",
        "\n",
        "  #end of for\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Number of unique Positive documents\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "dfSimTopicNeg.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "\n",
        "print(\"Number of unique Positive documents after droping duplicates\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents after droping duplicates\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "#Sampling 1000 positive and 1000 negatives\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos = dfSimTopicPos.iloc[0:1000, :]\n",
        "dfSimTopicNeg = dfSimTopicNeg.iloc[0:1000, :]\n",
        "\n",
        "#end Sampling 1000 positive and 1000 negatives\n",
        "\n",
        "\n",
        "print(\"Max Positive:\" , max(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Max Negatives:\" , max(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Min Positive:\" , min(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Min Negatives:\" , min(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Mean Positive:\", dfSimTopicPos[\"SimilarityScore\"].mean())\n",
        "print(\"Mean Positive:\", dfSimTopicNeg[\"SimilarityScore\"].mean())\n",
        "\n",
        "print(\"Std Positive:\",dfSimTopicPos[\"SimilarityScore\"].std())\n",
        "print(\"Std Negative:\",dfSimTopicNeg[\"SimilarityScore\"].std())\n",
        "\n",
        "\n",
        "print(\"len Positive:\" , len(dfSimTopicPos))\n",
        "print(\"len Negatives:\" , len(dfSimTopicNeg))\n",
        "\n",
        "dfAll50 = dfSimTopicNeg.append(dfSimTopicPos)\n",
        "dfAll50.to_csv(csvTopic50MostSimilar, header=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(50, 4)\n",
            "Number of unique Positive documents 4513\n",
            "Number of unique Negative documents 3596\n",
            "Number of unique Positive documents after droping duplicates 4513\n",
            "Number of unique Negative documents after droping duplicates 3596\n",
            "Max Positive: tensor(0.7436)\n",
            "Max Negatives: tensor(0.7340)\n",
            "Min Positive: tensor(0.6305)\n",
            "Min Negatives: tensor(0.6069)\n",
            "Mean Positive: 0.6575084838867188\n",
            "Mean Positive: 0.6414441528320313\n",
            "Std Positive: 0.019681915879928884\n",
            "Std Negative: 0.023935546840345576\n",
            "len Positive: 1000\n",
            "len Negatives: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9oj1SUTFYWm"
      },
      "source": [
        "# Find the most similar docs tn = 60"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "B3ktIBbvpYu7",
        "outputId": "e6dced18-9707-4469-f2fa-de2e5b28cc57"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "\n",
        "top_k = min(500, len(allPositiveReviews))\n",
        "\n",
        "\n",
        "dfTopic60 = pd.read_csv(csvTopic60)\n",
        "print(dfTopic60.shape)\n",
        "dfTopic60 = dfTopic60.dropna()\n",
        "dfSimTopic60 = pd.DataFrame()\n",
        "keywordsTopic60 = []\n",
        "\n",
        "keywordsTopic60 = dfTopic60['Keywords']\n",
        "\n",
        "dfSimTopicPos = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorPos = np.zeros(768)\n",
        "\n",
        "dfSimTopicNeg = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorNeg = np.zeros(768)\n",
        "\n",
        "\n",
        "\n",
        "for item in keywordsTopic60 :\n",
        "  item = item.replace('[','')\n",
        "  item = item.replace(']','') \n",
        "  item = item.replace(\"'\",'')\n",
        "  item = item.replace(\",\",'')\n",
        "  inferred_docvecPos = positiveModel.encode(item, convert_to_numpy=True)\n",
        "  inferred_docvecNeg = negativeModel.encode(item, convert_to_numpy=True)\n",
        "\n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecPos, positiveEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicPos = dfSimTopicPos.append({\"docid\": dfReviews.index[dfReviews[\"Text\"] == allPositiveReviews[idx]].tolist()[0], \n",
        "                                          \"SimilarityScore\": score, \"Text\":allPositiveReviews[idx], \n",
        "                                          \"Sentiment\":\"1\"}, ignore_index = True)\n",
        "        \n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecNeg, negativeEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicNeg = dfSimTopicNeg.append({\"docid\": dfReviews.index[dfReviews[\"Text\"] == allNegativeReviews[idx]].tolist()[0], \n",
        "                                          \"SimilarityScore\": score, \"Text\":allNegativeReviews[idx], \n",
        "                                          \"Sentiment\":\"0\"}, ignore_index = True)\n",
        "\n",
        "\n",
        "\n",
        "  #end of for\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Number of unique Positive documents\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "dfSimTopicNeg.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "\n",
        "print(\"Number of unique Positive documents after droping duplicates\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents after droping duplicates\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "#Sampling 1000 positive and 1000 negatives\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos = dfSimTopicPos.iloc[0:1000, :]\n",
        "dfSimTopicNeg = dfSimTopicNeg.iloc[0:1000, :]\n",
        "\n",
        "#end Sampling 1000 positive and 1000 negatives\n",
        "\n",
        "\n",
        "print(\"Max Positive:\" , max(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Max Negatives:\" , max(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Min Positive:\" , min(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Min Negatives:\" , min(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Mean Positive:\", dfSimTopicPos[\"SimilarityScore\"].mean())\n",
        "print(\"Mean Positive:\", dfSimTopicNeg[\"SimilarityScore\"].mean())\n",
        "\n",
        "print(\"Std Positive:\",dfSimTopicPos[\"SimilarityScore\"].std())\n",
        "print(\"Std Negative:\",dfSimTopicNeg[\"SimilarityScore\"].std())\n",
        "\n",
        "\n",
        "print(\"len Positive:\" , len(dfSimTopicPos))\n",
        "print(\"len Negatives:\" , len(dfSimTopicNeg))\n",
        "\n",
        "dfAll60 = dfSimTopicNeg.append(dfSimTopicPos)\n",
        "dfAll60.to_csv(csvTopic60MostSimilar, header=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60, 4)\n",
            "Number of unique Positive documents 9424\n",
            "Number of unique Negative documents 7144\n",
            "Number of unique Positive documents after droping duplicates 9424\n",
            "Number of unique Negative documents after droping duplicates 7144\n",
            "Max Positive: tensor(0.7536)\n",
            "Max Negatives: tensor(0.7587)\n",
            "Min Positive: tensor(0.6453)\n",
            "Min Negatives: tensor(0.6284)\n",
            "Mean Positive: 0.6669966430664063\n",
            "Mean Positive: 0.6572528076171875\n",
            "Std Positive: 0.018915244197137637\n",
            "Std Negative: 0.021823321029939172\n",
            "len Positive: 1000\n",
            "len Negatives: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mye0KNDdFZm4"
      },
      "source": [
        "# Find the most similar docs tn = 65"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OM4bWg5aprEW"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "\n",
        "top_k = min(500, len(allPositiveReviews))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "dfTopic65 = pd.read_csv(csvTopic65)\n",
        "print(dfTopic65.shape)\n",
        "dfTopic65 = dfTopic65.dropna()\n",
        "dfSimTopic65 = pd.DataFrame()\n",
        "keywordsTopic65 = []\n",
        "\n",
        "keywordsTopic65 = dfTopic65['Keywords']\n",
        "\n",
        "dfSimTopicPos = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorPos = np.zeros(768)\n",
        "\n",
        "dfSimTopicNeg = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorNeg = np.zeros(768)\n",
        "\n",
        "\n",
        "\n",
        "for item in keywordsTopic65 :\n",
        "  item = item.replace('[','')\n",
        "  item = item.replace(']','') \n",
        "  item = item.replace(\"'\",'')\n",
        "  item = item.replace(\",\",'')\n",
        "  inferred_docvecPos = positiveModel.encode(item, convert_to_numpy=True)\n",
        "  inferred_docvecNeg = negativeModel.encode(item, convert_to_numpy=True)\n",
        "\n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecPos, positiveEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicPos = dfSimTopicPos.append({\"docid\": dfReviews.index[dfReviews[\"Text\"] == allPositiveReviews[idx]].tolist()[0], \n",
        "                                          \"SimilarityScore\": score, \"Text\":allPositiveReviews[idx], \n",
        "                                          \"Sentiment\":\"1\"}, ignore_index = True)\n",
        "        \n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecNeg, negativeEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicNeg = dfSimTopicNeg.append({\"docid\": dfReviews.index[dfReviews[\"Text\"] == allNegativeReviews[idx]].tolist()[0], \n",
        "                                          \"SimilarityScore\": score, \"Text\":allNegativeReviews[idx], \n",
        "                                          \"Sentiment\":\"0\"}, ignore_index = True)\n",
        "\n",
        "\n",
        "\n",
        "  #end of for\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Number of unique Positive documents\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "dfSimTopicNeg.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "\n",
        "print(\"Number of unique Positive documents after droping duplicates\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents after droping duplicates\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "#Sampling 1000 positive and 1000 negatives\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos = dfSimTopicPos.iloc[0:1000, :]\n",
        "dfSimTopicNeg = dfSimTopicNeg.iloc[0:1000, :]\n",
        "\n",
        "#end Sampling 1000 positive and 1000 negatives\n",
        "\n",
        "\n",
        "print(\"Max Positive:\" , max(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Max Negatives:\" , max(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Min Positive:\" , min(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Min Negatives:\" , min(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Mean Positive:\", dfSimTopicPos[\"SimilarityScore\"].mean())\n",
        "print(\"Mean Positive:\", dfSimTopicNeg[\"SimilarityScore\"].mean())\n",
        "\n",
        "print(\"Std Positive:\",dfSimTopicPos[\"SimilarityScore\"].std())\n",
        "print(\"Std Negative:\",dfSimTopicNeg[\"SimilarityScore\"].std())\n",
        "\n",
        "\n",
        "print(\"len Positive:\" , len(dfSimTopicPos))\n",
        "print(\"len Negatives:\" , len(dfSimTopicNeg))\n",
        "\n",
        "dfAll65 = dfSimTopicNeg.append(dfSimTopicPos)\n",
        "dfAll65.to_csv(csvTopic65MostSimilar, header=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RHcSo4-Fa_a"
      },
      "source": [
        "# Find the most similar docs tn = 70"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgopwngQqKuk"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "\n",
        "top_k = min(500, len(allPositiveReviews))\n",
        "\n",
        "dfTopic70 = pd.read_csv(csvTopic70)\n",
        "print(dfTopic70.shape)\n",
        "dfTopic70 = dfTopic70.dropna()\n",
        "dfSimTopic70 = pd.DataFrame()\n",
        "keywordsTopic70 = []\n",
        "\n",
        "keywordsTopic70 = dfTopic70['Keywords']\n",
        "\n",
        "dfSimTopicPos = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorPos = np.zeros(768)\n",
        "\n",
        "dfSimTopicNeg = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorNeg = np.zeros(768)\n",
        "\n",
        "\n",
        "\n",
        "for item in keywordsTopic70 :\n",
        "  item = item.replace('[','')\n",
        "  item = item.replace(']','') \n",
        "  item = item.replace(\"'\",'')\n",
        "  item = item.replace(\",\",'')\n",
        "  inferred_docvecPos = positiveModel.encode(item, convert_to_numpy=True)\n",
        "  inferred_docvecNeg = negativeModel.encode(item, convert_to_numpy=True)\n",
        "\n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecPos, positiveEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicPos = dfSimTopicPos.append({\"docid\": dfReviews.index[dfReviews[\"Text\"] == allPositiveReviews[idx]].tolist()[0], \n",
        "                                          \"SimilarityScore\": score, \"Text\":allPositiveReviews[idx], \n",
        "                                          \"Sentiment\":\"1\"}, ignore_index = True)\n",
        "        \n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecNeg, negativeEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicNeg = dfSimTopicNeg.append({\"docid\": dfReviews.index[dfReviews[\"Text\"] == allNegativeReviews[idx]].tolist()[0], \n",
        "                                          \"SimilarityScore\": score, \"Text\":allNegativeReviews[idx], \n",
        "                                          \"Sentiment\":\"0\"}, ignore_index = True)\n",
        "\n",
        "\n",
        "\n",
        "  #end of for\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Number of unique Positive documents\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "dfSimTopicNeg.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "\n",
        "print(\"Number of unique Positive documents after droping duplicates\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents after droping duplicates\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "#Sampling 1000 positive and 1000 negatives\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos = dfSimTopicPos.iloc[0:1000, :]\n",
        "dfSimTopicNeg = dfSimTopicNeg.iloc[0:1000, :]\n",
        "\n",
        "#end Sampling 1000 positive and 1000 negatives\n",
        "\n",
        "\n",
        "print(\"Max Positive:\" , max(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Max Negatives:\" , max(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Min Positive:\" , min(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Min Negatives:\" , min(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Mean Positive:\", dfSimTopicPos[\"SimilarityScore\"].mean())\n",
        "print(\"Mean Positive:\", dfSimTopicNeg[\"SimilarityScore\"].mean())\n",
        "\n",
        "print(\"Std Positive:\",dfSimTopicPos[\"SimilarityScore\"].std())\n",
        "print(\"Std Negative:\",dfSimTopicNeg[\"SimilarityScore\"].std())\n",
        "\n",
        "\n",
        "print(\"len Positive:\" , len(dfSimTopicPos))\n",
        "print(\"len Negatives:\" , len(dfSimTopicNeg))\n",
        "\n",
        "dfAll70 = dfSimTopicNeg.append(dfSimTopicPos)\n",
        "dfAll70.to_csv(csvTopic70MostSimilar, header=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAWPmqdjFcjw"
      },
      "source": [
        "# Find the most similar docs tn = 80"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6Fvh6CmqjbE"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "\n",
        "top_k = min(500, len(allPositiveReviews))\n",
        "\n",
        "\n",
        "\n",
        "dfTopic80 = pd.read_csv(csvTopic80)\n",
        "print(dfTopic80.shape)\n",
        "dfTopic80 = dfTopic80.dropna()\n",
        "dfSimTopic80 = pd.DataFrame()\n",
        "keywordsTopic80 = []\n",
        "\n",
        "keywordsTopic80 = dfTopic80['Keywords']\n",
        "\n",
        "dfSimTopicPos = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorPos = np.zeros(768)\n",
        "\n",
        "dfSimTopicNeg = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorNeg = np.zeros(768)\n",
        "\n",
        "\n",
        "\n",
        "for item in keywordsTopic80 :\n",
        "  item = item.replace('[','')\n",
        "  item = item.replace(']','') \n",
        "  item = item.replace(\"'\",'')\n",
        "  item = item.replace(\",\",'')\n",
        "  inferred_docvecPos = positiveModel.encode(item, convert_to_numpy=True)\n",
        "  inferred_docvecNeg = negativeModel.encode(item, convert_to_numpy=True)\n",
        "\n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecPos, positiveEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicPos = dfSimTopicPos.append({\"docid\": dfReviews.index[dfReviews[\"Text\"] == allPositiveReviews[idx]].tolist()[0], \n",
        "                                          \"SimilarityScore\": score, \"Text\":allPositiveReviews[idx], \n",
        "                                          \"Sentiment\":\"1\"}, ignore_index = True)\n",
        "        \n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecNeg, negativeEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicNeg = dfSimTopicNeg.append({\"docid\": dfReviews.index[dfReviews[\"Text\"] == allNegativeReviews[idx]].tolist()[0], \n",
        "                                          \"SimilarityScore\": score, \"Text\":allNegativeReviews[idx], \n",
        "                                          \"Sentiment\":\"0\"}, ignore_index = True)\n",
        "\n",
        "\n",
        "\n",
        "print(\"end of for\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Number of unique Positive documents\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "dfSimTopicNeg.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "\n",
        "print(\"Number of unique Positive documents after droping duplicates\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents after droping duplicates\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "#Sampling 1000 positive and 1000 negatives\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos = dfSimTopicPos.iloc[0:1000, :]\n",
        "dfSimTopicNeg = dfSimTopicNeg.iloc[0:1000, :]\n",
        "\n",
        "#end Sampling 1000 positive and 1000 negatives\n",
        "\n",
        "\n",
        "print(\"Max Positive:\" , max(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Max Negatives:\" , max(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Min Positive:\" , min(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Min Negatives:\" , min(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Mean Positive:\", dfSimTopicPos[\"SimilarityScore\"].mean())\n",
        "print(\"Mean Positive:\", dfSimTopicNeg[\"SimilarityScore\"].mean())\n",
        "\n",
        "print(\"Std Positive:\",dfSimTopicPos[\"SimilarityScore\"].std())\n",
        "print(\"Std Negative:\",dfSimTopicNeg[\"SimilarityScore\"].std())\n",
        "\n",
        "\n",
        "print(\"len Positive:\" , len(dfSimTopicPos))\n",
        "print(\"len Negatives:\" , len(dfSimTopicNeg))\n",
        "\n",
        "dfAll80 = dfSimTopicNeg.append(dfSimTopicPos)\n",
        "dfAll80.to_csv(csvTopic80MostSimilar, header=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bGC0gx3uTF3"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}