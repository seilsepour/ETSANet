{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "kuu6z-ZZoZHq",
        "HiSEEeOX5UxO",
        "S2kue_J3ls55"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5Fp4PNOzHf6"
      },
      "source": [
        "This module is responsible for:\n",
        "  \n",
        "\n",
        "*   Finding the most similar documents to topics using Sentence Bert\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuu6z-ZZoZHq"
      },
      "source": [
        "## Configurations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbkcv3irn-mi"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf6N4pe_oSu6"
      },
      "source": [
        "import logging\n",
        "#logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tBIYWabuTES",
        "outputId": "8bdccf54-c3b0-41c7-facb-6bfc176dfb9e"
      },
      "source": [
        "pip install sentence-transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.1.0.tar.gz (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 3.6 MB/s \n",
            "\u001b[?25hCollecting transformers<5.0.0,>=4.6.0\n",
            "  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 12.6 MB/s \n",
            "\u001b[?25hCollecting tokenizers>=0.10.3\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 32.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.62.3)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.9.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.10.0+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 37.5 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 33.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (4.8.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.23.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 40.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.0.1)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.1.0-py3-none-any.whl size=121000 sha256=27fa6a48ac8d6cd265b94b28601b982c1e9dbc4fa76f35a89b8ae095fe3d4745\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/f0/bb/ed1add84da70092ea526466eadc2bfb197c4bcb8d4fa5f7bad\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers, sentencepiece, sentence-transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.19 pyyaml-5.4.1 sacremoses-0.0.46 sentence-transformers-2.1.0 sentencepiece-0.1.96 tokenizers-0.10.3 transformers-4.11.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOZnc3w7CA9Y"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gensim\n",
        "from sklearn.model_selection import train_test_split\n",
        "import multiprocessing\n",
        "from collections import OrderedDict\n",
        "\n",
        "import gensim.models.doc2vec\n",
        "assert gensim.models.doc2vec.FAST_VERSION > -1, \"This will be painfully slow otherwise\"\n",
        "\n",
        "from gensim.models.doc2vec import Doc2Vec\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import collections\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxGpI5Zq6IQl",
        "outputId": "301fc274-c515-470d-aa24-f555278a1f19"
      },
      "source": [
        "pip install testfixtures"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting testfixtures\n",
            "  Downloading testfixtures-6.18.3-py2.py3-none-any.whl (95 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▍                            | 10 kB 25.7 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 20 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 30 kB 18.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 40 kB 15.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 51 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 61 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 71 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 81 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 92 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 95 kB 2.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: testfixtures\n",
            "Successfully installed testfixtures-6.18.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0FG4Qzc_bYD"
      },
      "source": [
        "#'/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Processed-Merged-Dataset-99-08-28.csv'\n",
        "\n",
        "inputFileName = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Balenced-Dataset-00-06-26.csv'\n",
        "\n",
        "\n",
        "outputLabelledTTDS= '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Balenced-Dataset-00-06-26.csv'\n",
        "outputDocsFileName = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/DocsReadyForD2V-00-06-26.csv'\n",
        "\n",
        "d2vModelFNmPos = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModelPositive-00-06-26.model'\n",
        "d2vModelFNtPos = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModelPositive-00-06-26.txt' \n",
        "\n",
        "d2vModelFNmNeg = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModelNegative-00-06-26.model'\n",
        "d2vModelFNtNeg = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModelNegative-00-06-26.txt' \n",
        "\n",
        "csvTopic8 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Topics_8.csv'\n",
        "csvTopic20 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Topics_20.csv'\n",
        "csvTopic40 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Topics_40.csv'\n",
        "csvTopic80 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Topics_80.csv'\n",
        "csvTopic50 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Topics_50.csv'\n",
        "csvTopic60 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Topics_60.csv'\n",
        "csvTopic65 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Topics_65.csv'\n",
        "csvTopic70 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Topics_70.csv'\n",
        "\n",
        "\n",
        "d2vModelFNm0 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModel0-00-06-23.model'\n",
        "d2vModelFNt0 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModel0-00-06-23.txt' \n",
        "\n",
        "d2vModelFNm1 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModel1-00-06-23.model'\n",
        "d2vModelFNt1 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModel1-00-06-23.txt' \n",
        "\n",
        "d2vModelFNm2 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModel2-00-06-23.model'\n",
        "d2vModelFNt2 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModel2-00-06-23.txt' \n",
        "\n",
        "d2vModelFNm3 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModel3-00-06-23.model'\n",
        "d2vModelFNt3 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModel3-00-06-23.txt' \n",
        "\n",
        "csvTopic8MostSimilar = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/SimilarDocsBySBERT/Topics_8_MostSimilar_SB.csv'\n",
        "csvTopic20MostSimilar = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/SimilarDocsBySBERT/Topics_20_MostSimilar_SB.csv'\n",
        "csvTopic40MostSimilar = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/SimilarDocsBySBERT/Topics_40_MostSimilar_SB.csv'\n",
        "csvTopic50MostSimilar = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/SimilarDocsBySBERT/Topics_50_MostSimilar_SB.csv'\n",
        "csvTopic60MostSimilar = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/SimilarDocsBySBERT/Topics_60_MostSimilar_SB.csv'\n",
        "csvTopic65MostSimilar = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/SimilarDocsBySBERT/Topics_65_MostSimilar_SB.csv'\n",
        "csvTopic70MostSimilar = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/SimilarDocsBySBERT/Topics_70_MostSimilar_SB.csv'\n",
        "csvTopic80MostSimilar = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/SimilarDocsBySBERT/Topics_80_MostSimilar_SB.csv'\n",
        "#SimilarDocsBySBERT-Albert\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiSEEeOX5UxO"
      },
      "source": [
        "# Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-ztS1ZQ_5Xz",
        "outputId": "068b15d0-fc72-43d1-e654-4f6acc51fa3f"
      },
      "source": [
        "#No need in local\n",
        "from google.colab import drive\n",
        "drive.mount('/MYDRIVE', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /MYDRIVE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmK-tAmXydXh"
      },
      "source": [
        "# Prepair Dataset (Dividing into Test and Train)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "b9N4Y2ry_9yW",
        "outputId": "bad1654b-e90e-403a-e6c2-7222bbb2f24b"
      },
      "source": [
        "dfReviews = pd.DataFrame()\n",
        "dfReviews = pd.read_csv(inputFileName, encoding = 'utf-8', header = 0 )\n",
        "dfReviews.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Text</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>watch movi rock babi kitti asleep sling hang n...</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>hata good compani right can feel sorri might c...</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>finish cuba straight round</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...   Type\n",
              "0           0  ...  train\n",
              "1           1  ...  train\n",
              "2           2  ...  train\n",
              "\n",
              "[3 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "P5k6XdrymFqu",
        "outputId": "301fe0dd-98ae-403f-cd4c-680a0a09c343"
      },
      "source": [
        "inputFileName"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Balenced-Dataset-00-06-26.csv'"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKonEE_yHIW2",
        "outputId": "257ed621-75c0-4c93-94ee-f45d0b62f860"
      },
      "source": [
        "dfReviews.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(566600, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0b20GkvxEm1"
      },
      "source": [
        "dfReviews = dfReviews.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pL4BWFkNxJdr",
        "outputId": "faeb2310-32ac-41e5-e9a5-55f0bf9066d1"
      },
      "source": [
        "dfReviews.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(566600, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQFrAAjUHpAu",
        "outputId": "5271b58f-31bf-420c-84fb-7635ccafcbae"
      },
      "source": [
        "len (dfReviews.loc[dfReviews[\"Sentiment\"] == 0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "283300"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RcaSW8uISBH",
        "outputId": "40bae636-f0d3-4993-ab46-0ee8222b384d"
      },
      "source": [
        "len (dfReviews.loc[dfReviews[\"Sentiment\"] == 1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "283300"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leTzHA-2aH88"
      },
      "source": [
        "dfReviews[4] = 'train'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8bMsPoClaLT",
        "outputId": "6c6a1d7a-e227-4666-e08f-d02a5d49d417"
      },
      "source": [
        "dfReviews.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'Text', 'Sentiment', 'Type', 4], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFWPmH-nleBf"
      },
      "source": [
        "dfReviews.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWjQ6aA7bDwI"
      },
      "source": [
        "testNumber=113320\n",
        "trainNumber=453280"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCylZNA_sOF1"
      },
      "source": [
        "dfReviews.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2kue_J3ls55"
      },
      "source": [
        "# Preparing test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDJllF_IIzKf"
      },
      "source": [
        "# Making embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6q0tLIMsuTFD"
      },
      "source": [
        "dfPositiveReviews = dfReviews[dfReviews[\"Sentiment\"] == 1]\n",
        "print(len(dfPositiveReviews))\n",
        "dfNegativeReviews = dfReviews[dfReviews[\"Sentiment\"] == 0]\n",
        "print(len(dfNegativeReviews))\n",
        "\n",
        "allPositiveReviews = list()\n",
        "for line in dfPositiveReviews[\"Text\"]:\n",
        "  allPositiveReviews.append( str(line) )\n",
        "\n",
        "\n",
        "allNegativeReviews = list()\n",
        "for line in dfNegativeReviews[\"Text\"]:\n",
        "  allNegativeReviews.append( str(line) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9z55MhtYuTFF",
        "outputId": "2038563d-af87-4cb4-afd6-507b64794d38"
      },
      "source": [
        "%time\n",
        "#model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
        "positiveModel = SentenceTransformer(\"/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/all-MiniLM-L6-v2\")\n",
        "negativeModel = SentenceTransformer(\"/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/all-MiniLM-L6-v2\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3 µs, sys: 1e+03 ns, total: 4 µs\n",
            "Wall time: 7.15 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9sJopKsuTFN",
        "outputId": "173cb8be-bf50-460d-8db3-7d980c3b7ea8"
      },
      "source": [
        "%time\n",
        "positiveEmbeddings = positiveModel.encode(allPositiveReviews, convert_to_numpy=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
            "Wall time: 5.25 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UA5QMloruTFO",
        "outputId": "27fb1238-c1ba-4deb-b297-95ff33f18619"
      },
      "source": [
        "%time\n",
        "negativeEmbeddings = negativeModel.encode(allNegativeReviews, convert_to_numpy=True)\n",
        "\n",
        "print(positiveEmbeddings.shape)\n",
        "\n",
        "print(negativeEmbeddings.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 5.72 µs\n",
            "(283300, 384)\n",
            "(283300, 384)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVfCNShf8zHs"
      },
      "source": [
        "# Save embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krU14g_GuTFQ",
        "outputId": "8c1f23b4-a566-4a3a-d296-7e6402be048f"
      },
      "source": [
        "%time\n",
        "\n",
        "import os\n",
        "import csv\n",
        "import pickle\n",
        "embedding_positive_path = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Positive-Embeddings-SBERT.pkl'\n",
        "embedding_negative_path = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Negative-Embeddings-SBERT.pkl'\n",
        "print(\"Store file on disc\")\n",
        "with open(embedding_positive_path, \"wb\") as fOutPositive:\n",
        "    pickle.dump({'sentences': allPositiveReviews, 'embeddings': positiveEmbeddings}, fOutPositive)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
            "Wall time: 8.34 µs\n",
            "Store file on disc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikg_YDBWuTFS",
        "outputId": "ff277e5e-99dc-4025-c235-fa56bee2c0ed"
      },
      "source": [
        "%time\n",
        "\n",
        "with open(embedding_negative_path, \"wb\") as fOutNegative:\n",
        "    pickle.dump({'sentences': allNegativeReviews, 'embeddings': negativeEmbeddings}, fOutNegative)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 6 µs, sys: 0 ns, total: 6 µs\n",
            "Wall time: 11 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4PpCJX5855K"
      },
      "source": [
        "# Load Pretrained embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmaJLRyL8-tL"
      },
      "source": [
        "print(\"Load positive pre-computed embeddings from disc\")\n",
        "with open(embedding_positive_path, \"rb\") as fInp:\n",
        "    cache_data = pickle.load(fInp)\n",
        "    positiveSentences = cache_data['sentences']\n",
        "    positiveEmbeddings = cache_data['embeddings']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_q2Drekc-K3p"
      },
      "source": [
        "print(\"Load negtive pre-computed embeddings from disc\")\n",
        "with open(embedding_negative_path, \"rb\") as fInn:\n",
        "    cache_data = pickle.load(fInn)\n",
        "    negativeSentences = cache_data['sentences']\n",
        "    negativeEmbeddings = cache_data['embeddings']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xTX52eC94Wr"
      },
      "source": [
        "# Find similarities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0_CY1LSEsfI"
      },
      "source": [
        "# Find the most similar docs tn = 8\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFrNxoZUGJoV"
      },
      "source": [
        "\n",
        "\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "\n",
        "top_k = min(1000, len(allPositiveReviews))\n",
        "\n",
        "\n",
        "\n",
        "dfTopic8 = pd.read_csv(csvTopic8)\n",
        "print(dfTopic8.shape)\n",
        "dfTopic8 = dfTopic8.dropna()\n",
        "dfSimTopic8 = pd.DataFrame()\n",
        "keywordsTopic8 = []\n",
        "\n",
        "keywordsTopic8 = dfTopic8['Keywords']\n",
        "\n",
        "dfSimTopicPos = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorPos = np.zeros(768)\n",
        "\n",
        "dfSimTopicNeg = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorNeg = np.zeros(768)\n",
        "\n",
        "\n",
        "\n",
        "for item in keywordsTopic8 :\n",
        "  item = item.replace('[','')\n",
        "  item = item.replace(']','') \n",
        "  item = item.replace(\"'\",'')\n",
        "  item = item.replace(\",\",'')\n",
        "  inferred_docvecPos = positiveModel.encode(item, convert_to_numpy=True)\n",
        "  inferred_docvecNeg = negativeModel.encode(item, convert_to_numpy=True)\n",
        "\n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecPos, positiveEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicPos = dfSimTopicPos.append({\"docid\": idx, \"SimilarityScore\": score, \"Text\":allPositiveReviews[idx]}, ignore_index = True)\n",
        "        \n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecNeg, negativeEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicNeg = dfSimTopicNeg.append({\"docid\": idx + 283300, \"SimilarityScore\": score, \"Text\":allNegativeReviews[idx]}, ignore_index = True)\n",
        "\n",
        "  #end of for\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Number of unique Positive documents\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "dfSimTopicNeg.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "\n",
        "print(\"Number of unique Positive documents after droping duplicates\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents after droping duplicates\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "#Sampling 1000 positive and 1000 negatives\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos = dfSimTopicPos.iloc[0:1000, :]\n",
        "dfSimTopicNeg = dfSimTopicNeg.iloc[0:1000, :]\n",
        "\n",
        "#end Sampling 1000 positive and 1000 negatives\n",
        "\n",
        "\n",
        "print(\"Max Positive:\" , max(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Max Negatives:\" , max(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Min Positive:\" , min(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Min Negatives:\" , min(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Mean Positive:\", dfSimTopicPos[\"SimilarityScore\"].mean())\n",
        "print(\"Mean Negative:\", dfSimTopicNeg[\"SimilarityScore\"].mean())\n",
        "\n",
        "print(\"Std Positive:\",dfSimTopicPos[\"SimilarityScore\"].std())\n",
        "print(\"Std Negative:\",dfSimTopicNeg[\"SimilarityScore\"].std())\n",
        "\n",
        "\n",
        "print(\"len Positive:\" , len(dfSimTopicPos))\n",
        "print(\"len Negatives:\" , len(dfSimTopicNeg))\n",
        "\n",
        "dfAll8 = dfSimTopicNeg.append(dfSimTopicPos)\n",
        "dfAll8.to_csv(csvTopic8MostSimilar, header=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQT8TtiuFS9j"
      },
      "source": [
        "# Find the most similar docs tn = 20"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Di2OwCl9mS-Q"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "\n",
        "top_k = min(1000, len(allPositiveReviews))\n",
        "\n",
        "dfTopic20 = pd.read_csv(csvTopic20)\n",
        "print(dfTopic20.shape)\n",
        "dfTopic20 = dfTopic20.dropna()\n",
        "dfSimTopic20 = pd.DataFrame()\n",
        "keywordsTopic20 = []\n",
        "\n",
        "keywordsTopic20 = dfTopic20['Keywords']\n",
        "\n",
        "dfSimTopicPos = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorPos = np.zeros(768)\n",
        "\n",
        "dfSimTopicNeg = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorNeg = np.zeros(768)\n",
        "\n",
        "\n",
        "\n",
        "for item in keywordsTopic20 :\n",
        "  item = item.replace('[','')\n",
        "  item = item.replace(']','') \n",
        "  item = item.replace(\"'\",'')\n",
        "  item = item.replace(\",\",'')\n",
        "  inferred_docvecPos = positiveModel.encode(item, convert_to_numpy=True)\n",
        "  inferred_docvecNeg = negativeModel.encode(item, convert_to_numpy=True)\n",
        "\n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecPos, positiveEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicPos = dfSimTopicPos.append({\"docid\": idx, \"SimilarityScore\": score, \"Text\":allPositiveReviews[idx]}, ignore_index = True)\n",
        "        \n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecNeg, negativeEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicNeg = dfSimTopicNeg.append({\"docid\": idx + 283300, \"SimilarityScore\": score, \"Text\":allNegativeReviews[idx]}, ignore_index = True)\n",
        "\n",
        "\n",
        "\n",
        "  #end of for\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Number of unique Positive documents\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "dfSimTopicNeg.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "\n",
        "print(\"Number of unique Positive documents after droping duplicates\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents after droping duplicates\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "#Sampling 1000 positive and 1000 negatives\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos = dfSimTopicPos.iloc[0:1000, :]\n",
        "dfSimTopicNeg = dfSimTopicNeg.iloc[0:1000, :]\n",
        "\n",
        "#end Sampling 1000 positive and 1000 negatives\n",
        "\n",
        "\n",
        "print(\"Max Positive:\" , max(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Max Negatives:\" , max(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Min Positive:\" , min(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Min Negatives:\" , min(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Mean Positive:\", dfSimTopicPos[\"SimilarityScore\"].mean())\n",
        "print(\"Mean Positive:\", dfSimTopicNeg[\"SimilarityScore\"].mean())\n",
        "\n",
        "print(\"Std Positive:\",dfSimTopicPos[\"SimilarityScore\"].std())\n",
        "print(\"Std Negative:\",dfSimTopicNeg[\"SimilarityScore\"].std())\n",
        "\n",
        "\n",
        "print(\"len Positive:\" , len(dfSimTopicPos))\n",
        "print(\"len Negatives:\" , len(dfSimTopicNeg))\n",
        "\n",
        "dfAll20 = dfSimTopicNeg.append(dfSimTopicPos)\n",
        "dfAll20.to_csv(csvTopic20MostSimilar, header=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyME1mZ5FUrl"
      },
      "source": [
        "# Find the most similar docs tn = 40"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJOS7VAImqiz"
      },
      "source": [
        "\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "\n",
        "top_k = min(1000, len(allPositiveReviews))\n",
        "dfTopic40 = pd.read_csv(csvTopic40)\n",
        "print(dfTopic40.shape)\n",
        "dfTopic40 = dfTopic40.dropna()\n",
        "dfSimTopic40 = pd.DataFrame()\n",
        "keywordsTopic40 = []\n",
        "\n",
        "keywordsTopic40 = dfTopic40['Keywords']\n",
        "\n",
        "dfSimTopicPos = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorPos = np.zeros(768)\n",
        "\n",
        "dfSimTopicNeg = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorNeg = np.zeros(768)\n",
        "\n",
        "\n",
        "\n",
        "for item in keywordsTopic40 :\n",
        "  item = item.replace('[','')\n",
        "  item = item.replace(']','') \n",
        "  item = item.replace(\"'\",'')\n",
        "  item = item.replace(\",\",'')\n",
        "  inferred_docvecPos = positiveModel.encode(item, convert_to_numpy=True)\n",
        "  inferred_docvecNeg = negativeModel.encode(item, convert_to_numpy=True)\n",
        "\n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecPos, positiveEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicPos = dfSimTopicPos.append({\"docid\": idx, \"SimilarityScore\": score, \"Text\":allPositiveReviews[idx]}, ignore_index = True)\n",
        "        \n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecNeg, negativeEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicNeg = dfSimTopicNeg.append({\"docid\": idx + 283300, \"SimilarityScore\": score, \"Text\":allNegativeReviews[idx]}, ignore_index = True)\n",
        "\n",
        "\n",
        "  #end of for\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Number of unique Positive documents\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "dfSimTopicNeg.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "\n",
        "print(\"Number of unique Positive documents after droping duplicates\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents after droping duplicates\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "#Sampling 1000 positive and 1000 negatives\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos = dfSimTopicPos.iloc[0:1000, :]\n",
        "dfSimTopicNeg = dfSimTopicNeg.iloc[0:1000, :]\n",
        "\n",
        "#end Sampling 1000 positive and 1000 negatives\n",
        "\n",
        "\n",
        "print(\"Max Positive:\" , max(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Max Negatives:\" , max(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Min Positive:\" , min(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Min Negatives:\" , min(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Mean Positive:\", dfSimTopicPos[\"SimilarityScore\"].mean())\n",
        "print(\"Mean Positive:\", dfSimTopicNeg[\"SimilarityScore\"].mean())\n",
        "\n",
        "print(\"Std Positive:\",dfSimTopicPos[\"SimilarityScore\"].std())\n",
        "print(\"Std Negative:\",dfSimTopicNeg[\"SimilarityScore\"].std())\n",
        "\n",
        "\n",
        "print(\"len Positive:\" , len(dfSimTopicPos))\n",
        "print(\"len Negatives:\" , len(dfSimTopicNeg))\n",
        "\n",
        "dfAll40 = dfSimTopicNeg.append(dfSimTopicPos)\n",
        "dfAll40.to_csv(csvTopic40MostSimilar, header=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDAPVn0mFWWU"
      },
      "source": [
        "# Find the most similar docs tn = 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7aDWFX-nB3f"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "\n",
        "top_k = min(1000, len(allPositiveReviews))\n",
        "\n",
        "dfTopic50 = pd.read_csv(csvTopic50)\n",
        "print(dfTopic50.shape)\n",
        "dfTopic50 = dfTopic50.dropna()\n",
        "dfSimTopic50 = pd.DataFrame()\n",
        "keywordsTopic50 = []\n",
        "\n",
        "keywordsTopic50 = dfTopic50['Keywords']\n",
        "\n",
        "dfSimTopicPos = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorPos = np.zeros(768)\n",
        "\n",
        "dfSimTopicNeg = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorNeg = np.zeros(768)\n",
        "\n",
        "\n",
        "\n",
        "for item in keywordsTopic50 :\n",
        "  item = item.replace('[','')\n",
        "  item = item.replace(']','') \n",
        "  item = item.replace(\"'\",'')\n",
        "  item = item.replace(\",\",'')\n",
        "  inferred_docvecPos = positiveModel.encode(item, convert_to_numpy=True)\n",
        "  inferred_docvecNeg = negativeModel.encode(item, convert_to_numpy=True)\n",
        "\n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecPos, positiveEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicPos = dfSimTopicPos.append({\"docid\": idx, \"SimilarityScore\": score, \"Text\":allPositiveReviews[idx]}, ignore_index = True)\n",
        "        \n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecNeg, negativeEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicNeg = dfSimTopicNeg.append({\"docid\": idx + 283300, \"SimilarityScore\": score, \"Text\":allNegativeReviews[idx]}, ignore_index = True)\n",
        "\n",
        "  #end of for\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Number of unique Positive documents\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "dfSimTopicNeg.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "\n",
        "print(\"Number of unique Positive documents after droping duplicates\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents after droping duplicates\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "#Sampling 1000 positive and 1000 negatives\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos = dfSimTopicPos.iloc[0:1000, :]\n",
        "dfSimTopicNeg = dfSimTopicNeg.iloc[0:1000, :]\n",
        "\n",
        "#end Sampling 1000 positive and 1000 negatives\n",
        "\n",
        "\n",
        "print(\"Max Positive:\" , max(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Max Negatives:\" , max(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Min Positive:\" , min(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Min Negatives:\" , min(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Mean Positive:\", dfSimTopicPos[\"SimilarityScore\"].mean())\n",
        "print(\"Mean Positive:\", dfSimTopicNeg[\"SimilarityScore\"].mean())\n",
        "\n",
        "print(\"Std Positive:\",dfSimTopicPos[\"SimilarityScore\"].std())\n",
        "print(\"Std Negative:\",dfSimTopicNeg[\"SimilarityScore\"].std())\n",
        "\n",
        "\n",
        "print(\"len Positive:\" , len(dfSimTopicPos))\n",
        "print(\"len Negatives:\" , len(dfSimTopicNeg))\n",
        "\n",
        "dfAll50 = dfSimTopicNeg.append(dfSimTopicPos)\n",
        "dfAll50.to_csv(csvTopic50MostSimilar, header=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9oj1SUTFYWm"
      },
      "source": [
        "# Find the most similar docs tn = 60"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3ktIBbvpYu7"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "\n",
        "top_k = min(1000, len(allPositiveReviews))\n",
        "\n",
        "\n",
        "dfTopic60 = pd.read_csv(csvTopic60)\n",
        "print(dfTopic60.shape)\n",
        "dfTopic60 = dfTopic60.dropna()\n",
        "dfSimTopic60 = pd.DataFrame()\n",
        "keywordsTopic60 = []\n",
        "\n",
        "keywordsTopic60 = dfTopic60['Keywords']\n",
        "\n",
        "dfSimTopicPos = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorPos = np.zeros(768)\n",
        "\n",
        "dfSimTopicNeg = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorNeg = np.zeros(768)\n",
        "\n",
        "\n",
        "\n",
        "for item in keywordsTopic60 :\n",
        "  item = item.replace('[','')\n",
        "  item = item.replace(']','') \n",
        "  item = item.replace(\"'\",'')\n",
        "  item = item.replace(\",\",'')\n",
        "  inferred_docvecPos = positiveModel.encode(item, convert_to_numpy=True)\n",
        "  inferred_docvecNeg = negativeModel.encode(item, convert_to_numpy=True)\n",
        "\n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecPos, positiveEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicPos = dfSimTopicPos.append({\"docid\": idx, \"SimilarityScore\": score, \"Text\":allPositiveReviews[idx]}, ignore_index = True)\n",
        "        \n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecNeg, negativeEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicNeg = dfSimTopicNeg.append({\"docid\": idx + 283300, \"SimilarityScore\": score, \"Text\":allNegativeReviews[idx]}, ignore_index = True)\n",
        "\n",
        "\n",
        "\n",
        "  #end of for\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Number of unique Positive documents\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "dfSimTopicNeg.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "\n",
        "print(\"Number of unique Positive documents after droping duplicates\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents after droping duplicates\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "#Sampling 1000 positive and 1000 negatives\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos = dfSimTopicPos.iloc[0:1000, :]\n",
        "dfSimTopicNeg = dfSimTopicNeg.iloc[0:1000, :]\n",
        "\n",
        "#end Sampling 1000 positive and 1000 negatives\n",
        "\n",
        "\n",
        "print(\"Max Positive:\" , max(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Max Negatives:\" , max(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Min Positive:\" , min(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Min Negatives:\" , min(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Mean Positive:\", dfSimTopicPos[\"SimilarityScore\"].mean())\n",
        "print(\"Mean Positive:\", dfSimTopicNeg[\"SimilarityScore\"].mean())\n",
        "\n",
        "print(\"Std Positive:\",dfSimTopicPos[\"SimilarityScore\"].std())\n",
        "print(\"Std Negative:\",dfSimTopicNeg[\"SimilarityScore\"].std())\n",
        "\n",
        "\n",
        "print(\"len Positive:\" , len(dfSimTopicPos))\n",
        "print(\"len Negatives:\" , len(dfSimTopicNeg))\n",
        "\n",
        "dfAll60 = dfSimTopicNeg.append(dfSimTopicPos)\n",
        "dfAll60.to_csv(csvTopic60MostSimilar, header=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mye0KNDdFZm4"
      },
      "source": [
        "# Find the most similar docs tn = 65"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OM4bWg5aprEW"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "\n",
        "top_k = min(1000, len(allPositiveReviews))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "dfTopic65 = pd.read_csv(csvTopic65)\n",
        "print(dfTopic65.shape)\n",
        "dfTopic65 = dfTopic65.dropna()\n",
        "dfSimTopic65 = pd.DataFrame()\n",
        "keywordsTopic65 = []\n",
        "\n",
        "keywordsTopic65 = dfTopic65['Keywords']\n",
        "\n",
        "dfSimTopicPos = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorPos = np.zeros(768)\n",
        "\n",
        "dfSimTopicNeg = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorNeg = np.zeros(768)\n",
        "\n",
        "\n",
        "\n",
        "for item in keywordsTopic65 :\n",
        "  item = item.replace('[','')\n",
        "  item = item.replace(']','') \n",
        "  item = item.replace(\"'\",'')\n",
        "  item = item.replace(\",\",'')\n",
        "  inferred_docvecPos = positiveModel.encode(item, convert_to_numpy=True)\n",
        "  inferred_docvecNeg = negativeModel.encode(item, convert_to_numpy=True)\n",
        "\n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecPos, positiveEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicPos = dfSimTopicPos.append({\"docid\": idx, \"SimilarityScore\": score, \"Text\":allPositiveReviews[idx]}, ignore_index = True)\n",
        "        \n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecNeg, negativeEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicNeg = dfSimTopicNeg.append({\"docid\": idx + 283300, \"SimilarityScore\": score, \"Text\":allNegativeReviews[idx]}, ignore_index = True)\n",
        "\n",
        "\n",
        "\n",
        "  #end of for\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Number of unique Positive documents\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "dfSimTopicNeg.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "\n",
        "print(\"Number of unique Positive documents after droping duplicates\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents after droping duplicates\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "#Sampling 1000 positive and 1000 negatives\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos = dfSimTopicPos.iloc[0:1000, :]\n",
        "dfSimTopicNeg = dfSimTopicNeg.iloc[0:1000, :]\n",
        "\n",
        "#end Sampling 1000 positive and 1000 negatives\n",
        "\n",
        "\n",
        "print(\"Max Positive:\" , max(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Max Negatives:\" , max(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Min Positive:\" , min(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Min Negatives:\" , min(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Mean Positive:\", dfSimTopicPos[\"SimilarityScore\"].mean())\n",
        "print(\"Mean Positive:\", dfSimTopicNeg[\"SimilarityScore\"].mean())\n",
        "\n",
        "print(\"Std Positive:\",dfSimTopicPos[\"SimilarityScore\"].std())\n",
        "print(\"Std Negative:\",dfSimTopicNeg[\"SimilarityScore\"].std())\n",
        "\n",
        "\n",
        "print(\"len Positive:\" , len(dfSimTopicPos))\n",
        "print(\"len Negatives:\" , len(dfSimTopicNeg))\n",
        "\n",
        "dfAll65 = dfSimTopicNeg.append(dfSimTopicPos)\n",
        "dfAll65.to_csv(csvTopic65MostSimilar, header=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RHcSo4-Fa_a"
      },
      "source": [
        "# Find the most similar docs tn = 70"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgopwngQqKuk"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "\n",
        "top_k = min(500, len(allPositiveReviews))\n",
        "\n",
        "dfTopic70 = pd.read_csv(csvTopic70)\n",
        "print(dfTopic70.shape)\n",
        "dfTopic70 = dfTopic70.dropna()\n",
        "dfSimTopic70 = pd.DataFrame()\n",
        "keywordsTopic70 = []\n",
        "\n",
        "keywordsTopic70 = dfTopic70['Keywords']\n",
        "\n",
        "dfSimTopicPos = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorPos = np.zeros(768)\n",
        "\n",
        "dfSimTopicNeg = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorNeg = np.zeros(768)\n",
        "\n",
        "\n",
        "\n",
        "for item in keywordsTopic70 :\n",
        "  item = item.replace('[','')\n",
        "  item = item.replace(']','') \n",
        "  item = item.replace(\"'\",'')\n",
        "  item = item.replace(\",\",'')\n",
        "  inferred_docvecPos = positiveModel.encode(item, convert_to_numpy=True)\n",
        "  inferred_docvecNeg = negativeModel.encode(item, convert_to_numpy=True)\n",
        "\n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecPos, positiveEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicPos = dfSimTopicPos.append({\"docid\": idx, \"SimilarityScore\": score, \"Text\":allPositiveReviews[idx]}, ignore_index = True)\n",
        "        \n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecNeg, negativeEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicNeg = dfSimTopicNeg.append({\"docid\": idx + 283300, \"SimilarityScore\": score, \"Text\":allNegativeReviews[idx]}, ignore_index = True)\n",
        "\n",
        "\n",
        "\n",
        "  #end of for\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Number of unique Positive documents\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "dfSimTopicNeg.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "\n",
        "print(\"Number of unique Positive documents after droping duplicates\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents after droping duplicates\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "#Sampling 1000 positive and 1000 negatives\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos = dfSimTopicPos.iloc[0:1000, :]\n",
        "dfSimTopicNeg = dfSimTopicNeg.iloc[0:1000, :]\n",
        "\n",
        "#end Sampling 1000 positive and 1000 negatives\n",
        "\n",
        "\n",
        "print(\"Max Positive:\" , max(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Max Negatives:\" , max(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Min Positive:\" , min(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Min Negatives:\" , min(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Mean Positive:\", dfSimTopicPos[\"SimilarityScore\"].mean())\n",
        "print(\"Mean Positive:\", dfSimTopicNeg[\"SimilarityScore\"].mean())\n",
        "\n",
        "print(\"Std Positive:\",dfSimTopicPos[\"SimilarityScore\"].std())\n",
        "print(\"Std Negative:\",dfSimTopicNeg[\"SimilarityScore\"].std())\n",
        "\n",
        "\n",
        "print(\"len Positive:\" , len(dfSimTopicPos))\n",
        "print(\"len Negatives:\" , len(dfSimTopicNeg))\n",
        "\n",
        "dfAll70 = dfSimTopicNeg.append(dfSimTopicPos)\n",
        "dfAll70.to_csv(csvTopic70MostSimilar, header=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAWPmqdjFcjw"
      },
      "source": [
        "# Find the most similar docs tn = 80"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6Fvh6CmqjbE"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "\n",
        "top_k = min(500, len(allPositiveReviews))\n",
        "\n",
        "\n",
        "\n",
        "dfTopic80 = pd.read_csv(csvTopic80)\n",
        "print(dfTopic80.shape)\n",
        "dfTopic80 = dfTopic80.dropna()\n",
        "dfSimTopic80 = pd.DataFrame()\n",
        "keywordsTopic80 = []\n",
        "\n",
        "keywordsTopic80 = dfTopic80['Keywords']\n",
        "\n",
        "dfSimTopicPos = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorPos = np.zeros(768)\n",
        "\n",
        "dfSimTopicNeg = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorNeg = np.zeros(768)\n",
        "\n",
        "\n",
        "\n",
        "for item in keywordsTopic80 :\n",
        "  item = item.replace('[','')\n",
        "  item = item.replace(']','') \n",
        "  item = item.replace(\"'\",'')\n",
        "  item = item.replace(\",\",'')\n",
        "  inferred_docvecPos = positiveModel.encode(item, convert_to_numpy=True)\n",
        "  inferred_docvecNeg = negativeModel.encode(item, convert_to_numpy=True)\n",
        "\n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecPos, positiveEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicPos = dfSimTopicPos.append({\"docid\": idx, \"SimilarityScore\": score, \"Text\":allPositiveReviews[idx]}, ignore_index = True)\n",
        "        \n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecNeg, negativeEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicNeg = dfSimTopicNeg.append({\"docid\": idx + 283300, \"SimilarityScore\": score, \"Text\":allNegativeReviews[idx]}, ignore_index = True)\n",
        "\n",
        "\n",
        "\n",
        "print(\"end of for\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Number of unique Positive documents\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "dfSimTopicNeg.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "\n",
        "print(\"Number of unique Positive documents after droping duplicates\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents after droping duplicates\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "#Sampling 1000 positive and 1000 negatives\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos = dfSimTopicPos.iloc[0:1000, :]\n",
        "dfSimTopicNeg = dfSimTopicNeg.iloc[0:1000, :]\n",
        "\n",
        "#end Sampling 1000 positive and 1000 negatives\n",
        "\n",
        "\n",
        "print(\"Max Positive:\" , max(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Max Negatives:\" , max(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Min Positive:\" , min(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Min Negatives:\" , min(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Mean Positive:\", dfSimTopicPos[\"SimilarityScore\"].mean())\n",
        "print(\"Mean Positive:\", dfSimTopicNeg[\"SimilarityScore\"].mean())\n",
        "\n",
        "print(\"Std Positive:\",dfSimTopicPos[\"SimilarityScore\"].std())\n",
        "print(\"Std Negative:\",dfSimTopicNeg[\"SimilarityScore\"].std())\n",
        "\n",
        "\n",
        "print(\"len Positive:\" , len(dfSimTopicPos))\n",
        "print(\"len Negatives:\" , len(dfSimTopicNeg))\n",
        "\n",
        "dfAll80 = dfSimTopicNeg.append(dfSimTopicPos)\n",
        "dfAll80.to_csv(csvTopic80MostSimilar, header=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}