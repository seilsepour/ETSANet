{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "lwb4Ph9h9Na3",
        "RiYTcq6lW7ey",
        "eOk_44PcXC2_",
        "h6CrLAr2XY-q",
        "JiPH8WllUkFp",
        "nwVW1N2p_sER",
        "8cT9nGB9-6lp",
        "viMDe0U9XlHt"
      ]
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This Module is responsible for:\n",
        " \n",
        "\n",
        "*   Finding the best number of topics using Coherence Value\n",
        "\n",
        "*   Performing the LDA\n",
        "\n",
        "\n",
        "*   Saving topics\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tE_7jdqqr8V9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwb4Ph9h9Na3"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLhtaspD-vhl"
      },
      "source": [
        "pip install pyLDAvis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFnu4UiB9QGp"
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "\n",
        "# Gensim\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "\n",
        "# spacy for lemmatization\n",
        "import spacy\n",
        "\n",
        "# Plotting tools\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim  # don't skip this\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Enable logging for gensim - optional\n",
        "import logging\n",
        "#logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiYTcq6lW7ey"
      },
      "source": [
        "## Configurations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSc3eEj9UkEX"
      },
      "source": [
        "#DEFAULT_SAVING_PATH = 'D:\\\\Jupyter notebooks\\\\Twitter-Gensim-LDA-Labelling-WE-Edited2\\\\'\n",
        "#DATASET_PATH = 'D:\\\\Jupyter notebooks\\\\Twitter-Gensim-LDA-Labelling-WE-Edited2\\\\dataset-USA-stream.xlsx'\n",
        "DEFAULT_SAVING_PATH = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/'\n",
        "OUTPUT_PATH = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/'\n",
        "#BIGRAM_PKL = 'Output\\\\bigram-uk-2000.pkl'\n",
        "#TRIGRAM_PKL = 'Output\\\\trigram-uk-2000.pkl'\n",
        "TOPICS_PKL = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/topics-MR80.pkl'\n",
        "#TRIGRAM_OUTPUT = 'Output\\\\trigrams.csv'\n",
        "#BIGRAM_OUTPUT = 'Output\\\\bigrams.csv'\n",
        "TOP_WORDS_OUTPUT = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/toptweetwords-MR80.csv'\n",
        "T_K_D = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/topkd-MR80.csv'\n",
        "\n",
        "LDA_MODEL = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/model-MR.gensim'\n",
        "DIC_PATH = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/dictionary-MR.gensim'\n",
        "CORPUS_PATH = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/corpus-MR.pkl'\n",
        "LDA_TOPICS = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/lda-topics-MR80.csv'\n",
        "\n",
        "\n",
        "\n",
        "PREPROCESSED_TWEETS1 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/movie-pang-processed-98-12-08.csv'\n",
        "\n",
        "\n",
        "NUM_TOPICS = 80\n",
        "NUM_WORDS = 10\n",
        "'''\n",
        "IN moteghayer moshakhas minamayad ke yek topic bayad dar che \n",
        "tedad doc vojud dashte bashad ta be onvane topice mohem ghalamdad shavad\n",
        "'''\n",
        "NUM_TOPIC_DOC = 50\n",
        "NUM_IMPORTANT_TOPICS = 100\n",
        "TWEET_CONTENT_LIMIT = 50\n",
        "\n",
        "\n",
        "TWEET_CONTENT = 'Tweet content'\n",
        "TWEET_LANG = 'lang'\n",
        "TWEET_ID = 'Tweet Id'\n",
        "TWEET_FOLLOWERS = 'Followers'\n",
        "TWEET_FOLLOWING = 'Following'\n",
        "TWEET_FAVS = 'Favs'\n",
        "TWEET_RTS = 'RTs'\n",
        "TWEET_LISTED = 'Listed'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_J3O_I0UkE4"
      },
      "source": [
        "import pprint\n",
        "import csv\n",
        "import time\n",
        "from gensim import corpora, models, similarities\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from itertools import chain\n",
        "from collections import Counter\n",
        "import spacy\n",
        "import gensim, logging\n",
        "from time import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "from gensim.models import Word2Vec\n",
        "import pickle\n",
        "\n",
        "import nltk\n",
        "from nltk.collocations import *\n",
        "\n",
        "from gensim.models import Phrases\n",
        "from gensim.models.phrases import Phraser\n",
        "\n",
        "\n",
        "#logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsH5WnWwW3Bb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/MYDRIVE', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOk_44PcXC2_"
      },
      "source": [
        "## Loading Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8k_5BSqUkFG"
      },
      "source": [
        "#Getting Ready for LDA\n",
        "print(\"Getting Ready for LDA\")\n",
        "print(\"Loading preprocessed tweets\")\n",
        "dfPreprocessedTweets = pd.read_csv(PREPROCESSED_TWEETS1, header=None)\n",
        "print(\"The preprocessed tweets were loaded\")\n",
        "print(\"The shape of dataframe is\", dfPreprocessedTweets.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEfl1M2zp2vR"
      },
      "source": [
        "dfPreprocessedTweets.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xks-FKkym0N"
      },
      "source": [
        "dfPreprocessedTweets.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBPxSRyCyq3E"
      },
      "source": [
        "dfPreprocessedTweets = dfPreprocessedTweets.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWzsAIgyy0uh"
      },
      "source": [
        "dfPreprocessedTweets.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXiAh9liZfrA"
      },
      "source": [
        "PREPROCESSED_TWEETS1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6CrLAr2XY-q"
      },
      "source": [
        "## Making list before LDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yN8W0Mo0ppFr",
        "outputId": "2223c9e7-0cd4-4df3-cff8-1002d0fe1819",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "tweet_content = []\n",
        "print(\"Converting dataframe to array\")\n",
        "for row in dfPreprocessedTweets.itertuples(index=False):\n",
        "    tweet_content.append(row[1])\n",
        "print(\"Converting is done successfully\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converting dataframe to array\n",
            "Converting is done successfully\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yoedznOsaHq"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcWsAM3fzzgr"
      },
      "source": [
        "tweet_content = [d.split() for d in tweet_content]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiPH8WllUkFp"
      },
      "source": [
        "## LDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7nVjCAJq1LT",
        "outputId": "e09f1167-8b01-4c48-96da-f223854107dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "DIC_PATH"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/dictionary-MR.gensim'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vqhPvrIrNSW",
        "outputId": "5fdb50c1-cc73-4613-ce9c-19713458dcee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "CORPUS_PATH"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/corpus-MR.pkl'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8W-DZ8b6UkFt",
        "outputId": "7ce5ad25-7a8a-4eb1-e464-e49ad8590e0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "print(\"Creating dictionary...\")\n",
        "dictionary = corpora.Dictionary(tweet_content)\n",
        "print(\"Saving dictionary...\")\n",
        "dictionary.save( DIC_PATH )\n",
        "print(\"Creating corpus...\")\n",
        "corpus = [dictionary.doc2bow(text) for text in tweet_content]\n",
        "print(\"Saving corpus\")\n",
        "pickle.dump(corpus, open( CORPUS_PATH , 'wb'))\n",
        "print(\"Corpus saved\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating dictionary...\n",
            "Saving dictionary...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Creating corpus...\n",
            "Saving corpus\n",
            "Corpus saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwVW1N2p_sER"
      },
      "source": [
        "## Get the best topic number"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdBMAdkB_v4J"
      },
      "source": [
        "def compute_coherence_values(dictionary, corpus, texts, limit=120, start=5, step=5):\n",
        "    \"\"\"\n",
        "    Compute c_v coherence for various number of topics\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    dictionary : Gensim dictionary\n",
        "    corpus : Gensim corpus\n",
        "    texts : List of input texts\n",
        "    limit : Max num of topics\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    model_list : List of LDA topic models\n",
        "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
        "    \"\"\"\n",
        "    coherence_values = []\n",
        "    model_list = []\n",
        "    perplexity_values = []\n",
        "    for num_topics in range(start, limit, step):\n",
        "        #model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
        "        model = models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                    id2word=dictionary, \n",
        "                                    iterations=200, \n",
        "                                    num_topics=num_topics,\n",
        "                                    update_every=1,\n",
        "                                    chunksize=100,\n",
        "                                    passes=20,\n",
        "                                    alpha='auto',\n",
        "                                    per_word_topics=True)\n",
        "        model_list.append(model)\n",
        "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "        coherence_values.append(coherencemodel.get_coherence())\n",
        "        perplexity_values.append(model.log_perplexity(corpus))\n",
        "    return model_list, coherence_values, perplexity_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waKGlU_H_0zD"
      },
      "source": [
        "# Can take a long time to run.\n",
        "limit=120; start=5; step=5;\n",
        "model_list, coherence_values, perplexity_values  = compute_coherence_values(dictionary=dictionary, corpus=corpus, texts=tweet_content, start=start, limit=limit, step=step)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_12gaO5x_8Ib"
      },
      "source": [
        "# Show graph\n",
        "\n",
        "x = range(start, limit, step)\n",
        "plt.plot(x, coherence_values)\n",
        "plt.xlabel(\"Number of topics\")\n",
        "plt.ylabel(\"Coherence score\")\n",
        "plt.legend((\"coherence_values\"), loc='best')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zu2ozUJACPV"
      },
      "source": [
        "# Print the coherence scores\n",
        "i = 0\n",
        "for m, cv, pe in zip(x, coherence_values, perplexity_values):\n",
        "    #print(i)\n",
        "    print(i, \" Num Topics =\", m, \" has Coherence Value of\", round(cv, 4), \" and Perplexity of\", round(pe,4))\n",
        "    i = i + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMRorcCdYtRD"
      },
      "source": [
        "NUM_TOPICS = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZjntFV0YkTl"
      },
      "source": [
        "lda_model = models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                    id2word=dictionary, \n",
        "                                    iterations=200, \n",
        "                                    num_topics=NUM_TOPICS,\n",
        "                                    update_every=1,\n",
        "                                    chunksize=100,\n",
        "                                    passes=20,\n",
        "                                    alpha='auto',\n",
        "                                    per_word_topics=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cT9nGB9-6lp"
      },
      "source": [
        "##Topics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TW-5ynFc5hh1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "7b45a65c-bb76-4fcd-ea81-a04c13a234d5"
      },
      "source": [
        "len(lda_model.get_topics())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRaGp1gd83ms",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "87c0ec6d-2fb0-4929-8c90-b1aec2673f27"
      },
      "source": [
        "len(lda_model.show_topics(num_topics=64))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJyrXsCSZO7I"
      },
      "source": [
        "from pprint import pprint\n",
        "\n",
        "model_topics = lda_model.show_topics(formatted=False)\n",
        "pprint(lda_model.print_topics(num_words=10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmAjnH6V_PDC"
      },
      "source": [
        "# Visualize the topics\n",
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary)\n",
        "vis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alzjWIRSv1gn",
        "outputId": "17920112-0acb-4b15-d179-bf645d22eb71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "LDA_MODEL"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/model-MR.gensim'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCgnxhSX39vh",
        "outputId": "7d3623c2-65a1-49fb-c6e3-e7e28af058b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        }
      },
      "source": [
        "lda_model.save( LDA_MODEL )\n",
        "t1 = time()\n",
        "print(\"Building and saving model took: \" )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building and saving model took: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76z2P6VQUkGM"
      },
      "source": [
        "topics = lda_model.print_topics(num_topics=80)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aM3lArqQH7cz"
      },
      "source": [
        "#saving topics without text\n",
        "topic_words = []\n",
        "topics_df = pd.DataFrame()\n",
        "for i in range(64):\n",
        "    wp = lda_model.show_topic(i)\n",
        "    topic_keywords = \", \".join([word for word, prop in wp])\n",
        "    #tt = lda_model.get_topic_terms(i,10)\n",
        "    #topics_df = topics_df.append(pd.Series([i,  [dictionary[pair[0]] for pair in tt]]), ignore_index=True)\n",
        "    topics_df = topics_df.append(pd.Series([i,  topic_keywords]), ignore_index=True)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuZiUnoQJXF8"
      },
      "source": [
        "topics_df.to_csv('/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/topkd-MR64.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viMDe0U9XlHt"
      },
      "source": [
        "## Saving topics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yawgiufiXjWD",
        "outputId": "e55f5cda-fe20-4d1d-c319-451a6eaf4e2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "with open( TOPICS_PKL , 'wb') as to:\n",
        "    pickle.dump( topics , to)\n",
        "\n",
        "print(\"Topics saved\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topics saved\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}