{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "kuu6z-ZZoZHq",
        "QmK-tAmXydXh",
        "S2kue_J3ls55",
        "jyxXR41GIsLN",
        "w-S1wuAojt6G",
        "pDJllF_IIzKf",
        "qVjIzwqtwQ1Z",
        "cGQg6jO0DCLK",
        "zszrHKMx9FtI",
        "2W0WIixKknnR",
        "rQT8TtiuFS9j",
        "vlTK301VmNEQ",
        "OyME1mZ5FUrl",
        "W4uds5a2mnRA",
        "56EvLlCTnCQm",
        "n9oj1SUTFYWm",
        "ztOulH6Ro7-D",
        "Mye0KNDdFZm4",
        "4HoypU0FprVy",
        "7RHcSo4-Fa_a",
        "5IiNt4D-qK83",
        "22xOChv1qjl-"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5Fp4PNOzHf6"
      },
      "source": [
        "https://radimrehurek.com/gensim/auto_examples/howtos/run_doc2vec_imdb.html\n",
        "\n",
        "https://radimrehurek.com/gensim/models/doc2vec.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuu6z-ZZoZHq"
      },
      "source": [
        "## Configurations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbkcv3irn-mi"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf6N4pe_oSu6"
      },
      "source": [
        "import logging\n",
        "#logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOZnc3w7CA9Y"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gensim\n",
        "from sklearn.model_selection import train_test_split\n",
        "import multiprocessing\n",
        "from collections import OrderedDict\n",
        "\n",
        "import gensim.models.doc2vec\n",
        "assert gensim.models.doc2vec.FAST_VERSION > -1, \"This will be painfully slow otherwise\"\n",
        "\n",
        "from gensim.models.doc2vec import Doc2Vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxGpI5Zq6IQl"
      },
      "source": [
        "pip install testfixtures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GiKOztIlqIP"
      },
      "source": [
        "import collections\n",
        "\n",
        "SentimentDocument = collections.namedtuple('SentimentDocument', 'words tags split sentiment')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0FG4Qzc_bYD"
      },
      "source": [
        "inputFileName = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Processed-Merged-Dataset-99-08-28.csv'\n",
        "\n",
        "\n",
        "outputLabelledTTDS= '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Balenced-Dataset-00-06-26.csv'\n",
        "outputDocsFileName = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/DocsReadyForD2V-00-06-26.csv'\n",
        "\n",
        "d2vModelFNmPos = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModelPositive-00-06-26.model'\n",
        "d2vModelFNtPos = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModelPositive-00-06-26.txt'\n",
        "\n",
        "d2vModelFNmNeg = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModelNegative-00-06-26.model'\n",
        "d2vModelFNtNeg = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModelNegative-00-06-26.txt'\n",
        "\n",
        "csvTopic8 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Topics_8.csv'\n",
        "csvTopic20 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Topics_20.csv'\n",
        "csvTopic40 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Topics_40.csv'\n",
        "csvTopic80 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Topics_80.csv'\n",
        "csvTopic50 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Topics_50.csv'\n",
        "csvTopic60 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Topics_60.csv'\n",
        "csvTopic65 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Topics_65.csv'\n",
        "csvTopic70 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Topics_70.csv'\n",
        "\n",
        "\n",
        "d2vModelFNm0 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModel0-00-06-23.model'\n",
        "d2vModelFNt0 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModel0-00-06-23.txt'\n",
        "\n",
        "d2vModelFNm1 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModel1-00-06-23.model'\n",
        "d2vModelFNt1 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModel1-00-06-23.txt'\n",
        "\n",
        "d2vModelFNm2 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModel2-00-06-23.model'\n",
        "d2vModelFNt2 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModel2-00-06-23.txt'\n",
        "\n",
        "d2vModelFNm3 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModel3-00-06-23.model'\n",
        "d2vModelFNt3 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModel3-00-06-23.txt'\n",
        "\n",
        "csvTopic8MostSimilar = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/SimilarDocsByCosine/Topics_8_MostSimilar_cs.csv'\n",
        "csvTopic20MostSimilar = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/SimilarDocsByCosine/Topics_20_MostSimilar_cs.csv'\n",
        "csvTopic40MostSimilar = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/SimilarDocsByCosine/Topics_40_MostSimilar_cs.csv'\n",
        "csvTopic50MostSimilar = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/SimilarDocsByCosine/Topics_50_MostSimilar_cs.csv'\n",
        "csvTopic60MostSimilar = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/SimilarDocsByCosine/Topics_60_MostSimilar_cs.csv'\n",
        "csvTopic65MostSimilar = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/SimilarDocsByCosine/Topics_65_MostSimilar_cs.csv'\n",
        "csvTopic70MostSimilar = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/SimilarDocsByCosine/Topics_70_MostSimilar_cs.csv'\n",
        "csvTopic80MostSimilar = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/SimilarDocsByCosine/Topics_80_MostSimilar_cs.csv'\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVI5vELQ6KA8"
      },
      "source": [
        "def create_sentiment_document(index, tex, sent, sp):\n",
        "    #_, split, sentiment_str, _ = name.split('/')\n",
        "    #sentiment = {'pos': 1.0, 'neg': 0.0, 'unsup': None}[sentiment_str]\n",
        "\n",
        "    #if sentiment is None:\n",
        "        #split = 'extra'\n",
        "    #print(tex)\n",
        "    tokens = gensim.utils.to_unicode(tex).split()\n",
        "    #tokens = gensim.utils.sp\n",
        "    return SentimentDocument(tokens, [index], sp, sent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiSEEeOX5UxO"
      },
      "source": [
        "# Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-ztS1ZQ_5Xz"
      },
      "source": [
        "#No need in local\n",
        "from google.colab import drive\n",
        "drive.mount('/MYDRIVE', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmK-tAmXydXh"
      },
      "source": [
        "# Prepair Dataset (Dividing into Test and Train)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9N4Y2ry_9yW"
      },
      "source": [
        "dfReviews = pd.DataFrame()\n",
        "dfReviews = pd.read_csv(inputFileName, encoding = 'utf-8', header = None )\n",
        "dfReviews.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5k6XdrymFqu"
      },
      "source": [
        "inputFileName"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKonEE_yHIW2"
      },
      "source": [
        "dfReviews.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0b20GkvxEm1"
      },
      "source": [
        "dfReviews = dfReviews.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pL4BWFkNxJdr"
      },
      "source": [
        "dfReviews.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQFrAAjUHpAu"
      },
      "source": [
        "len (dfReviews.loc[dfReviews[3] == 0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RcaSW8uISBH"
      },
      "source": [
        "len (dfReviews.loc[dfReviews[3] == 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leTzHA-2aH88"
      },
      "source": [
        "dfReviews[4] = 'train'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8bMsPoClaLT"
      },
      "source": [
        "dfReviews.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFWPmH-nleBf"
      },
      "source": [
        "dfReviews.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWjQ6aA7bDwI"
      },
      "source": [
        "testNumber=113320\n",
        "trainNumber=453280"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29IU7Y7x98VK"
      },
      "source": [
        "#Making a copy of All REVIEWS\n",
        "dfReviews2 = dfReviews"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0ro4cAJapmc"
      },
      "source": [
        "#Selecting 500,000 records from alol reviews (250,000 positive and 250,000 negative) to make a balanced dataset\n",
        "dfTemp1 = dfReviews[dfReviews[3] == 1].sample( n = 283300)\n",
        "dfTemp2 = dfReviews[dfReviews[3] == 0].sample( n = 283300)\n",
        "dfTemp = dfTemp1.append(dfTemp2)\n",
        "print( \"length of dfTemp \" + str( len (dfTemp) ))\n",
        "print(len(dfTemp[dfTemp[3]==0]))\n",
        "print(len(dfTemp[dfTemp[3]==1]))\n",
        "dfReviews = dfTemp\n",
        "dfTest = dfTemp[dfTemp[3] == 0].sample( n = 56660)\n",
        "dfTest = dfTest.append(dfTemp[dfTemp[3] == 1].sample( n = 56660))\n",
        "print( \"length of dfTest \" + str( len (dfTest) ) )\n",
        "print(len(dfTest[dfTest[3]==0]))\n",
        "print(len(dfTest[dfTest[3]==1]))\n",
        "\n",
        "print( \"length of dfReviews \" + str( len (dfReviews) ) )\n",
        "print(len(dfReviews[dfReviews[3]==0]))\n",
        "print(len(dfReviews[dfReviews[3]==1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qwbWSXQb030"
      },
      "source": [
        "dfTest.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3yqMuY_GLNF"
      },
      "source": [
        "dfReviews.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1EBK1aVwvKa"
      },
      "source": [
        "len (dfReviews.loc[dfReviews[4] == 'train'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2_sBD-wINy6"
      },
      "source": [
        "len (dfReviews.loc[dfReviews[4] == 'test'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCylZNA_sOF1"
      },
      "source": [
        "dfReviews.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gWOSC8UJWnI"
      },
      "source": [
        "len(dfTest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "My4boAOIBe5p"
      },
      "source": [
        "testRows = dfTest[1]\n",
        "type(testRows)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbwZfamADMFl"
      },
      "source": [
        "testRows"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6Zl3z6SGpZB"
      },
      "source": [
        "len(testRows)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgKSpNH_FqZz"
      },
      "source": [
        "type(dfReviews)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2kue_J3ls55"
      },
      "source": [
        "# Preparing test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zy3JCICyLt-U"
      },
      "source": [
        "dfReviews.loc[dfReviews[1].isin(testRows),4] = 'test'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZg0r0wXmQsf"
      },
      "source": [
        "dfReviews.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7kCeO1SnSFD"
      },
      "source": [
        "len (dfReviews.loc[dfReviews[4] == 'test'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhD8QBUdnS8L"
      },
      "source": [
        "len (dfReviews.loc[dfReviews[4] == 'train'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0htx1J2pTPce"
      },
      "source": [
        "print( \"length of dfReviews \" + str( len (dfReviews) ) )\n",
        "print(len(dfReviews[dfReviews[3]==0]))\n",
        "print(len(dfReviews[dfReviews[3]==1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iidH4sUiMSG5"
      },
      "source": [
        "dfReviews.iloc[238937,4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUXrz6inAcfU"
      },
      "source": [
        "print( \"length of dfReviews \" + str( len (dfReviews) ) )\n",
        "print(len(dfReviews[dfReviews[3]==0]))\n",
        "print(len(dfReviews[dfReviews[3]==1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPU7797PAum3"
      },
      "source": [
        "print( \"length of dfReviews \" + str( len (dfReviews) ) )\n",
        "print(len(dfReviews[dfReviews[4]=='test']))\n",
        "print(len(dfReviews[dfReviews[4]=='train']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJB-DzIPqSS4"
      },
      "source": [
        "dfReviews.sample(n=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-cxmhismuwV"
      },
      "source": [
        "dfReviews.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLtbXrvysYm4"
      },
      "source": [
        "dfReviews.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsPcBccIqWAf"
      },
      "source": [
        "dfReviews.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD8mDCZOuwHz"
      },
      "source": [
        "dfReviews.drop(columns=[0,1], inplace= True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJnN29v5u6Hz"
      },
      "source": [
        "dfReviews.columns = ['Text', 'Sentiment', 'Type']\n",
        "dfReviews.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeiIsboxTfEY"
      },
      "source": [
        "print( \"length of dfReviews \" + str( len (dfReviews) ) )\n",
        "print(len(dfReviews[dfReviews['Sentiment']==0]))\n",
        "print(len(dfReviews[dfReviews['Sentiment']==1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyxXR41GIsLN"
      },
      "source": [
        "# Save the divided dataset into csv file\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xzLaZRyvvIE"
      },
      "source": [
        "dfReviews.to_csv( outputLabelledTTDS, header=True, index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voiAjBBhk7rb"
      },
      "source": [
        "outputLabelledTTDS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPoYOJQ0Npe0"
      },
      "source": [
        "dfReviews.sample(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-S1wuAojt6G"
      },
      "source": [
        "## Load Saved LabelledTTDS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8R-JQlTrjsGQ"
      },
      "source": [
        "#dfReviews = pd.read_csv(outputLabelledTTDS, header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3B5I6MGksMU"
      },
      "source": [
        "len(dfReviews)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyOjFMYplDoz"
      },
      "source": [
        "dfReviews.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDJllF_IIzKf"
      },
      "source": [
        "# Make the big list of sentiment and doc to be learned by Doc2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYRCC4peOc6A"
      },
      "source": [
        "allDocs = list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADeKzhZiQlcx"
      },
      "source": [
        "dfReviews.sample(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7yynGrJLO1k"
      },
      "source": [
        "i=0\n",
        "for index , row in dfReviews.iterrows():\n",
        "  allDocs.append(  create_sentiment_document( (index) , (row[\"Text\"]) , (row[\"Sentiment\"]) , row[\"Type\"] ) )\n",
        "  #allDocs.append(  create_sentiment_document( (index) , (row[2]) , (row[3]) , row[4] ) )\n",
        "  i = i + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTcrPx_mOk60"
      },
      "source": [
        "len(allDocs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZsfRHeKJ74I"
      },
      "source": [
        "allDocs[500]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vU-P_PKEzzl"
      },
      "source": [
        "dfReviews.loc[500]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3X2DGgJSZeh"
      },
      "source": [
        "len(allDocs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojX6HTVBuZyG"
      },
      "source": [
        "allDocs[400000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_KzuFVPtxQK"
      },
      "source": [
        "## Writing all docs to file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOeiEbyVvYin"
      },
      "source": [
        "my_df = pd.DataFrame(allDocs)\n",
        "my_df.to_csv(outputDocsFileName,  header=True, index = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9ThamM9Lk7J"
      },
      "source": [
        "outputDocsFileName"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVjIzwqtwQ1Z"
      },
      "source": [
        "# Make, Train, and Save Two doc2vec models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woCFCV8xJq2v"
      },
      "source": [
        "trainPositiveDocs = [doc for doc in allDocs if doc.split == 'train' and doc.sentiment == 1 ]\n",
        "testPositiveDocs = [doc for doc in allDocs if doc.split == 'test' and doc.sentiment == 1]\n",
        "\n",
        "trainNegativeDocs = [doc for doc in allDocs if doc.split == 'train' and doc.sentiment == 0]\n",
        "testNegativeDocs = [doc for doc in allDocs if doc.split == 'test' and doc.sentiment == 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1kzLeVbMDhq"
      },
      "source": [
        "allPositiveDocs = [doc for doc in allDocs if  doc.sentiment == 1 ]\n",
        "allNegativeDocs = [doc for doc in allDocs if  doc.sentiment == 0 ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkkRBas8HPdS"
      },
      "source": [
        "type(allDocs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTuzY9L3O84K"
      },
      "source": [
        "import multiprocessing\n",
        "from collections import OrderedDict\n",
        "\n",
        "import gensim.models.doc2vec\n",
        "assert gensim.models.doc2vec.FAST_VERSION > -1, \"This will be painfully slow otherwise\"\n",
        "\n",
        "from gensim.models.doc2vec import Doc2Vec\n",
        "\n",
        "d2vPositiveModel = Doc2Vec(dm=0, dm_mean = 1,  vector_size=400, epochs=20, min_count=5,\n",
        "    sample=0, workers=multiprocessing.cpu_count(), negative=5, hs=0)\n",
        "\n",
        "d2vNegativeModel = Doc2Vec(dm=0, dm_mean = 1,  vector_size=400, epochs=20, min_count=5,\n",
        "    sample=0, workers=multiprocessing.cpu_count(), negative=5, hs=0)\n",
        "\n",
        "d2vPositiveModel.build_vocab(allPositiveDocs)\n",
        "print(\"%s vocabulary scanned & state initialized\" % d2vPositiveModel)\n",
        "\n",
        "d2vNegativeModel.build_vocab(allNegativeDocs)\n",
        "print(\"%s vocabulary scanned & state initialized\" % d2vNegativeModel)\n",
        "\n",
        "#models_by_name = OrderedDict((str(model), model) for model in simple_models)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lxsl7gZJC8kf"
      },
      "source": [
        "from random import shuffle\n",
        "shuffled_positiveDocs = allPositiveDocs[:]\n",
        "shuffled_negativeDocs = allNegativeDocs[:]\n",
        "\n",
        "shuffle(shuffled_positiveDocs)\n",
        "shuffle(shuffled_negativeDocs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVgd-v-RSgvI"
      },
      "source": [
        "print(len(shuffled_positiveDocs))\n",
        "print(len(shuffled_negativeDocs))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzRJP-SdC-u0"
      },
      "source": [
        "    print(\"Training %s\" % d2vPositiveModel)\n",
        "    d2vPositiveModel.train(shuffled_positiveDocs, total_examples=len(shuffled_positiveDocs), epochs=10)\n",
        "\n",
        "    print(\"Training %s\" % d2vNegativeModel)\n",
        "    d2vNegativeModel.train(shuffled_negativeDocs, total_examples=len(shuffled_negativeDocs), epochs=10)\n",
        "\n",
        "    d2vNegativeModel.save(d2vModelFNmNeg)\n",
        "    d2vNegativeModel.save(d2vModelFNtNeg)\n",
        "\n",
        "    d2vPositiveModel.save(d2vModelFNmPos)\n",
        "    d2vPositiveModel.save(d2vModelFNtPos)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGQg6jO0DCLK"
      },
      "source": [
        "## Are inferred vectors close to the precalculated ones?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYqVYUT64uOi"
      },
      "source": [
        "doc_id = np.random.randint(d2vPositiveModel.docvecs.count)  # Pick random doc; re-run cell for more examples\n",
        "print('for doc %d...' % doc_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erUzU82xFSQB"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljWhtEsz4ybf"
      },
      "source": [
        "allDocs[4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xR76xQpOV74B"
      },
      "source": [
        "doc_id = np.random.randint(d2vPositiveModel.docvecs.count)\n",
        "print(allDocs[doc_id])\n",
        "print(doc_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1aleipXy12-"
      },
      "source": [
        "inferred_docvec = d2vPositiveModel.infer_vector(allDocs[doc_id].words)\n",
        "print('%s:\\n %s' % (d2vPositiveModel, d2vPositiveModel.docvecs.most_similar([inferred_docvec], topn=3)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvnXr2wi5EEm"
      },
      "source": [
        "allDocs[429632]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xTX52eC94Wr"
      },
      "source": [
        "# Find similarities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zszrHKMx9FtI"
      },
      "source": [
        "## Loading Saved d2v Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGPkZxmf__Js"
      },
      "source": [
        "#No need in local\n",
        "from google.colab import drive\n",
        "drive.mount('/MYDRIVE', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yn4Ulgwh9LZn"
      },
      "source": [
        "d2vPositiveModel = Doc2Vec.load(d2vModelFNtPos)\n",
        "d2vNegativeModel = Doc2Vec.load(d2vModelFNtNeg)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0_CY1LSEsfI"
      },
      "source": [
        "# Find the most similar docs tn = 8\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bpvKgWoy59e"
      },
      "source": [
        "dfTopic8 = pd.read_csv(csvTopic8)\n",
        "print(dfTopic8.shape)\n",
        "dfTopic8 = dfTopic8.dropna()\n",
        "dfSimTopic8 = pd.DataFrame()\n",
        "keywordsTopic8 = []\n",
        "\n",
        "keywordsTopic8 = dfTopic8['Keywords']\n",
        "\n",
        "dfSimTopicPos = pd.DataFrame()\n",
        "totalVectorPos = np.zeros(400)\n",
        "\n",
        "dfSimTopicNeg = pd.DataFrame()\n",
        "totalVectorNeg = np.zeros(400)\n",
        "\n",
        "\n",
        "\n",
        "for item in keywordsTopic8 :\n",
        "  item = item.replace('[','')\n",
        "  item = item.replace(']','')\n",
        "  item = item.replace(\"'\",'')\n",
        "  jtems = item.split(',')\n",
        "  inferred_docvecPos = d2vPositiveModel.infer_vector(jtems)\n",
        "  #totalVectorPos = totalVectorPos + inferred_docvecPos\n",
        "  inferred_docvecNeg = d2vNegativeModel.infer_vector(jtems)\n",
        "  #totalVectorNeg = totalVectorNeg + inferred_docvecNeg\n",
        "  dfSimTopicPos = dfSimTopicPos.append( d2vPositiveModel.docvecs.most_similar([inferred_docvecPos], topn=50000))\n",
        "  dfSimTopicNeg = dfSimTopicNeg.append( d2vNegativeModel.docvecs.most_similar([inferred_docvecNeg], topn=50000))\n",
        "\n",
        "  #end of for\n",
        "\n",
        "\n",
        "dfSimTopicPos.columns = [\"docid\",\"SimilarityScore\"]\n",
        "dfSimTopicNeg.columns = [\"docid\",\"SimilarityScore\"]\n",
        "\n",
        "print(\"Number of unique Positive documents\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "dfSimTopicNeg.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "\n",
        "print(\"Number of unique Positive documents after droping duplicates\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents after droping duplicates\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "\n",
        "#Sampling 1000 positive and 1000 negatives\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos = dfSimTopicPos.iloc[0:1000, :]\n",
        "dfSimTopicNeg = dfSimTopicNeg.iloc[0:1000, :]\n",
        "\n",
        "#end Sampling 1000 positive and 1000 negatives\n",
        "print(\"Max Positive:\" , max(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Max Negatives:\" , max(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Min Positive:\" , min(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Min Negatives:\" , min(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Mean Positive:\", dfSimTopicPos[\"SimilarityScore\"].mean())\n",
        "print(\"Mean Positive:\", dfSimTopicNeg[\"SimilarityScore\"].mean())\n",
        "\n",
        "print(\"Std Positive:\",dfSimTopicPos[\"SimilarityScore\"].std())\n",
        "print(\"Std Negative:\",dfSimTopicNeg[\"SimilarityScore\"].std())\n",
        "\n",
        "\n",
        "print(\"len Positive:\" , len(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"len Negatives:\" , len(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "dfAll8 = dfSimTopicNeg.append(dfSimTopicPos)\n",
        "dfAll8.to_csv(csvTopic8MostSimilar, header=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2W0WIixKknnR"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-mHHemxB-up"
      },
      "source": [
        "bin_values = np.arange(start=0.5, stop=1, step=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMqHTOMbCD1A"
      },
      "source": [
        "dfSimTopicPos[1].hist(bins=bin_values, figsize=[8,4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvWbH2UJCw7E"
      },
      "source": [
        "dfSimTopic1[1].hist(bins=bin_values, figsize=[8,4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMEoZnZ-DMnY"
      },
      "source": [
        "bin_values = np.arange(start=0.1, stop=1, step=0.1)\n",
        "dfSimTopic2[1].hist(bins=bin_values, figsize=[8,4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qdew2Q8ADOev"
      },
      "source": [
        "bin_values = np.arange(start=0.4, stop=1, step=0.1)\n",
        "dfSimTopic3[1].hist(bins=bin_values, figsize=[8,4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0HcmsRqjUL6"
      },
      "source": [
        "dfAll8 = dfSimTopicNeg.append(dfSimTopicPos)\n",
        "print(len(dfAll8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AFM4KwgjrDP"
      },
      "source": [
        "csvTopic8MostSimilar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vIwH-n_9qG3"
      },
      "source": [
        "dfAll8.to_csv(csvTopic8MostSimilar, header=True)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQT8TtiuFS9j"
      },
      "source": [
        "# Find the most similar docs tn = 20"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Di2OwCl9mS-Q"
      },
      "source": [
        "\n",
        "\n",
        "dfTopic20 = pd.read_csv(csvTopic20)\n",
        "print(dfTopic20.shape)\n",
        "dfTopic20 = dfTopic20.dropna()\n",
        "dfSimTopic20 = pd.DataFrame()\n",
        "keywordsTopic20= []\n",
        "\n",
        "keywordsTopic20= dfTopic20['Keywords']\n",
        "\n",
        "dfSimTopicPos = pd.DataFrame()\n",
        "totalVectorPos = np.zeros(400)\n",
        "\n",
        "dfSimTopicNeg = pd.DataFrame()\n",
        "totalVectorNeg = np.zeros(400)\n",
        "\n",
        "\n",
        "\n",
        "for item in keywordsTopic20:\n",
        "  item = item.replace('[','')\n",
        "  item = item.replace(']','')\n",
        "  item = item.replace(\"'\",'')\n",
        "  jtems = item.split(',')\n",
        "  inferred_docvecPos = d2vPositiveModel.infer_vector(jtems)\n",
        "  totalVectorPos = totalVectorPos + inferred_docvecPos\n",
        "  inferred_docvecNeg = d2vNegativeModel.infer_vector(jtems)\n",
        "  totalVectorNeg = totalVectorNeg + inferred_docvecNeg\n",
        "  dfSimTopicPos = dfSimTopicPos.append( d2vPositiveModel.docvecs.most_similar([inferred_docvecPos], topn=50000))\n",
        "  dfSimTopicNeg = dfSimTopicNeg.append( d2vNegativeModel.docvecs.most_similar([inferred_docvecNeg], topn=50000))\n",
        "\n",
        "\n",
        "\n",
        "  #end of for\n",
        "\n",
        "\n",
        "dfSimTopicPos.columns = [\"docid\",\"SimilarityScore\"]\n",
        "dfSimTopicNeg.columns = [\"docid\",\"SimilarityScore\"]\n",
        "\n",
        "print(\"Number of unique Positive documents\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "dfSimTopicNeg.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "\n",
        "print(\"Number of unique Positive documents after droping duplicates\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents after droping duplicates\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "#Sampling 1000 positive and 1000 negatives\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos = dfSimTopicPos.iloc[0:1000, :]\n",
        "dfSimTopicNeg = dfSimTopicNeg.iloc[0:1000, :]\n",
        "\n",
        "#end Sampling 1000 positive and 1000 negatives\n",
        "\n",
        "print(\"Max Positive:\" , max(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Max Negatives:\" , max(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Min Positive:\" , min(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Min Negatives:\" , min(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Mean Positive:\", dfSimTopicPos[\"SimilarityScore\"].mean())\n",
        "print(\"Mean Positive:\", dfSimTopicNeg[\"SimilarityScore\"].mean())\n",
        "\n",
        "print(\"Std Positive:\",dfSimTopicPos[\"SimilarityScore\"].std())\n",
        "print(\"Std Negative:\",dfSimTopicNeg[\"SimilarityScore\"].std())\n",
        "\n",
        "\n",
        "print(\"len Positive:\" , len(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"len Negatives:\" , len(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "dfAll8 = dfSimTopicNeg.append(dfSimTopicPos)\n",
        "dfAll8.to_csv(csvTopic20MostSimilar, header=True)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlTK301VmNEQ"
      },
      "source": [
        "# Visualizatiom"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-PpK1oDPaTA"
      },
      "source": [
        "bin_values = np.arange(start=0.5, stop=1, step=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6l7RSoQPtLr"
      },
      "source": [
        "dfSimTopic0_20[1].hist(bins=bin_values, figsize=[8,4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lOYSiMJP15b"
      },
      "source": [
        "dfSimTopic1_20[1].hist(bins=bin_values, figsize=[8,4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPgZTIh0P5QA"
      },
      "source": [
        "bin_values = np.arange(start=0.1, stop=1, step=0.1)\n",
        "dfSimTopic2_20[1].hist(bins=bin_values, figsize=[8,4])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Icdwn4E9P-tc"
      },
      "source": [
        "bin_values = np.arange(start=0.5, stop=1, step=0.1)\n",
        "dfSimTopic3_20[1].hist(bins=bin_values, figsize=[8,4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyME1mZ5FUrl"
      },
      "source": [
        "# Find the most similar docs tn = 40"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJOS7VAImqiz"
      },
      "source": [
        "\n",
        "\n",
        "dfTopic40 = pd.read_csv(csvTopic40)\n",
        "print(dfTopic40.shape)\n",
        "dfTopic40 = dfTopic40.dropna()\n",
        "dfSimTopic40 = pd.DataFrame()\n",
        "keywordsTopic40= []\n",
        "\n",
        "keywordsTopic40= dfTopic40['Keywords']\n",
        "\n",
        "dfSimTopicPos = pd.DataFrame()\n",
        "totalVectorPos = np.zeros(400)\n",
        "\n",
        "dfSimTopicNeg = pd.DataFrame()\n",
        "totalVectorNeg = np.zeros(400)\n",
        "\n",
        "\n",
        "\n",
        "for item in keywordsTopic40:\n",
        "  item = item.replace('[','')\n",
        "  item = item.replace(']','')\n",
        "  item = item.replace(\"'\",'')\n",
        "  jtems = item.split(',')\n",
        "  inferred_docvecPos = d2vPositiveModel.infer_vector(jtems)\n",
        "  totalVectorPos = totalVectorPos + inferred_docvecPos\n",
        "  inferred_docvecNeg = d2vNegativeModel.infer_vector(jtems)\n",
        "  totalVectorNeg = totalVectorNeg + inferred_docvecNeg\n",
        "  dfSimTopicPos = dfSimTopicPos.append( d2vPositiveModel.docvecs.most_similar([inferred_docvecPos], topn=50000))\n",
        "  dfSimTopicNeg = dfSimTopicNeg.append( d2vNegativeModel.docvecs.most_similar([inferred_docvecNeg], topn=50000))\n",
        "  #end of for\n",
        "\n",
        "\n",
        "dfSimTopicPos.columns = [\"docid\",\"SimilarityScore\"]\n",
        "dfSimTopicNeg.columns = [\"docid\",\"SimilarityScore\"]\n",
        "\n",
        "print(\"Number of unique Positive documents\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "dfSimTopicNeg.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "\n",
        "print(\"Number of unique Positive documents after droping duplicates\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents after droping duplicates\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "#Sampling 1000 positive and 1000 negatives\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos = dfSimTopicPos.iloc[0:1000, :]\n",
        "dfSimTopicNeg = dfSimTopicNeg.iloc[0:1000, :]\n",
        "\n",
        "#end Sampling 1000 positive and 1000 negatives\n",
        "\n",
        "print(\"Max Positive:\" , max(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Max Negatives:\" , max(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Min Positive:\" , min(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Min Negatives:\" , min(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Mean Positive:\", dfSimTopicPos[\"SimilarityScore\"].mean())\n",
        "print(\"Mean Positive:\", dfSimTopicNeg[\"SimilarityScore\"].mean())\n",
        "\n",
        "print(\"Std Positive:\",dfSimTopicPos[\"SimilarityScore\"].std())\n",
        "print(\"Std Negative:\",dfSimTopicNeg[\"SimilarityScore\"].std())\n",
        "\n",
        "\n",
        "print(\"len Positive:\" , len(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"len Negatives:\" , len(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "dfAll8 = dfSimTopicNeg.append(dfSimTopicPos)\n",
        "dfAll8.to_csv(csvTopic40MostSimilar, header=True)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4uds5a2mnRA"
      },
      "source": [
        "# Visuaization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YL5MCCjc4nwh"
      },
      "source": [
        "bin_values = np.arange(start=0.5, stop=1, step=0.1)\n",
        "dfSimTopic0_40[1].hist(bins=bin_values, figsize=[8,4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ln6QLOaM4pQh"
      },
      "source": [
        "bin_values = np.arange(start=0.5, stop=1, step=0.1)\n",
        "dfSimTopic1_40[1].hist(bins=bin_values, figsize=[8,4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKhLL8KM4rBD"
      },
      "source": [
        "bin_values = np.arange(start=0.1, stop=1, step=0.1)\n",
        "dfSimTopic2_40[1].hist(bins=bin_values, figsize=[8,4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uP2RD_Yv4svn"
      },
      "source": [
        "bin_values = np.arange(start=0.5, stop=1, step=0.1)\n",
        "dfSimTopic3_40[1].hist(bins=bin_values, figsize=[8,4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDAPVn0mFWWU"
      },
      "source": [
        "# Find the most similar docs tn = 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7aDWFX-nB3f"
      },
      "source": [
        "dfTopic50 = pd.read_csv(csvTopic50)\n",
        "print(dfTopic50.shape)\n",
        "dfTopic50 = dfTopic50.dropna()\n",
        "dfSimTopic50 = pd.DataFrame()\n",
        "keywordsTopic50= []\n",
        "\n",
        "keywordsTopic50= dfTopic50['Keywords']\n",
        "\n",
        "dfSimTopicPos = pd.DataFrame()\n",
        "totalVectorPos = np.zeros(400)\n",
        "\n",
        "dfSimTopicNeg = pd.DataFrame()\n",
        "totalVectorNeg = np.zeros(400)\n",
        "\n",
        "\n",
        "\n",
        "for item in keywordsTopic50:\n",
        "  item = item.replace('[','')\n",
        "  item = item.replace(']','')\n",
        "  item = item.replace(\"'\",'')\n",
        "  jtems = item.split(',')\n",
        "  inferred_docvecPos = d2vPositiveModel.infer_vector(jtems)\n",
        "  totalVectorPos = totalVectorPos + inferred_docvecPos\n",
        "  inferred_docvecNeg = d2vNegativeModel.infer_vector(jtems)\n",
        "  totalVectorNeg = totalVectorNeg + inferred_docvecNeg\n",
        "  dfSimTopicPos = dfSimTopicPos.append( d2vPositiveModel.docvecs.most_similar([inferred_docvecPos], topn=50000))\n",
        "  dfSimTopicNeg = dfSimTopicNeg.append( d2vNegativeModel.docvecs.most_similar([inferred_docvecNeg], topn=50000))\n",
        "\n",
        "  #end of for\n",
        "\n",
        "\n",
        "dfSimTopicPos.columns = [\"docid\",\"SimilarityScore\"]\n",
        "dfSimTopicNeg.columns = [\"docid\",\"SimilarityScore\"]\n",
        "\n",
        "print(\"Number of unique Positive documents\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "dfSimTopicNeg.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "\n",
        "print(\"Number of unique Positive documents after droping duplicates\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents after droping duplicates\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "#Sampling 1000 positive and 1000 negatives\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos = dfSimTopicPos.iloc[0:1000, :]\n",
        "dfSimTopicNeg = dfSimTopicNeg.iloc[0:1000, :]\n",
        "\n",
        "#end Sampling 1000 positive and 1000 negatives\n",
        "\n",
        "print(\"Max Positive:\" , max(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Max Negatives:\" , max(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Min Positive:\" , min(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Min Negatives:\" , min(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Mean Positive:\", dfSimTopicPos[\"SimilarityScore\"].mean())\n",
        "print(\"Mean Positive:\", dfSimTopicNeg[\"SimilarityScore\"].mean())\n",
        "\n",
        "print(\"Std Positive:\",dfSimTopicPos[\"SimilarityScore\"].std())\n",
        "print(\"Std Negative:\",dfSimTopicNeg[\"SimilarityScore\"].std())\n",
        "\n",
        "\n",
        "print(\"len Positive:\" , len(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"len Negatives:\" , len(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "dfAll50 = dfSimTopicNeg.append(dfSimTopicPos)\n",
        "dfAll50.to_csv(csvTopic50MostSimilar, header=True)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56EvLlCTnCQm"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hknSxWA9S6x9"
      },
      "source": [
        "\n",
        "bin_values = np.arange(start=0.5, stop=1, step=0.1)\n",
        "dfSimTopic0_50[1].hist(bins=bin_values, figsize=[8,4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnUU61A-GqVD"
      },
      "source": [
        "bin_values = np.arange(start=0.5, stop=1, step=0.1)\n",
        "dfSimTopic1_50[1].hist(bins=bin_values, figsize=[8,4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTL0ELNXGsLT"
      },
      "source": [
        "bin_values = np.arange(start=0.1, stop=1, step=0.1)\n",
        "dfSimTopic2_50[1].hist(bins=bin_values, figsize=[8,4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIBdu3hvGty5"
      },
      "source": [
        "bin_values = np.arange(start=0.1, stop=1, step=0.1)\n",
        "dfSimTopic3_50[1].hist(bins=bin_values, figsize=[8,4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9oj1SUTFYWm"
      },
      "source": [
        "# Find the most similar docs tn = 60"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3ktIBbvpYu7"
      },
      "source": [
        "\n",
        "dfTopic60 = pd.read_csv(csvTopic60)\n",
        "print(dfTopic60.shape)\n",
        "dfTopic60 = dfTopic60.dropna()\n",
        "dfSimTopic60 = pd.DataFrame()\n",
        "keywordsTopic60= []\n",
        "\n",
        "keywordsTopic60= dfTopic60['Keywords']\n",
        "\n",
        "dfSimTopicPos = pd.DataFrame()\n",
        "totalVectorPos = np.zeros(400)\n",
        "\n",
        "dfSimTopicNeg = pd.DataFrame()\n",
        "totalVectorNeg = np.zeros(400)\n",
        "\n",
        "\n",
        "\n",
        "for item in keywordsTopic60:\n",
        "  item = item.replace('[','')\n",
        "  item = item.replace(']','')\n",
        "  item = item.replace(\"'\",'')\n",
        "  jtems = item.split(',')\n",
        "  inferred_docvecPos = d2vPositiveModel.infer_vector(jtems)\n",
        "  totalVectorPos = totalVectorPos + inferred_docvecPos\n",
        "  inferred_docvecNeg = d2vNegativeModel.infer_vector(jtems)\n",
        "  totalVectorNeg = totalVectorNeg + inferred_docvecNeg\n",
        "  dfSimTopicPos = dfSimTopicPos.append( d2vPositiveModel.docvecs.most_similar([inferred_docvecPos], topn=50000))\n",
        "  dfSimTopicNeg = dfSimTopicNeg.append( d2vNegativeModel.docvecs.most_similar([inferred_docvecNeg], topn=50000))\n",
        "  #end of for\n",
        "\n",
        "\n",
        "dfSimTopicPos.columns = [\"docid\",\"SimilarityScore\"]\n",
        "dfSimTopicNeg.columns = [\"docid\",\"SimilarityScore\"]\n",
        "\n",
        "print(\"Number of unique Positive documents\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "dfSimTopicNeg.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "\n",
        "print(\"Number of unique Positive documents after droping duplicates\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents after droping duplicates\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "#Sampling 1000 positive and 1000 negatives\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos = dfSimTopicPos.iloc[0:1000, :]\n",
        "dfSimTopicNeg = dfSimTopicNeg.iloc[0:1000, :]\n",
        "\n",
        "#end Sampling 1000 positive and 1000 negatives\n",
        "\n",
        "print(\"Max Positive:\" , max(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Max Negatives:\" , max(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Min Positive:\" , min(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Min Negatives:\" , min(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Mean Positive:\", dfSimTopicPos[\"SimilarityScore\"].mean())\n",
        "print(\"Mean Positive:\", dfSimTopicNeg[\"SimilarityScore\"].mean())\n",
        "\n",
        "print(\"Std Positive:\",dfSimTopicPos[\"SimilarityScore\"].std())\n",
        "print(\"Std Negative:\",dfSimTopicNeg[\"SimilarityScore\"].std())\n",
        "\n",
        "\n",
        "print(\"len Positive:\" , len(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"len Negatives:\" , len(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "dfAll60 = dfSimTopicNeg.append(dfSimTopicPos)\n",
        "dfAll60.to_csv(csvTopic60MostSimilar, header=True)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztOulH6Ro7-D"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yf8_aLTJHL7O"
      },
      "source": [
        "bin_values = np.arange(start=0.5, stop=1, step=0.1)\n",
        "dfSimTopic0_60[1].hist(bins=bin_values, figsize=[8,4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2zVDBbVHMvH"
      },
      "source": [
        "bin_values = np.arange(start=0.5, stop=1, step=0.1)\n",
        "dfSimTopic1_60[1].hist(bins=bin_values, figsize=[8,4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDBKRHeqHNog"
      },
      "source": [
        "bin_values = np.arange(start=0.1, stop=1, step=0.1)\n",
        "dfSimTopic2_60[1].hist(bins=bin_values, figsize=[8,4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIejB1NQHOUG"
      },
      "source": [
        "bin_values = np.arange(start=0.5, stop=1, step=0.1)\n",
        "dfSimTopic3_60[1].hist(bins=bin_values, figsize=[8,4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mye0KNDdFZm4"
      },
      "source": [
        "# Find the most similar docs tn = 65"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OM4bWg5aprEW"
      },
      "source": [
        "\n",
        "\n",
        "dfTopic65 = pd.read_csv(csvTopic65)\n",
        "print(dfTopic65.shape)\n",
        "dfTopic65 = dfTopic65.dropna()\n",
        "dfSimTopic65 = pd.DataFrame()\n",
        "keywordsTopic65= []\n",
        "\n",
        "keywordsTopic65= dfTopic65['Keywords']\n",
        "\n",
        "dfSimTopicPos = pd.DataFrame()\n",
        "totalVectorPos = np.zeros(400)\n",
        "\n",
        "dfSimTopicNeg = pd.DataFrame()\n",
        "totalVectorNeg = np.zeros(400)\n",
        "\n",
        "\n",
        "\n",
        "for item in keywordsTopic65:\n",
        "  item = item.replace('[','')\n",
        "  item = item.replace(']','')\n",
        "  item = item.replace(\"'\",'')\n",
        "  jtems = item.split(',')\n",
        "  inferred_docvecPos = d2vPositiveModel.infer_vector(jtems)\n",
        "  totalVectorPos = totalVectorPos + inferred_docvecPos\n",
        "  inferred_docvecNeg = d2vNegativeModel.infer_vector(jtems)\n",
        "  totalVectorNeg = totalVectorNeg + inferred_docvecNeg\n",
        "  dfSimTopicPos = dfSimTopicPos.append( d2vPositiveModel.docvecs.most_similar([inferred_docvecPos], topn=50000))\n",
        "  dfSimTopicNeg = dfSimTopicNeg.append( d2vNegativeModel.docvecs.most_similar([inferred_docvecNeg], topn=50000))\n",
        "\n",
        "  #end of for\n",
        "\n",
        "\n",
        "dfSimTopicPos.columns = [\"docid\",\"SimilarityScore\"]\n",
        "dfSimTopicNeg.columns = [\"docid\",\"SimilarityScore\"]\n",
        "\n",
        "print(\"Number of unique Positive documents\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "dfSimTopicNeg.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "\n",
        "print(\"Number of unique Positive documents after droping duplicates\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents after droping duplicates\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "#Sampling 1000 positive and 1000 negatives\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos = dfSimTopicPos.iloc[0:1000, :]\n",
        "dfSimTopicNeg = dfSimTopicNeg.iloc[0:1000, :]\n",
        "\n",
        "#end Sampling 1000 positive and 1000 negatives\n",
        "\n",
        "print(\"Max Positive:\" , max(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Max Negatives:\" , max(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Min Positive:\" , min(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Min Negatives:\" , min(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Mean Positive:\", dfSimTopicPos[\"SimilarityScore\"].mean())\n",
        "print(\"Mean Positive:\", dfSimTopicNeg[\"SimilarityScore\"].mean())\n",
        "\n",
        "print(\"Std Positive:\",dfSimTopicPos[\"SimilarityScore\"].std())\n",
        "print(\"Std Negative:\",dfSimTopicNeg[\"SimilarityScore\"].std())\n",
        "\n",
        "\n",
        "print(\"len Positive:\" , len(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"len Negatives:\" , len(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "dfAll65 = dfSimTopicNeg.append(dfSimTopicPos)\n",
        "dfAll65.to_csv(csvTopic65MostSimilar, header=True)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HoypU0FprVy"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIVDe1YPIJrW"
      },
      "source": [
        "\n",
        "bin_values = np.arange(start=0.5, stop=1, step=0.1)\n",
        "dfSimTopic0_65[1].hist(bins=bin_values, figsize=[8,4])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEjtP2tVIMFX"
      },
      "source": [
        "dfSimTopic1_65[1].hist(bins=bin_values, figsize=[8,4])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNcX4gi-INtd"
      },
      "source": [
        "bin_values = np.arange(start=0.1, stop=1, step=0.1)\n",
        "dfSimTopic2_65[1].hist(bins=bin_values, figsize=[8,4])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_6GGKVLIPTQ"
      },
      "source": [
        "dfSimTopic3_65[1].hist(bins=bin_values, figsize=[8,4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RHcSo4-Fa_a"
      },
      "source": [
        "# Find the most similar docs tn = 70"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyJDj5QVF6mr"
      },
      "source": [
        "csvTopic70MostSimilar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgopwngQqKuk"
      },
      "source": [
        "\n",
        "\n",
        "dfTopic70 = pd.read_csv(csvTopic70)\n",
        "print(dfTopic70.shape)\n",
        "dfTopic70 = dfTopic70.dropna()\n",
        "dfSimTopic70 = pd.DataFrame()\n",
        "keywordsTopic70= []\n",
        "\n",
        "keywordsTopic70= dfTopic70['Keywords']\n",
        "\n",
        "dfSimTopicPos = pd.DataFrame()\n",
        "totalVectorPos = np.zeros(400)\n",
        "\n",
        "dfSimTopicNeg = pd.DataFrame()\n",
        "totalVectorNeg = np.zeros(400)\n",
        "\n",
        "\n",
        "\n",
        "for item in keywordsTopic70:\n",
        "  item = item.replace('[','')\n",
        "  item = item.replace(']','')\n",
        "  item = item.replace(\"'\",'')\n",
        "  jtems = item.split(',')\n",
        "  inferred_docvecPos = d2vPositiveModel.infer_vector(jtems)\n",
        "  totalVectorPos = totalVectorPos + inferred_docvecPos\n",
        "  inferred_docvecNeg = d2vNegativeModel.infer_vector(jtems)\n",
        "  totalVectorNeg = totalVectorNeg + inferred_docvecNeg\n",
        "  dfSimTopicPos = dfSimTopicPos.append( d2vPositiveModel.docvecs.most_similar([inferred_docvecPos], topn=50000))\n",
        "  dfSimTopicNeg = dfSimTopicNeg.append( d2vNegativeModel.docvecs.most_similar([inferred_docvecNeg], topn=50000))\n",
        "\n",
        "  #end of for\n",
        "\n",
        "\n",
        "dfSimTopicPos.columns = [\"docid\",\"SimilarityScore\"]\n",
        "dfSimTopicNeg.columns = [\"docid\",\"SimilarityScore\"]\n",
        "\n",
        "print(\"Number of unique Positive documents\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "dfSimTopicNeg.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "\n",
        "print(\"Number of unique Positive documents after droping duplicates\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents after droping duplicates\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "#Sampling 1000 positive and 1000 negatives\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos = dfSimTopicPos.iloc[0:1000, :]\n",
        "dfSimTopicNeg = dfSimTopicNeg.iloc[0:1000, :]\n",
        "\n",
        "#end Sampling 1000 positive and 1000 negatives\n",
        "\n",
        "print(\"Max Positive:\" , max(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Max Negatives:\" , max(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Min Positive:\" , min(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Min Negatives:\" , min(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Mean Positive:\", dfSimTopicPos[\"SimilarityScore\"].mean())\n",
        "print(\"Mean Positive:\", dfSimTopicNeg[\"SimilarityScore\"].mean())\n",
        "\n",
        "print(\"Std Positive:\",dfSimTopicPos[\"SimilarityScore\"].std())\n",
        "print(\"Std Negative:\",dfSimTopicNeg[\"SimilarityScore\"].std())\n",
        "\n",
        "\n",
        "print(\"len Positive:\" , len(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"len Negatives:\" , len(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "dfAll70 = dfSimTopicNeg.append(dfSimTopicPos)\n",
        "dfAll70.to_csv(csvTopic70MostSimilar, header=True)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IiNt4D-qK83"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WqcgnJ3IleA"
      },
      "source": [
        "bin_values = np.arange(start=0.5, stop=1, step=0.1)\n",
        "dfSimTopic0_70[1].hist(bins=bin_values, figsize=[8,4])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWJqh9o-IoN3"
      },
      "source": [
        "dfSimTopic1_70[1].hist(bins=bin_values, figsize=[8,4])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfIKDHRzIptR"
      },
      "source": [
        "bin_values = np.arange(start=0.1, stop=1, step=0.1)\n",
        "dfSimTopic2_70[1].hist(bins=bin_values, figsize=[8,4])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdBCpBgtIrB7"
      },
      "source": [
        "dfSimTopic3_70[1].hist(bins=bin_values, figsize=[8,4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAWPmqdjFcjw"
      },
      "source": [
        "# Find the most similar docs tn = 80"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USvy6I4OFoxU"
      },
      "source": [
        "csvTopic80MostSimilar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6Fvh6CmqjbE"
      },
      "source": [
        "\n",
        "\n",
        "dfTopic80 = pd.read_csv(csvTopic80)\n",
        "print(dfTopic80.shape)\n",
        "dfTopic80 = dfTopic80.dropna()\n",
        "dfSimTopic80 = pd.DataFrame()\n",
        "keywordsTopic80= []\n",
        "\n",
        "keywordsTopic80= dfTopic80['Keywords']\n",
        "\n",
        "dfSimTopicPos = pd.DataFrame()\n",
        "totalVectorPos = np.zeros(400)\n",
        "\n",
        "dfSimTopicNeg = pd.DataFrame()\n",
        "totalVectorNeg = np.zeros(400)\n",
        "\n",
        "\n",
        "\n",
        "for item in keywordsTopic80:\n",
        "  item = item.replace('[','')\n",
        "  item = item.replace(']','')\n",
        "  item = item.replace(\"'\",'')\n",
        "  jtems = item.split(',')\n",
        "  inferred_docvecPos = d2vPositiveModel.infer_vector(jtems)\n",
        "  totalVectorPos = totalVectorPos + inferred_docvecPos\n",
        "  inferred_docvecNeg = d2vNegativeModel.infer_vector(jtems)\n",
        "  totalVectorNeg = totalVectorNeg + inferred_docvecNeg\n",
        "  dfSimTopicPos = dfSimTopicPos.append( d2vPositiveModel.docvecs.most_similar([inferred_docvecPos], topn=50000))\n",
        "  dfSimTopicNeg = dfSimTopicNeg.append( d2vNegativeModel.docvecs.most_similar([inferred_docvecNeg], topn=50000))\n",
        "\n",
        "  #end of for\n",
        "\n",
        "\n",
        "dfSimTopicPos.columns = [\"docid\",\"SimilarityScore\"]\n",
        "dfSimTopicNeg.columns = [\"docid\",\"SimilarityScore\"]\n",
        "\n",
        "print(\"Number of unique Positive documents\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "dfSimTopicNeg.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "\n",
        "print(\"Number of unique Positive documents after droping duplicates\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents after droping duplicates\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "#Sampling 1000 positive and 1000 negatives\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos = dfSimTopicPos.iloc[0:1000, :]\n",
        "dfSimTopicNeg = dfSimTopicNeg.iloc[0:1000, :]\n",
        "\n",
        "#end Sampling 1000 positive and 1000 negatives\n",
        "\n",
        "print(\"Max Positive:\" , max(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Max Negatives:\" , max(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Min Positive:\" , min(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Min Negatives:\" , min(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Mean Positive:\", dfSimTopicPos[\"SimilarityScore\"].mean())\n",
        "print(\"Mean Positive:\", dfSimTopicNeg[\"SimilarityScore\"].mean())\n",
        "\n",
        "print(\"Std Positive:\",dfSimTopicPos[\"SimilarityScore\"].std())\n",
        "print(\"Std Negative:\",dfSimTopicNeg[\"SimilarityScore\"].std())\n",
        "\n",
        "\n",
        "print(\"len Positive:\" , len(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"len Negatives:\" , len(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "dfAll80 = dfSimTopicNeg.append(dfSimTopicPos)\n",
        "dfAll80.to_csv(csvTopic80MostSimilar, header=True)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22xOChv1qjl-"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yh3y4ywMLuyS"
      },
      "source": [
        "bin_values = np.arange(start=0.5, stop=1, step=0.1)\n",
        "dfSimTopic0_80[1].hist(bins=bin_values, figsize=[8,4])\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeC39sUYLxZH"
      },
      "source": [
        "dfSimTopic1_80[1].hist(bins=bin_values, figsize=[8,4])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f5qJMoXLy50"
      },
      "source": [
        "bin_values = np.arange(start=0.1, stop=1, step=0.1)\n",
        "dfSimTopic2_80[1].hist(bins=bin_values, figsize=[8,4])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmZC1Aw6L0du"
      },
      "source": [
        "dfSimTopic3_80[1].hist(bins=bin_values, figsize=[8,4])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}