{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "HiSEEeOX5UxO",
        "QmK-tAmXydXh",
        "S2kue_J3ls55",
        "pDJllF_IIzKf",
        "PVfCNShf8zHs",
        "P4PpCJX5855K",
        "t0_CY1LSEsfI",
        "rQT8TtiuFS9j",
        "OyME1mZ5FUrl",
        "yDAPVn0mFWWU",
        "n9oj1SUTFYWm",
        "Mye0KNDdFZm4",
        "7RHcSo4-Fa_a",
        "kAWPmqdjFcjw"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This module is responsible for:\n",
        "\n",
        "\n",
        "*   Finding the most similar documents to topics by RoBERTa\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gaLL1AbCHjzt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuu6z-ZZoZHq"
      },
      "source": [
        "## Configurations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbkcv3irn-mi"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf6N4pe_oSu6"
      },
      "source": [
        "import logging\n",
        "#logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tBIYWabuTES",
        "outputId": "8d7142e3-3a5d-4377-c119-85a4120bb924"
      },
      "source": [
        "pip install sentence-transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.1.0.tar.gz (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 2.6 MB/s \n",
            "\u001b[?25hCollecting transformers<5.0.0,>=4.6.0\n",
            "  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 11.8 MB/s \n",
            "\u001b[?25hCollecting tokenizers>=0.10.3\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 39.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.62.3)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.9.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.10.0+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 51.1 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 45.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (4.8.1)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 46.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.5.30)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.1.0-py3-none-any.whl size=121000 sha256=872d021fb62e59a36ede4078644fab8de294f9b2c3b4119c51f5c85a0156f34f\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/f0/bb/ed1add84da70092ea526466eadc2bfb197c4bcb8d4fa5f7bad\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers, sentencepiece, sentence-transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.19 pyyaml-6.0 sacremoses-0.0.46 sentence-transformers-2.1.0 sentencepiece-0.1.96 tokenizers-0.10.3 transformers-4.11.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOZnc3w7CA9Y"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gensim\n",
        "from sklearn.model_selection import train_test_split\n",
        "import multiprocessing\n",
        "from collections import OrderedDict\n",
        "\n",
        "import gensim.models.doc2vec\n",
        "assert gensim.models.doc2vec.FAST_VERSION > -1, \"This will be painfully slow otherwise\"\n",
        "\n",
        "from gensim.models.doc2vec import Doc2Vec\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import collections\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxGpI5Zq6IQl",
        "outputId": "c62d1a20-0a84-4df3-ec7a-ee81385d7588"
      },
      "source": [
        "pip install testfixtures"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting testfixtures\n",
            "  Downloading testfixtures-6.18.3-py2.py3-none-any.whl (95 kB)\n",
            "\u001b[K     |████████████████████████████████| 95 kB 3.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: testfixtures\n",
            "Successfully installed testfixtures-6.18.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0FG4Qzc_bYD"
      },
      "source": [
        "#'/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Processed-Merged-Dataset-99-08-28.csv'\n",
        "\n",
        "inputFileName = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Balenced-Dataset-00-06-26.csv'\n",
        "\n",
        "\n",
        "outputLabelledTTDS= '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Balenced-Dataset-00-06-26.csv'\n",
        "outputDocsFileName = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/DocsReadyForD2V-00-06-26.csv'\n",
        "\n",
        "d2vModelFNmPos = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModelPositive-00-06-26.model'\n",
        "d2vModelFNtPos = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModelPositive-00-06-26.txt' \n",
        "\n",
        "d2vModelFNmNeg = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModelNegative-00-06-26.model'\n",
        "d2vModelFNtNeg = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModelNegative-00-06-26.txt' \n",
        "\n",
        "csvTopic8 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Topics_8.csv'\n",
        "csvTopic20 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Topics_20.csv'\n",
        "csvTopic40 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Topics_40.csv'\n",
        "csvTopic80 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Topics_80.csv'\n",
        "csvTopic50 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Topics_50.csv'\n",
        "csvTopic60 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Topics_60.csv'\n",
        "csvTopic65 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Topics_65.csv'\n",
        "csvTopic70 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Topics_70.csv'\n",
        "\n",
        "\n",
        "d2vModelFNm0 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModel0-00-06-23.model'\n",
        "d2vModelFNt0 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModel0-00-06-23.txt' \n",
        "\n",
        "d2vModelFNm1 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModel1-00-06-23.model'\n",
        "d2vModelFNt1 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModel1-00-06-23.txt' \n",
        "\n",
        "d2vModelFNm2 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModel2-00-06-23.model'\n",
        "d2vModelFNt2 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModel2-00-06-23.txt' \n",
        "\n",
        "d2vModelFNm3 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModel3-00-06-23.model'\n",
        "d2vModelFNt3 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModel3-00-06-23.txt' \n",
        "\n",
        "csvTopic8MostSimilar = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/SimilarDocsByRoberta/Topics_8_MostSimilar_RO.csv'\n",
        "csvTopic20MostSimilar = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/SimilarDocsByRoberta/Topics_20_MostSimilar_RO.csv'\n",
        "csvTopic40MostSimilar = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/SimilarDocsByRoberta/Topics_40_MostSimilar_RO.csv'\n",
        "csvTopic50MostSimilar = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/SimilarDocsByRoberta/Topics_50_MostSimilar_RO.csv'\n",
        "csvTopic60MostSimilar = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/SimilarDocsByRoberta/Topics_60_MostSimilar_RO.csv'\n",
        "csvTopic65MostSimilar = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/SimilarDocsByRoberta/Topics_65_MostSimilar_RO.csv'\n",
        "csvTopic70MostSimilar = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/SimilarDocsByRoberta/Topics_70_MostSimilar_RO.csv'\n",
        "csvTopic80MostSimilar = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/SimilarDocsByRoberta/Topics_80_MostSimilar_RO.csv'\n",
        "#SimilarDocsByProposedMethod-Albert-Albert\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiSEEeOX5UxO"
      },
      "source": [
        "# Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-ztS1ZQ_5Xz",
        "outputId": "5771cba4-ba40-4e8c-e319-3b8923b3cc1a"
      },
      "source": [
        "#No need in local\n",
        "from google.colab import drive\n",
        "drive.mount('/MYDRIVE', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /MYDRIVE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmK-tAmXydXh"
      },
      "source": [
        "# Prepair Dataset (Dividing into Test and Train)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhzbLnooKzgZ"
      },
      "source": [
        "dfReviews.loc[dfReviews[\"Text\"] == 'finish cuba straight round']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9N4Y2ry_9yW"
      },
      "source": [
        "dfReviews = pd.DataFrame()\n",
        "dfReviews = pd.read_csv(inputFileName, encoding = 'utf-8', header = 0 )\n",
        "dfReviews.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8nnJXkPMdqe",
        "outputId": "f73b2348-8ec8-4129-9439-2a0d102bbd7e"
      },
      "source": [
        "print(dfReviews.index[dfReviews[\"Text\"] == 'finish cuba straight round'].tolist() )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5k6XdrymFqu",
        "outputId": "45a65a8d-a47c-44f3-a834-9d545d611115"
      },
      "source": [
        "inputFileName"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Balenced-Dataset-00-06-26.csv'"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKonEE_yHIW2"
      },
      "source": [
        "dfReviews.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0b20GkvxEm1"
      },
      "source": [
        "dfReviews = dfReviews.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pL4BWFkNxJdr"
      },
      "source": [
        "dfReviews.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQFrAAjUHpAu"
      },
      "source": [
        "len (dfReviews.loc[dfReviews[\"Sentiment\"] == 0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RcaSW8uISBH"
      },
      "source": [
        "len (dfReviews.loc[dfReviews[\"Sentiment\"] == 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leTzHA-2aH88"
      },
      "source": [
        "dfReviews[4] = 'train'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8bMsPoClaLT"
      },
      "source": [
        "dfReviews.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFWPmH-nleBf"
      },
      "source": [
        "dfReviews.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWjQ6aA7bDwI"
      },
      "source": [
        "testNumber=113320\n",
        "trainNumber=453280"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCylZNA_sOF1"
      },
      "source": [
        "dfReviews.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2kue_J3ls55"
      },
      "source": [
        "# Preparing test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDJllF_IIzKf"
      },
      "source": [
        "# Making embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6q0tLIMsuTFD"
      },
      "source": [
        "dfPositiveReviews = dfReviews[dfReviews[\"Sentiment\"] == 1]\n",
        "print(len(dfPositiveReviews))\n",
        "dfNegativeReviews = dfReviews[dfReviews[\"Sentiment\"] == 0]\n",
        "print(len(dfNegativeReviews))\n",
        "\n",
        "allPositiveReviews = list()\n",
        "for line in dfPositiveReviews[\"Text\"]:\n",
        "  allPositiveReviews.append( str(line) )\n",
        "\n",
        "\n",
        "allNegativeReviews = list()\n",
        "for line in dfNegativeReviews[\"Text\"]:\n",
        "  allNegativeReviews.append( str(line) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9z55MhtYuTFF",
        "outputId": "ef9ef7a2-b0c6-4620-dc6c-8b0c724ad3d1"
      },
      "source": [
        "%time\n",
        "#model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
        "positiveModel = SentenceTransformer(\"/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/nli-roberta-base-v2\")\n",
        "negativeModel = SentenceTransformer(\"/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/nli-roberta-base-v2\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
            "Wall time: 8.11 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9sJopKsuTFN",
        "outputId": "65660e50-8741-40b7-af0c-740bdc56cb29"
      },
      "source": [
        "%time\n",
        "positiveEmbeddings = positiveModel.encode(allPositiveReviews, convert_to_numpy=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 5.48 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UA5QMloruTFO",
        "outputId": "0f3cfe3e-16ef-418e-f7b9-cbb3b48bc753"
      },
      "source": [
        "%time\n",
        "negativeEmbeddings = negativeModel.encode(allNegativeReviews, convert_to_numpy=True)\n",
        "\n",
        "print(positiveEmbeddings.shape)\n",
        "\n",
        "print(negativeEmbeddings.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
            "Wall time: 10.3 µs\n",
            "(283300, 768)\n",
            "(283300, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVfCNShf8zHs"
      },
      "source": [
        "# Save embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krU14g_GuTFQ",
        "outputId": "6ab0e966-c9d6-49e9-d3a1-429aba683266"
      },
      "source": [
        "%time\n",
        "\n",
        "import os\n",
        "import csv\n",
        "import pickle\n",
        "embedding_positive_path = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Positive-Embeddings-Roberta.pkl'\n",
        "embedding_negative_path = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Negative-Embeddings-Roberta.pkl'\n",
        "print(\"Store file on disc\")\n",
        "with open(embedding_positive_path, \"wb\") as fOutPositive:\n",
        "    pickle.dump({'sentences': allPositiveReviews, 'embeddings': positiveEmbeddings}, fOutPositive)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
            "Wall time: 10.3 µs\n",
            "Store file on disc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikg_YDBWuTFS",
        "outputId": "ce1b32f7-63cd-4594-c285-2f2a63409ad0"
      },
      "source": [
        "%time\n",
        "\n",
        "with open(embedding_negative_path, \"wb\") as fOutNegative:\n",
        "    pickle.dump({'sentences': allNegativeReviews, 'embeddings': negativeEmbeddings}, fOutNegative)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 5.96 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4PpCJX5855K"
      },
      "source": [
        "# Load Pretrained embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmaJLRyL8-tL"
      },
      "source": [
        "print(\"Load positive pre-computed embeddings from disc\")\n",
        "with open(embedding_positive_path, \"rb\") as fInp:\n",
        "    cache_data = pickle.load(fInp)\n",
        "    positiveSentences = cache_data['sentences']\n",
        "    positiveEmbeddings = cache_data['embeddings']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_q2Drekc-K3p"
      },
      "source": [
        "print(\"Load negtive pre-computed embeddings from disc\")\n",
        "with open(embedding_negative_path, \"rb\") as fInn:\n",
        "    cache_data = pickle.load(fInn)\n",
        "    negativeSentences = cache_data['sentences']\n",
        "    negativeEmbeddings = cache_data['embeddings']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xTX52eC94Wr"
      },
      "source": [
        "# Find similarities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0_CY1LSEsfI"
      },
      "source": [
        "# Find the most similar docs tn = 8\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFrNxoZUGJoV"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "\n",
        "top_k = min(1000, len(allPositiveReviews))\n",
        "\n",
        "\n",
        "\n",
        "dfTopic8 = pd.read_csv(csvTopic8)\n",
        "print(dfTopic8.shape)\n",
        "dfTopic8 = dfTopic8.dropna()\n",
        "dfSimTopic8 = pd.DataFrame()\n",
        "keywordsTopic8 = []\n",
        "\n",
        "keywordsTopic8 = dfTopic8['Keywords']\n",
        "\n",
        "dfSimTopicPos = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorPos = np.zeros(768)\n",
        "\n",
        "dfSimTopicNeg = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorNeg = np.zeros(768)\n",
        "\n",
        "\n",
        "\n",
        "for item in keywordsTopic8 :\n",
        "  item = item.replace('[','')\n",
        "  item = item.replace(']','') \n",
        "  item = item.replace(\"'\",'')\n",
        "  item = item.replace(\",\",'')\n",
        "  inferred_docvecPos = positiveModel.encode(item, convert_to_numpy=True)\n",
        "  inferred_docvecNeg = negativeModel.encode(item, convert_to_numpy=True)\n",
        "\n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecPos, positiveEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    #dfSimTopicPos = dfSimTopicPos.append({\"docid\": idx, \"SimilarityScore\": score, \"Text\":allPositiveReviews[idx], \"Sentiment\":\"1\"}, ignore_index = True)\n",
        "    dfSimTopicPos = dfSimTopicPos.append({\"docid\":  dfReviews.index[dfReviews[\"Text\"] == allPositiveReviews[idx]].tolist()[0], \n",
        "                                          \"SimilarityScore\": score, \"Text\":allPositiveReviews[idx], \n",
        "                                          \"Sentiment\":\"1\"}, ignore_index = True)\n",
        "        \n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecNeg, negativeEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    #dfSimTopicNeg = dfSimTopicNeg.append({\"docid\": idx + 283300, \"SimilarityScore\": score, \"Text\":allNegativeReviews[idx], \"Sentiment\":\"0\"}, ignore_index = True)\n",
        "    dfSimTopicNeg = dfSimTopicNeg.append({\"docid\": dfReviews.index[dfReviews[\"Text\"] == allNegativeReviews[idx]].tolist()[0] , \n",
        "                                          \"SimilarityScore\": score, \"Text\":allNegativeReviews[idx], \n",
        "                                          \"Sentiment\":\"0\"}, ignore_index = True)\n",
        "\n",
        "  #end of for\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Number of unique Positive documents\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "dfSimTopicNeg.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "\n",
        "print(\"Number of unique Positive documents after droping duplicates\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents after droping duplicates\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "#Sampling 1000 positive and 1000 negatives\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos = dfSimTopicPos.iloc[0:1000, :]\n",
        "dfSimTopicNeg = dfSimTopicNeg.iloc[0:1000, :]\n",
        "\n",
        "#end Sampling 1000 positive and 1000 negatives\n",
        "\n",
        "\n",
        "print(\"Max Positive:\" , max(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Max Negatives:\" , max(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Min Positive:\" , min(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Min Negatives:\" , min(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Mean Positive:\", dfSimTopicPos[\"SimilarityScore\"].mean())\n",
        "print(\"Mean Negative:\", dfSimTopicNeg[\"SimilarityScore\"].mean())\n",
        "\n",
        "print(\"Std Positive:\",dfSimTopicPos[\"SimilarityScore\"].std())\n",
        "print(\"Std Negative:\",dfSimTopicNeg[\"SimilarityScore\"].std())\n",
        "\n",
        "\n",
        "print(\"len Positive:\" , len(dfSimTopicPos))\n",
        "print(\"len Negatives:\" , len(dfSimTopicNeg))\n",
        "\n",
        "dfAll8 = dfSimTopicNeg.append(dfSimTopicPos)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8ZYoAm1gD5u"
      },
      "source": [
        "dfAll8.to_csv(csvTopic8MostSimilar, header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQT8TtiuFS9j"
      },
      "source": [
        "# Find the most similar docs tn = 20"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Di2OwCl9mS-Q",
        "outputId": "73cc92e6-1bd6-4e64-b224-2bddc672e8ae"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "\n",
        "top_k = min(200, len(allPositiveReviews))\n",
        "\n",
        "dfTopic20 = pd.read_csv(csvTopic20)\n",
        "print(dfTopic20.shape)\n",
        "dfTopic20 = dfTopic20.dropna()\n",
        "dfSimTopic20 = pd.DataFrame()\n",
        "keywordsTopic20 = []\n",
        "\n",
        "keywordsTopic20 = dfTopic20['Keywords']\n",
        "\n",
        "dfSimTopicPos = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorPos = np.zeros(768)\n",
        "\n",
        "dfSimTopicNeg = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorNeg = np.zeros(768)\n",
        "\n",
        "\n",
        "\n",
        "for item in keywordsTopic20 :\n",
        "  item = item.replace('[','')\n",
        "  item = item.replace(']','') \n",
        "  item = item.replace(\"'\",'')\n",
        "  item = item.replace(\",\",'')\n",
        "  inferred_docvecPos = positiveModel.encode(item, convert_to_numpy=True)\n",
        "  inferred_docvecNeg = negativeModel.encode(item, convert_to_numpy=True)\n",
        "\n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecPos, positiveEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicPos = dfSimTopicPos.append({\"docid\": dfReviews.index[dfReviews[\"Text\"] == allPositiveReviews[idx]].tolist()[0]\n",
        ", \"SimilarityScore\": score, \"Text\":allPositiveReviews[idx], \"Sentiment\":\"1\"}, ignore_index = True)\n",
        "        \n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecNeg, negativeEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicNeg = dfSimTopicNeg.append({\"docid\": dfReviews.index[dfReviews[\"Text\"] == allNegativeReviews[idx]].tolist()[0], \n",
        "                                          \"SimilarityScore\": score, \"Text\":allNegativeReviews[idx], \n",
        "                                          \"Sentiment\":\"0\"}, ignore_index = True)\n",
        "\n",
        "\n",
        "\n",
        "  #end of for\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Number of unique Positive documents\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "dfSimTopicNeg.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "\n",
        "print(\"Number of unique Positive documents after droping duplicates\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents after droping duplicates\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "#Sampling 1000 positive and 1000 negatives\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos = dfSimTopicPos.iloc[0:1000, :]\n",
        "dfSimTopicNeg = dfSimTopicNeg.iloc[0:1000, :]\n",
        "\n",
        "#end Sampling 1000 positive and 1000 negatives\n",
        "\n",
        "\n",
        "print(\"Max Positive:\" , max(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Max Negatives:\" , max(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Min Positive:\" , min(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Min Negatives:\" , min(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Mean Positive:\", dfSimTopicPos[\"SimilarityScore\"].mean())\n",
        "print(\"Mean Positive:\", dfSimTopicNeg[\"SimilarityScore\"].mean())\n",
        "\n",
        "print(\"Std Positive:\",dfSimTopicPos[\"SimilarityScore\"].std())\n",
        "print(\"Std Negative:\",dfSimTopicNeg[\"SimilarityScore\"].std())\n",
        "\n",
        "\n",
        "print(\"len Positive:\" , len(dfSimTopicPos))\n",
        "print(\"len Negatives:\" , len(dfSimTopicNeg))\n",
        "\n",
        "dfAll20 = dfSimTopicNeg.append(dfSimTopicPos)\n",
        "dfAll20.to_csv(csvTopic20MostSimilar, header=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(20, 4)\n",
            "Number of unique Positive documents 1748\n",
            "Number of unique Negative documents 1245\n",
            "Number of unique Positive documents after droping duplicates 1748\n",
            "Number of unique Negative documents after droping duplicates 1245\n",
            "Max Positive: tensor(0.8675)\n",
            "Max Negatives: tensor(0.8354)\n",
            "Min Positive: tensor(0.7427)\n",
            "Min Negatives: tensor(0.6934)\n",
            "Mean Positive: 0.775739013671875\n",
            "Mean Positive: 0.7471387939453125\n",
            "Std Positive: 0.01920236557897068\n",
            "Std Negative: 0.029181202634249354\n",
            "len Positive: 1000\n",
            "len Negatives: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyME1mZ5FUrl"
      },
      "source": [
        "# Find the most similar docs tn = 40"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJOS7VAImqiz",
        "outputId": "cd813ebf-f4e8-46ca-e20f-2704b658f7c6"
      },
      "source": [
        "\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "\n",
        "top_k = min(200, len(allPositiveReviews))\n",
        "dfTopic40 = pd.read_csv(csvTopic40)\n",
        "print(dfTopic40.shape)\n",
        "dfTopic40 = dfTopic40.dropna()\n",
        "dfSimTopic40 = pd.DataFrame()\n",
        "keywordsTopic40 = []\n",
        "\n",
        "keywordsTopic40 = dfTopic40['Keywords']\n",
        "\n",
        "dfSimTopicPos = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorPos = np.zeros(768)\n",
        "\n",
        "dfSimTopicNeg = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorNeg = np.zeros(768)\n",
        "\n",
        "\n",
        "\n",
        "for item in keywordsTopic40 :\n",
        "  item = item.replace('[','')\n",
        "  item = item.replace(']','') \n",
        "  item = item.replace(\"'\",'')\n",
        "  item = item.replace(\",\",'')\n",
        "  inferred_docvecPos = positiveModel.encode(item, convert_to_numpy=True)\n",
        "  inferred_docvecNeg = negativeModel.encode(item, convert_to_numpy=True)\n",
        "\n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecPos, positiveEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicPos = dfSimTopicPos.append({\"docid\": dfReviews.index[dfReviews[\"Text\"] == allPositiveReviews[idx]].tolist()[0], \n",
        "                                          \"SimilarityScore\": score, \n",
        "                                          \"Text\":allPositiveReviews[idx], \"Sentiment\":\"1\"}, ignore_index = True)\n",
        "        \n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecNeg, negativeEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicNeg = dfSimTopicNeg.append({\"docid\": dfReviews.index[dfReviews[\"Text\"] == allNegativeReviews[idx]].tolist()[0], \n",
        "                                          \"SimilarityScore\": score, \n",
        "                                          \"Text\":allNegativeReviews[idx], \"Sentiment\":\"0\"}, ignore_index = True)\n",
        "\n",
        "\n",
        "  #end of for\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Number of unique Positive documents\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "dfSimTopicNeg.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "\n",
        "print(\"Number of unique Positive documents after droping duplicates\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents after droping duplicates\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "#Sampling 1000 positive and 1000 negatives\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos = dfSimTopicPos.iloc[0:1000, :]\n",
        "dfSimTopicNeg = dfSimTopicNeg.iloc[0:1000, :]\n",
        "\n",
        "#end Sampling 1000 positive and 1000 negatives\n",
        "\n",
        "\n",
        "print(\"Max Positive:\" , max(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Max Negatives:\" , max(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Min Positive:\" , min(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Min Negatives:\" , min(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Mean Positive:\", dfSimTopicPos[\"SimilarityScore\"].mean())\n",
        "print(\"Mean Positive:\", dfSimTopicNeg[\"SimilarityScore\"].mean())\n",
        "\n",
        "print(\"Std Positive:\",dfSimTopicPos[\"SimilarityScore\"].std())\n",
        "print(\"Std Negative:\",dfSimTopicNeg[\"SimilarityScore\"].std())\n",
        "\n",
        "\n",
        "print(\"len Positive:\" , len(dfSimTopicPos))\n",
        "print(\"len Negatives:\" , len(dfSimTopicNeg))\n",
        "\n",
        "dfAll40 = dfSimTopicNeg.append(dfSimTopicPos)\n",
        "dfAll40.to_csv(csvTopic40MostSimilar, header=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40, 4)\n",
            "Number of unique Positive documents 3407\n",
            "Number of unique Negative documents 2173\n",
            "Number of unique Positive documents after droping duplicates 3407\n",
            "Number of unique Negative documents after droping duplicates 2173\n",
            "Max Positive: tensor(0.8726)\n",
            "Max Negatives: tensor(0.8509)\n",
            "Min Positive: tensor(0.7854)\n",
            "Min Negatives: tensor(0.7416)\n",
            "Mean Positive: 0.80797509765625\n",
            "Mean Positive: 0.7754810180664062\n",
            "Std Positive: 0.015483119986633745\n",
            "Std Negative: 0.02287271564458264\n",
            "len Positive: 1000\n",
            "len Negatives: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDAPVn0mFWWU"
      },
      "source": [
        "# Find the most similar docs tn = 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7aDWFX-nB3f"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "\n",
        "top_k = min(200, len(allPositiveReviews))\n",
        "\n",
        "dfTopic50 = pd.read_csv(csvTopic50)\n",
        "print(dfTopic50.shape)\n",
        "dfTopic50 = dfTopic50.dropna()\n",
        "dfSimTopic50 = pd.DataFrame()\n",
        "keywordsTopic50 = []\n",
        "\n",
        "keywordsTopic50 = dfTopic50['Keywords']\n",
        "\n",
        "dfSimTopicPos = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorPos = np.zeros(768)\n",
        "\n",
        "dfSimTopicNeg = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorNeg = np.zeros(768)\n",
        "\n",
        "\n",
        "\n",
        "for item in keywordsTopic50 :\n",
        "  item = item.replace('[','')\n",
        "  item = item.replace(']','') \n",
        "  item = item.replace(\"'\",'')\n",
        "  item = item.replace(\",\",'')\n",
        "  inferred_docvecPos = positiveModel.encode(item, convert_to_numpy=True)\n",
        "  inferred_docvecNeg = negativeModel.encode(item, convert_to_numpy=True)\n",
        "\n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecPos, positiveEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicPos = dfSimTopicPos.append({\"docid\": dfReviews.index[dfReviews[\"Text\"] == allPositiveReviews[idx]].tolist()[0],\n",
        "                                          \"SimilarityScore\": score, \n",
        "                                          \"Text\":allPositiveReviews[idx], \"Sentiment\":\"1\"}, ignore_index = True)\n",
        "        \n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecNeg, negativeEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicNeg = dfSimTopicNeg.append({\"docid\": dfReviews.index[dfReviews[\"Text\"] == allNegativeReviews[idx]].tolist()[0], \n",
        "                                          \"SimilarityScore\": score, \"Text\":allNegativeReviews[idx], \n",
        "                                          \"Sentiment\":\"0\"}, ignore_index = True)\n",
        "\n",
        "  #end of for\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Number of unique Positive documents\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "dfSimTopicNeg.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "\n",
        "print(\"Number of unique Positive documents after droping duplicates\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents after droping duplicates\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "#Sampling 1000 positive and 1000 negatives\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos = dfSimTopicPos.iloc[0:1000, :]\n",
        "dfSimTopicNeg = dfSimTopicNeg.iloc[0:1000, :]\n",
        "\n",
        "#end Sampling 1000 positive and 1000 negatives\n",
        "\n",
        "\n",
        "print(\"Max Positive:\" , max(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Max Negatives:\" , max(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Min Positive:\" , min(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Min Negatives:\" , min(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Mean Positive:\", dfSimTopicPos[\"SimilarityScore\"].mean())\n",
        "print(\"Mean Positive:\", dfSimTopicNeg[\"SimilarityScore\"].mean())\n",
        "\n",
        "print(\"Std Positive:\",dfSimTopicPos[\"SimilarityScore\"].std())\n",
        "print(\"Std Negative:\",dfSimTopicNeg[\"SimilarityScore\"].std())\n",
        "\n",
        "\n",
        "print(\"len Positive:\" , len(dfSimTopicPos))\n",
        "print(\"len Negatives:\" , len(dfSimTopicNeg))\n",
        "\n",
        "dfAll50 = dfSimTopicNeg.append(dfSimTopicPos)\n",
        "dfAll50.to_csv(csvTopic50MostSimilar, header=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9oj1SUTFYWm"
      },
      "source": [
        "# Find the most similar docs tn = 60"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3ktIBbvpYu7"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "\n",
        "top_k = min(200, len(allPositiveReviews))\n",
        "\n",
        "\n",
        "dfTopic60 = pd.read_csv(csvTopic60)\n",
        "print(dfTopic60.shape)\n",
        "dfTopic60 = dfTopic60.dropna()\n",
        "dfSimTopic60 = pd.DataFrame()\n",
        "keywordsTopic60 = []\n",
        "\n",
        "keywordsTopic60 = dfTopic60['Keywords']\n",
        "\n",
        "dfSimTopicPos = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorPos = np.zeros(768)\n",
        "\n",
        "dfSimTopicNeg = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorNeg = np.zeros(768)\n",
        "\n",
        "\n",
        "\n",
        "for item in keywordsTopic60 :\n",
        "  item = item.replace('[','')\n",
        "  item = item.replace(']','') \n",
        "  item = item.replace(\"'\",'')\n",
        "  item = item.replace(\",\",'')\n",
        "  inferred_docvecPos = positiveModel.encode(item, convert_to_numpy=True)\n",
        "  inferred_docvecNeg = negativeModel.encode(item, convert_to_numpy=True)\n",
        "\n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecPos, positiveEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicPos = dfSimTopicPos.append({\"docid\": dfReviews.index[dfReviews[\"Text\"] == allPositiveReviews[idx]].tolist()[0], \n",
        "                                          \"SimilarityScore\": score, \"Text\":allPositiveReviews[idx], \n",
        "                                          \"Sentiment\":\"1\"}, ignore_index = True)\n",
        "        \n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecNeg, negativeEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicNeg = dfSimTopicNeg.append({\"docid\": dfReviews.index[dfReviews[\"Text\"] == allNegativeReviews[idx]].tolist()[0], \n",
        "                                          \"SimilarityScore\": score, \"Text\":allNegativeReviews[idx], \n",
        "                                          \"Sentiment\":\"0\"}, ignore_index = True)\n",
        "\n",
        "\n",
        "\n",
        "  #end of for\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Number of unique Positive documents\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "dfSimTopicNeg.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "\n",
        "print(\"Number of unique Positive documents after droping duplicates\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents after droping duplicates\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "#Sampling 1000 positive and 1000 negatives\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos = dfSimTopicPos.iloc[0:1000, :]\n",
        "dfSimTopicNeg = dfSimTopicNeg.iloc[0:1000, :]\n",
        "\n",
        "#end Sampling 1000 positive and 1000 negatives\n",
        "\n",
        "\n",
        "print(\"Max Positive:\" , max(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Max Negatives:\" , max(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Min Positive:\" , min(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Min Negatives:\" , min(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Mean Positive:\", dfSimTopicPos[\"SimilarityScore\"].mean())\n",
        "print(\"Mean Positive:\", dfSimTopicNeg[\"SimilarityScore\"].mean())\n",
        "\n",
        "print(\"Std Positive:\",dfSimTopicPos[\"SimilarityScore\"].std())\n",
        "print(\"Std Negative:\",dfSimTopicNeg[\"SimilarityScore\"].std())\n",
        "\n",
        "\n",
        "print(\"len Positive:\" , len(dfSimTopicPos))\n",
        "print(\"len Negatives:\" , len(dfSimTopicNeg))\n",
        "\n",
        "dfAll60 = dfSimTopicNeg.append(dfSimTopicPos)\n",
        "dfAll60.to_csv(csvTopic60MostSimilar, header=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mye0KNDdFZm4"
      },
      "source": [
        "# Find the most similar docs tn = 65"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OM4bWg5aprEW"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "\n",
        "top_k = min(200, len(allPositiveReviews))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "dfTopic65 = pd.read_csv(csvTopic65)\n",
        "print(dfTopic65.shape)\n",
        "dfTopic65 = dfTopic65.dropna()\n",
        "dfSimTopic65 = pd.DataFrame()\n",
        "keywordsTopic65 = []\n",
        "\n",
        "keywordsTopic65 = dfTopic65['Keywords']\n",
        "\n",
        "dfSimTopicPos = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorPos = np.zeros(768)\n",
        "\n",
        "dfSimTopicNeg = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorNeg = np.zeros(768)\n",
        "\n",
        "\n",
        "\n",
        "for item in keywordsTopic65 :\n",
        "  item = item.replace('[','')\n",
        "  item = item.replace(']','') \n",
        "  item = item.replace(\"'\",'')\n",
        "  item = item.replace(\",\",'')\n",
        "  inferred_docvecPos = positiveModel.encode(item, convert_to_numpy=True)\n",
        "  inferred_docvecNeg = negativeModel.encode(item, convert_to_numpy=True)\n",
        "\n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecPos, positiveEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicPos = dfSimTopicPos.append({\"docid\": dfReviews.index[dfReviews[\"Text\"] == allPositiveReviews[idx]].tolist()[0], \n",
        "                                          \"SimilarityScore\": score, \"Text\":allPositiveReviews[idx], \n",
        "                                          \"Sentiment\":\"1\"}, ignore_index = True)\n",
        "        \n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecNeg, negativeEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicNeg = dfSimTopicNeg.append({\"docid\": dfReviews.index[dfReviews[\"Text\"] == allNegativeReviews[idx]].tolist()[0], \n",
        "                                          \"SimilarityScore\": score, \"Text\":allNegativeReviews[idx], \n",
        "                                          \"Sentiment\":\"0\"}, ignore_index = True)\n",
        "\n",
        "\n",
        "\n",
        "  #end of for\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Number of unique Positive documents\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "dfSimTopicNeg.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "\n",
        "print(\"Number of unique Positive documents after droping duplicates\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents after droping duplicates\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "#Sampling 1000 positive and 1000 negatives\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos = dfSimTopicPos.iloc[0:1000, :]\n",
        "dfSimTopicNeg = dfSimTopicNeg.iloc[0:1000, :]\n",
        "\n",
        "#end Sampling 1000 positive and 1000 negatives\n",
        "\n",
        "\n",
        "print(\"Max Positive:\" , max(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Max Negatives:\" , max(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Min Positive:\" , min(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Min Negatives:\" , min(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Mean Positive:\", dfSimTopicPos[\"SimilarityScore\"].mean())\n",
        "print(\"Mean Positive:\", dfSimTopicNeg[\"SimilarityScore\"].mean())\n",
        "\n",
        "print(\"Std Positive:\",dfSimTopicPos[\"SimilarityScore\"].std())\n",
        "print(\"Std Negative:\",dfSimTopicNeg[\"SimilarityScore\"].std())\n",
        "\n",
        "\n",
        "print(\"len Positive:\" , len(dfSimTopicPos))\n",
        "print(\"len Negatives:\" , len(dfSimTopicNeg))\n",
        "\n",
        "dfAll65 = dfSimTopicNeg.append(dfSimTopicPos)\n",
        "dfAll65.to_csv(csvTopic65MostSimilar, header=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RHcSo4-Fa_a"
      },
      "source": [
        "# Find the most similar docs tn = 70"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgopwngQqKuk"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "\n",
        "top_k = min(200, len(allPositiveReviews))\n",
        "\n",
        "dfTopic70 = pd.read_csv(csvTopic70)\n",
        "print(dfTopic70.shape)\n",
        "dfTopic70 = dfTopic70.dropna()\n",
        "dfSimTopic70 = pd.DataFrame()\n",
        "keywordsTopic70 = []\n",
        "\n",
        "keywordsTopic70 = dfTopic70['Keywords']\n",
        "\n",
        "dfSimTopicPos = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorPos = np.zeros(768)\n",
        "\n",
        "dfSimTopicNeg = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorNeg = np.zeros(768)\n",
        "\n",
        "\n",
        "\n",
        "for item in keywordsTopic70 :\n",
        "  item = item.replace('[','')\n",
        "  item = item.replace(']','') \n",
        "  item = item.replace(\"'\",'')\n",
        "  item = item.replace(\",\",'')\n",
        "  inferred_docvecPos = positiveModel.encode(item, convert_to_numpy=True)\n",
        "  inferred_docvecNeg = negativeModel.encode(item, convert_to_numpy=True)\n",
        "\n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecPos, positiveEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicPos = dfSimTopicPos.append({\"docid\": dfReviews.index[dfReviews[\"Text\"] == allPositiveReviews[idx]].tolist()[0], \n",
        "                                          \"SimilarityScore\": score, \"Text\":allPositiveReviews[idx], \n",
        "                                          \"Sentiment\":\"1\"}, ignore_index = True)\n",
        "        \n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecNeg, negativeEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicNeg = dfSimTopicNeg.append({\"docid\": dfReviews.index[dfReviews[\"Text\"] == allNegativeReviews[idx]].tolist()[0], \n",
        "                                          \"SimilarityScore\": score, \"Text\":allNegativeReviews[idx], \n",
        "                                          \"Sentiment\":\"0\"}, ignore_index = True)\n",
        "\n",
        "\n",
        "\n",
        "  #end of for\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Number of unique Positive documents\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "dfSimTopicNeg.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "\n",
        "print(\"Number of unique Positive documents after droping duplicates\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents after droping duplicates\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "#Sampling 1000 positive and 1000 negatives\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos = dfSimTopicPos.iloc[0:1000, :]\n",
        "dfSimTopicNeg = dfSimTopicNeg.iloc[0:1000, :]\n",
        "\n",
        "#end Sampling 1000 positive and 1000 negatives\n",
        "\n",
        "\n",
        "print(\"Max Positive:\" , max(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Max Negatives:\" , max(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Min Positive:\" , min(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Min Negatives:\" , min(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Mean Positive:\", dfSimTopicPos[\"SimilarityScore\"].mean())\n",
        "print(\"Mean Positive:\", dfSimTopicNeg[\"SimilarityScore\"].mean())\n",
        "\n",
        "print(\"Std Positive:\",dfSimTopicPos[\"SimilarityScore\"].std())\n",
        "print(\"Std Negative:\",dfSimTopicNeg[\"SimilarityScore\"].std())\n",
        "\n",
        "\n",
        "print(\"len Positive:\" , len(dfSimTopicPos))\n",
        "print(\"len Negatives:\" , len(dfSimTopicNeg))\n",
        "\n",
        "dfAll70 = dfSimTopicNeg.append(dfSimTopicPos)\n",
        "dfAll70.to_csv(csvTopic70MostSimilar, header=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAWPmqdjFcjw"
      },
      "source": [
        "# Find the most similar docs tn = 80"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6Fvh6CmqjbE"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "\n",
        "top_k = min(200, len(allPositiveReviews))\n",
        "\n",
        "\n",
        "\n",
        "dfTopic80 = pd.read_csv(csvTopic80)\n",
        "print(dfTopic80.shape)\n",
        "dfTopic80 = dfTopic80.dropna()\n",
        "dfSimTopic80 = pd.DataFrame()\n",
        "keywordsTopic80 = []\n",
        "\n",
        "keywordsTopic80 = dfTopic80['Keywords']\n",
        "\n",
        "dfSimTopicPos = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorPos = np.zeros(768)\n",
        "\n",
        "dfSimTopicNeg = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorNeg = np.zeros(768)\n",
        "\n",
        "\n",
        "\n",
        "for item in keywordsTopic80 :\n",
        "  item = item.replace('[','')\n",
        "  item = item.replace(']','') \n",
        "  item = item.replace(\"'\",'')\n",
        "  item = item.replace(\",\",'')\n",
        "  inferred_docvecPos = positiveModel.encode(item, convert_to_numpy=True)\n",
        "  inferred_docvecNeg = negativeModel.encode(item, convert_to_numpy=True)\n",
        "\n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecPos, positiveEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicPos = dfSimTopicPos.append({\"docid\": dfReviews.index[dfReviews[\"Text\"] == allPositiveReviews[idx]].tolist()[0], \n",
        "                                          \"SimilarityScore\": score, \"Text\":allPositiveReviews[idx], \n",
        "                                          \"Sentiment\":\"1\"}, ignore_index = True)\n",
        "        \n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecNeg, negativeEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicNeg = dfSimTopicNeg.append({\"docid\": dfReviews.index[dfReviews[\"Text\"] == allNegativeReviews[idx]].tolist()[0], \n",
        "                                          \"SimilarityScore\": score, \"Text\":allNegativeReviews[idx], \n",
        "                                          \"Sentiment\":\"0\"}, ignore_index = True)\n",
        "\n",
        "\n",
        "\n",
        "print(\"end of for\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Number of unique Positive documents\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "dfSimTopicNeg.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "\n",
        "print(\"Number of unique Positive documents after droping duplicates\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents after droping duplicates\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "#Sampling 1000 positive and 1000 negatives\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos = dfSimTopicPos.iloc[0:1000, :]\n",
        "dfSimTopicNeg = dfSimTopicNeg.iloc[0:1000, :]\n",
        "\n",
        "#end Sampling 1000 positive and 1000 negatives\n",
        "\n",
        "\n",
        "print(\"Max Positive:\" , max(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Max Negatives:\" , max(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Min Positive:\" , min(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Min Negatives:\" , min(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Mean Positive:\", dfSimTopicPos[\"SimilarityScore\"].mean())\n",
        "print(\"Mean Positive:\", dfSimTopicNeg[\"SimilarityScore\"].mean())\n",
        "\n",
        "print(\"Std Positive:\",dfSimTopicPos[\"SimilarityScore\"].std())\n",
        "print(\"Std Negative:\",dfSimTopicNeg[\"SimilarityScore\"].std())\n",
        "\n",
        "\n",
        "print(\"len Positive:\" , len(dfSimTopicPos))\n",
        "print(\"len Negatives:\" , len(dfSimTopicNeg))\n",
        "\n",
        "dfAll80 = dfSimTopicNeg.append(dfSimTopicPos)\n",
        "dfAll80.to_csv(csvTopic80MostSimilar, header=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}