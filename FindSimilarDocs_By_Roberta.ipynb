{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "S2kue_J3ls55",
        "P4PpCJX5855K",
        "OyME1mZ5FUrl",
        "n9oj1SUTFYWm",
        "Mye0KNDdFZm4",
        "kAWPmqdjFcjw"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5Fp4PNOzHf6"
      },
      "source": [
        "https://radimrehurek.com/gensim/auto_examples/howtos/run_doc2vec_imdb.html\n",
        "\n",
        "https://radimrehurek.com/gensim/models/doc2vec.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuu6z-ZZoZHq"
      },
      "source": [
        "## Configurations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbkcv3irn-mi"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf6N4pe_oSu6"
      },
      "source": [
        "import logging\n",
        "#logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tBIYWabuTES"
      },
      "source": [
        "pip install sentence-transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOZnc3w7CA9Y"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gensim\n",
        "from sklearn.model_selection import train_test_split\n",
        "import multiprocessing\n",
        "from collections import OrderedDict\n",
        "\n",
        "import gensim.models.doc2vec\n",
        "assert gensim.models.doc2vec.FAST_VERSION > -1, \"This will be painfully slow otherwise\"\n",
        "\n",
        "from gensim.models.doc2vec import Doc2Vec\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import collections\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxGpI5Zq6IQl"
      },
      "source": [
        "pip install testfixtures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0FG4Qzc_bYD"
      },
      "source": [
        "#'/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Processed-Merged-Dataset-99-08-28.csv'\n",
        "\n",
        "inputFileName = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Balenced-Dataset-00-06-26.csv'\n",
        "\n",
        "\n",
        "outputLabelledTTDS= '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Balenced-Dataset-00-06-26.csv'\n",
        "outputDocsFileName = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/DocsReadyForD2V-00-06-26.csv'\n",
        "\n",
        "d2vModelFNmPos = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModelPositive-00-06-26.model'\n",
        "d2vModelFNtPos = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModelPositive-00-06-26.txt'\n",
        "\n",
        "d2vModelFNmNeg = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModelNegative-00-06-26.model'\n",
        "d2vModelFNtNeg = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModelNegative-00-06-26.txt'\n",
        "\n",
        "csvTopic8 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Topics_8.csv'\n",
        "csvTopic20 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Topics_20.csv'\n",
        "csvTopic40 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Topics_40.csv'\n",
        "csvTopic80 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Topics_80.csv'\n",
        "csvTopic50 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Topics_50.csv'\n",
        "csvTopic60 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Topics_60.csv'\n",
        "csvTopic65 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Topics_65.csv'\n",
        "csvTopic70 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Topics_70.csv'\n",
        "\n",
        "\n",
        "d2vModelFNm0 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModel0-00-06-23.model'\n",
        "d2vModelFNt0 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModel0-00-06-23.txt'\n",
        "\n",
        "d2vModelFNm1 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModel1-00-06-23.model'\n",
        "d2vModelFNt1 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModel1-00-06-23.txt'\n",
        "\n",
        "d2vModelFNm2 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModel2-00-06-23.model'\n",
        "d2vModelFNt2 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModel2-00-06-23.txt'\n",
        "\n",
        "d2vModelFNm3 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModel3-00-06-23.model'\n",
        "d2vModelFNt3 = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/d2vModel3-00-06-23.txt'\n",
        "\n",
        "csvTopic8MostSimilar = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/SimilarDocsByRoberta/Topics_8_MostSimilar_Ro.csv'\n",
        "csvTopic20MostSimilar = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/SimilarDocsByRoberta/Topics_20_MostSimilar_Ro.csv'\n",
        "csvTopic40MostSimilar = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/SimilarDocsByRoberta/Topics_40_MostSimilar_Ro.csv'\n",
        "csvTopic50MostSimilar = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/SimilarDocsByRoberta/Topics_50_MostSimilar_Ro.csv'\n",
        "csvTopic60MostSimilar = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/SimilarDocsByRoberta/Topics_60_MostSimilar_Ro.csv'\n",
        "csvTopic65MostSimilar = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/SimilarDocsByRoberta/Topics_65_MostSimilar_Ro.csv'\n",
        "csvTopic70MostSimilar = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/SimilarDocsByRoberta/Topics_70_MostSimilar_Ro.csv'\n",
        "csvTopic80MostSimilar = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/SimilarDocsByRoberta/Topics_80_MostSimilar_Ro.csv'\n",
        "#SimilarDocsByRoberta-Albert\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiSEEeOX5UxO"
      },
      "source": [
        "# Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-ztS1ZQ_5Xz"
      },
      "source": [
        "#No need in local\n",
        "from google.colab import drive\n",
        "drive.mount('/MYDRIVE', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmK-tAmXydXh"
      },
      "source": [
        "# Prepair Dataset (Dividing into Test and Train)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9N4Y2ry_9yW"
      },
      "source": [
        "dfReviews = pd.DataFrame()\n",
        "dfReviews = pd.read_csv(inputFileName, encoding = 'utf-8', header = 0 )\n",
        "dfReviews.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5k6XdrymFqu"
      },
      "source": [
        "inputFileName"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKonEE_yHIW2"
      },
      "source": [
        "dfReviews.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0b20GkvxEm1"
      },
      "source": [
        "dfReviews = dfReviews.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pL4BWFkNxJdr"
      },
      "source": [
        "dfReviews.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQFrAAjUHpAu"
      },
      "source": [
        "len (dfReviews.loc[dfReviews[\"Sentiment\"] == 0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RcaSW8uISBH"
      },
      "source": [
        "len (dfReviews.loc[dfReviews[\"Sentiment\"] == 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leTzHA-2aH88"
      },
      "source": [
        "dfReviews[4] = 'train'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8bMsPoClaLT"
      },
      "source": [
        "dfReviews.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFWPmH-nleBf"
      },
      "source": [
        "dfReviews.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWjQ6aA7bDwI"
      },
      "source": [
        "testNumber=113320\n",
        "trainNumber=453280"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCylZNA_sOF1"
      },
      "source": [
        "dfReviews.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2kue_J3ls55"
      },
      "source": [
        "# Preparing test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDJllF_IIzKf"
      },
      "source": [
        "# Making embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6q0tLIMsuTFD"
      },
      "source": [
        "dfPositiveReviews = dfReviews[dfReviews[\"Sentiment\"] == 1]\n",
        "print(len(dfPositiveReviews))\n",
        "dfNegativeReviews = dfReviews[dfReviews[\"Sentiment\"] == 0]\n",
        "print(len(dfNegativeReviews))\n",
        "\n",
        "allPositiveReviews = list()\n",
        "for line in dfPositiveReviews[\"Text\"]:\n",
        "  allPositiveReviews.append( str(line) )\n",
        "\n",
        "\n",
        "allNegativeReviews = list()\n",
        "for line in dfNegativeReviews[\"Text\"]:\n",
        "  allNegativeReviews.append( str(line) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z55MhtYuTFF"
      },
      "source": [
        "%time\n",
        "#model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
        "positiveModel = SentenceTransformer(\"/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/nli-roberta-base-v2\")\n",
        "negativeModel = SentenceTransformer(\"/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/nli-roberta-base-v2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9sJopKsuTFN"
      },
      "source": [
        "%time\n",
        "positiveEmbeddings = positiveModel.encode(allPositiveReviews, convert_to_numpy=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UA5QMloruTFO"
      },
      "source": [
        "%time\n",
        "negativeEmbeddings = negativeModel.encode(allNegativeReviews, convert_to_numpy=True)\n",
        "\n",
        "print(positiveEmbeddings.shape)\n",
        "\n",
        "print(negativeEmbeddings.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVfCNShf8zHs"
      },
      "source": [
        "# Save embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krU14g_GuTFQ"
      },
      "source": [
        "%time\n",
        "\n",
        "import os\n",
        "import csv\n",
        "import pickle\n",
        "embedding_positive_path = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Positive-Embeddings-Roberta.pkl'\n",
        "embedding_negative_path = '/MYDRIVE/My Drive/Colab Notebooks/Proposal/Data/Negative-Embeddings-Roberta.pkl'\n",
        "print(\"Store file on disc\")\n",
        "with open(embedding_positive_path, \"wb\") as fOutPositive:\n",
        "    pickle.dump({'sentences': allPositiveReviews, 'embeddings': positiveEmbeddings}, fOutPositive)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikg_YDBWuTFS"
      },
      "source": [
        "%time\n",
        "\n",
        "with open(embedding_negative_path, \"wb\") as fOutNegative:\n",
        "    pickle.dump({'sentences': allNegativeReviews, 'embeddings': negativeEmbeddings}, fOutNegative)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4PpCJX5855K"
      },
      "source": [
        "# Load Pretrained embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmaJLRyL8-tL"
      },
      "source": [
        "print(\"Load positive pre-computed embeddings from disc\")\n",
        "with open(embedding_positive_path, \"rb\") as fInp:\n",
        "    cache_data = pickle.load(fInp)\n",
        "    positiveSentences = cache_data['sentences']\n",
        "    positiveEmbeddings = cache_data['embeddings']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_q2Drekc-K3p"
      },
      "source": [
        "print(\"Load negtive pre-computed embeddings from disc\")\n",
        "with open(embedding_negative_path, \"rb\") as fInn:\n",
        "    cache_data = pickle.load(fInn)\n",
        "    negativeSentences = cache_data['sentences']\n",
        "    negativeEmbeddings = cache_data['embeddings']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xTX52eC94Wr"
      },
      "source": [
        "# Find similarities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0_CY1LSEsfI"
      },
      "source": [
        "# Find the most similar docs tn = 8\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFrNxoZUGJoV"
      },
      "source": [
        "\n",
        "\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "\n",
        "top_k = min(1000, len(allPositiveReviews))\n",
        "\n",
        "\n",
        "\n",
        "dfTopic8 = pd.read_csv(csvTopic8)\n",
        "print(dfTopic8.shape)\n",
        "dfTopic8 = dfTopic8.dropna()\n",
        "dfSimTopic8 = pd.DataFrame()\n",
        "keywordsTopic8 = []\n",
        "\n",
        "keywordsTopic8 = dfTopic8['Keywords']\n",
        "\n",
        "dfSimTopicPos = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorPos = np.zeros(768)\n",
        "\n",
        "dfSimTopicNeg = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorNeg = np.zeros(768)\n",
        "\n",
        "\n",
        "\n",
        "for item in keywordsTopic8 :\n",
        "  item = item.replace('[','')\n",
        "  item = item.replace(']','')\n",
        "  item = item.replace(\"'\",'')\n",
        "  item = item.replace(\",\",'')\n",
        "  inferred_docvecPos = positiveModel.encode(item, convert_to_numpy=True)\n",
        "  inferred_docvecNeg = negativeModel.encode(item, convert_to_numpy=True)\n",
        "\n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecPos, positiveEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicPos = dfSimTopicPos.append({\"docid\": idx, \"SimilarityScore\": score, \"Text\":allPositiveReviews[idx]}, ignore_index = True)\n",
        "\n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecNeg, negativeEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicNeg = dfSimTopicNeg.append({\"docid\": idx + 283300, \"SimilarityScore\": score, \"Text\":allNegativeReviews[idx]}, ignore_index = True)\n",
        "\n",
        "  #end of for\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Number of unique Positive documents\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "dfSimTopicNeg.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "\n",
        "print(\"Number of unique Positive documents after droping duplicates\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents after droping duplicates\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "#Sampling 1000 positive and 1000 negatives\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos = dfSimTopicPos.iloc[0:1000, :]\n",
        "dfSimTopicNeg = dfSimTopicNeg.iloc[0:1000, :]\n",
        "\n",
        "#end Sampling 1000 positive and 1000 negatives\n",
        "\n",
        "\n",
        "print(\"Max Positive:\" , max(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Max Negatives:\" , max(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Min Positive:\" , min(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Min Negatives:\" , min(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Mean Positive:\", dfSimTopicPos[\"SimilarityScore\"].mean())\n",
        "print(\"Mean Negative:\", dfSimTopicNeg[\"SimilarityScore\"].mean())\n",
        "\n",
        "print(\"Std Positive:\",dfSimTopicPos[\"SimilarityScore\"].std())\n",
        "print(\"Std Negative:\",dfSimTopicNeg[\"SimilarityScore\"].std())\n",
        "\n",
        "\n",
        "print(\"len Positive:\" , len(dfSimTopicPos))\n",
        "print(\"len Negatives:\" , len(dfSimTopicNeg))\n",
        "\n",
        "dfAll8 = dfSimTopicNeg.append(dfSimTopicPos)\n",
        "dfAll8.to_csv(csvTopic8MostSimilar, header=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQT8TtiuFS9j"
      },
      "source": [
        "# Find the most similar docs tn = 20"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Di2OwCl9mS-Q"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "\n",
        "top_k = min(1000, len(allPositiveReviews))\n",
        "\n",
        "dfTopic20 = pd.read_csv(csvTopic20)\n",
        "print(dfTopic20.shape)\n",
        "dfTopic20 = dfTopic20.dropna()\n",
        "dfSimTopic20 = pd.DataFrame()\n",
        "keywordsTopic20 = []\n",
        "\n",
        "keywordsTopic20 = dfTopic20['Keywords']\n",
        "\n",
        "dfSimTopicPos = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorPos = np.zeros(768)\n",
        "\n",
        "dfSimTopicNeg = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorNeg = np.zeros(768)\n",
        "\n",
        "\n",
        "\n",
        "for item in keywordsTopic20 :\n",
        "  item = item.replace('[','')\n",
        "  item = item.replace(']','')\n",
        "  item = item.replace(\"'\",'')\n",
        "  item = item.replace(\",\",'')\n",
        "  inferred_docvecPos = positiveModel.encode(item, convert_to_numpy=True)\n",
        "  inferred_docvecNeg = negativeModel.encode(item, convert_to_numpy=True)\n",
        "\n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecPos, positiveEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicPos = dfSimTopicPos.append({\"docid\": idx, \"SimilarityScore\": score, \"Text\":allPositiveReviews[idx]}, ignore_index = True)\n",
        "\n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecNeg, negativeEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicNeg = dfSimTopicNeg.append({\"docid\": idx + 283300, \"SimilarityScore\": score, \"Text\":allNegativeReviews[idx]}, ignore_index = True)\n",
        "\n",
        "\n",
        "\n",
        "  #end of for\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Number of unique Positive documents\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "dfSimTopicNeg.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "\n",
        "print(\"Number of unique Positive documents after droping duplicates\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents after droping duplicates\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "#Sampling 1000 positive and 1000 negatives\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos = dfSimTopicPos.iloc[0:1000, :]\n",
        "dfSimTopicNeg = dfSimTopicNeg.iloc[0:1000, :]\n",
        "\n",
        "#end Sampling 1000 positive and 1000 negatives\n",
        "\n",
        "\n",
        "print(\"Max Positive:\" , max(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Max Negatives:\" , max(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Min Positive:\" , min(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Min Negatives:\" , min(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Mean Positive:\", dfSimTopicPos[\"SimilarityScore\"].mean())\n",
        "print(\"Mean Positive:\", dfSimTopicNeg[\"SimilarityScore\"].mean())\n",
        "\n",
        "print(\"Std Positive:\",dfSimTopicPos[\"SimilarityScore\"].std())\n",
        "print(\"Std Negative:\",dfSimTopicNeg[\"SimilarityScore\"].std())\n",
        "\n",
        "\n",
        "print(\"len Positive:\" , len(dfSimTopicPos))\n",
        "print(\"len Negatives:\" , len(dfSimTopicNeg))\n",
        "\n",
        "dfAll20 = dfSimTopicNeg.append(dfSimTopicPos)\n",
        "dfAll20.to_csv(csvTopic20MostSimilar, header=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyME1mZ5FUrl"
      },
      "source": [
        "# Find the most similar docs tn = 40"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJOS7VAImqiz"
      },
      "source": [
        "\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "\n",
        "top_k = min(1000, len(allPositiveReviews))\n",
        "dfTopic40 = pd.read_csv(csvTopic40)\n",
        "print(dfTopic40.shape)\n",
        "dfTopic40 = dfTopic40.dropna()\n",
        "dfSimTopic40 = pd.DataFrame()\n",
        "keywordsTopic40 = []\n",
        "\n",
        "keywordsTopic40 = dfTopic40['Keywords']\n",
        "\n",
        "dfSimTopicPos = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorPos = np.zeros(768)\n",
        "\n",
        "dfSimTopicNeg = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorNeg = np.zeros(768)\n",
        "\n",
        "\n",
        "\n",
        "for item in keywordsTopic40 :\n",
        "  item = item.replace('[','')\n",
        "  item = item.replace(']','')\n",
        "  item = item.replace(\"'\",'')\n",
        "  item = item.replace(\",\",'')\n",
        "  inferred_docvecPos = positiveModel.encode(item, convert_to_numpy=True)\n",
        "  inferred_docvecNeg = negativeModel.encode(item, convert_to_numpy=True)\n",
        "\n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecPos, positiveEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicPos = dfSimTopicPos.append({\"docid\": idx, \"SimilarityScore\": score, \"Text\":allPositiveReviews[idx]}, ignore_index = True)\n",
        "\n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecNeg, negativeEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicNeg = dfSimTopicNeg.append({\"docid\": idx + 283300, \"SimilarityScore\": score, \"Text\":allNegativeReviews[idx]}, ignore_index = True)\n",
        "\n",
        "\n",
        "  #end of for\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Number of unique Positive documents\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "dfSimTopicNeg.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "\n",
        "print(\"Number of unique Positive documents after droping duplicates\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents after droping duplicates\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "#Sampling 1000 positive and 1000 negatives\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos = dfSimTopicPos.iloc[0:1000, :]\n",
        "dfSimTopicNeg = dfSimTopicNeg.iloc[0:1000, :]\n",
        "\n",
        "#end Sampling 1000 positive and 1000 negatives\n",
        "\n",
        "\n",
        "print(\"Max Positive:\" , max(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Max Negatives:\" , max(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Min Positive:\" , min(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Min Negatives:\" , min(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Mean Positive:\", dfSimTopicPos[\"SimilarityScore\"].mean())\n",
        "print(\"Mean Positive:\", dfSimTopicNeg[\"SimilarityScore\"].mean())\n",
        "\n",
        "print(\"Std Positive:\",dfSimTopicPos[\"SimilarityScore\"].std())\n",
        "print(\"Std Negative:\",dfSimTopicNeg[\"SimilarityScore\"].std())\n",
        "\n",
        "\n",
        "print(\"len Positive:\" , len(dfSimTopicPos))\n",
        "print(\"len Negatives:\" , len(dfSimTopicNeg))\n",
        "\n",
        "dfAll40 = dfSimTopicNeg.append(dfSimTopicPos)\n",
        "dfAll40.to_csv(csvTopic40MostSimilar, header=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDAPVn0mFWWU"
      },
      "source": [
        "# Find the most similar docs tn = 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7aDWFX-nB3f"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "\n",
        "top_k = min(1000, len(allPositiveReviews))\n",
        "\n",
        "dfTopic50 = pd.read_csv(csvTopic50)\n",
        "print(dfTopic50.shape)\n",
        "dfTopic50 = dfTopic50.dropna()\n",
        "dfSimTopic50 = pd.DataFrame()\n",
        "keywordsTopic50 = []\n",
        "\n",
        "keywordsTopic50 = dfTopic50['Keywords']\n",
        "\n",
        "dfSimTopicPos = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorPos = np.zeros(768)\n",
        "\n",
        "dfSimTopicNeg = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorNeg = np.zeros(768)\n",
        "\n",
        "\n",
        "\n",
        "for item in keywordsTopic50 :\n",
        "  item = item.replace('[','')\n",
        "  item = item.replace(']','')\n",
        "  item = item.replace(\"'\",'')\n",
        "  item = item.replace(\",\",'')\n",
        "  inferred_docvecPos = positiveModel.encode(item, convert_to_numpy=True)\n",
        "  inferred_docvecNeg = negativeModel.encode(item, convert_to_numpy=True)\n",
        "\n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecPos, positiveEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicPos = dfSimTopicPos.append({\"docid\": idx, \"SimilarityScore\": score, \"Text\":allPositiveReviews[idx]}, ignore_index = True)\n",
        "\n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecNeg, negativeEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicNeg = dfSimTopicNeg.append({\"docid\": idx + 283300, \"SimilarityScore\": score, \"Text\":allNegativeReviews[idx]}, ignore_index = True)\n",
        "\n",
        "  #end of for\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Number of unique Positive documents\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "dfSimTopicNeg.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "\n",
        "print(\"Number of unique Positive documents after droping duplicates\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents after droping duplicates\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "#Sampling 1000 positive and 1000 negatives\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos = dfSimTopicPos.iloc[0:1000, :]\n",
        "dfSimTopicNeg = dfSimTopicNeg.iloc[0:1000, :]\n",
        "\n",
        "#end Sampling 1000 positive and 1000 negatives\n",
        "\n",
        "\n",
        "print(\"Max Positive:\" , max(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Max Negatives:\" , max(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Min Positive:\" , min(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Min Negatives:\" , min(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Mean Positive:\", dfSimTopicPos[\"SimilarityScore\"].mean())\n",
        "print(\"Mean Positive:\", dfSimTopicNeg[\"SimilarityScore\"].mean())\n",
        "\n",
        "print(\"Std Positive:\",dfSimTopicPos[\"SimilarityScore\"].std())\n",
        "print(\"Std Negative:\",dfSimTopicNeg[\"SimilarityScore\"].std())\n",
        "\n",
        "\n",
        "print(\"len Positive:\" , len(dfSimTopicPos))\n",
        "print(\"len Negatives:\" , len(dfSimTopicNeg))\n",
        "\n",
        "dfAll50 = dfSimTopicNeg.append(dfSimTopicPos)\n",
        "dfAll50.to_csv(csvTopic50MostSimilar, header=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9oj1SUTFYWm"
      },
      "source": [
        "# Find the most similar docs tn = 60"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3ktIBbvpYu7"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "\n",
        "top_k = min(1000, len(allPositiveReviews))\n",
        "\n",
        "\n",
        "dfTopic60 = pd.read_csv(csvTopic60)\n",
        "print(dfTopic60.shape)\n",
        "dfTopic60 = dfTopic60.dropna()\n",
        "dfSimTopic60 = pd.DataFrame()\n",
        "keywordsTopic60 = []\n",
        "\n",
        "keywordsTopic60 = dfTopic60['Keywords']\n",
        "\n",
        "dfSimTopicPos = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorPos = np.zeros(768)\n",
        "\n",
        "dfSimTopicNeg = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorNeg = np.zeros(768)\n",
        "\n",
        "\n",
        "\n",
        "for item in keywordsTopic60 :\n",
        "  item = item.replace('[','')\n",
        "  item = item.replace(']','')\n",
        "  item = item.replace(\"'\",'')\n",
        "  item = item.replace(\",\",'')\n",
        "  inferred_docvecPos = positiveModel.encode(item, convert_to_numpy=True)\n",
        "  inferred_docvecNeg = negativeModel.encode(item, convert_to_numpy=True)\n",
        "\n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecPos, positiveEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicPos = dfSimTopicPos.append({\"docid\": idx, \"SimilarityScore\": score, \"Text\":allPositiveReviews[idx]}, ignore_index = True)\n",
        "\n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecNeg, negativeEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicNeg = dfSimTopicNeg.append({\"docid\": idx + 283300, \"SimilarityScore\": score, \"Text\":allNegativeReviews[idx]}, ignore_index = True)\n",
        "\n",
        "\n",
        "\n",
        "  #end of for\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Number of unique Positive documents\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "dfSimTopicNeg.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "\n",
        "print(\"Number of unique Positive documents after droping duplicates\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents after droping duplicates\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "#Sampling 1000 positive and 1000 negatives\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos = dfSimTopicPos.iloc[0:1000, :]\n",
        "dfSimTopicNeg = dfSimTopicNeg.iloc[0:1000, :]\n",
        "\n",
        "#end Sampling 1000 positive and 1000 negatives\n",
        "\n",
        "\n",
        "print(\"Max Positive:\" , max(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Max Negatives:\" , max(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Min Positive:\" , min(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Min Negatives:\" , min(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Mean Positive:\", dfSimTopicPos[\"SimilarityScore\"].mean())\n",
        "print(\"Mean Positive:\", dfSimTopicNeg[\"SimilarityScore\"].mean())\n",
        "\n",
        "print(\"Std Positive:\",dfSimTopicPos[\"SimilarityScore\"].std())\n",
        "print(\"Std Negative:\",dfSimTopicNeg[\"SimilarityScore\"].std())\n",
        "\n",
        "\n",
        "print(\"len Positive:\" , len(dfSimTopicPos))\n",
        "print(\"len Negatives:\" , len(dfSimTopicNeg))\n",
        "\n",
        "dfAll60 = dfSimTopicNeg.append(dfSimTopicPos)\n",
        "dfAll60.to_csv(csvTopic60MostSimilar, header=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mye0KNDdFZm4"
      },
      "source": [
        "# Find the most similar docs tn = 65"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OM4bWg5aprEW"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "\n",
        "top_k = min(1000, len(allPositiveReviews))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "dfTopic65 = pd.read_csv(csvTopic65)\n",
        "print(dfTopic65.shape)\n",
        "dfTopic65 = dfTopic65.dropna()\n",
        "dfSimTopic65 = pd.DataFrame()\n",
        "keywordsTopic65 = []\n",
        "\n",
        "keywordsTopic65 = dfTopic65['Keywords']\n",
        "\n",
        "dfSimTopicPos = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorPos = np.zeros(768)\n",
        "\n",
        "dfSimTopicNeg = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorNeg = np.zeros(768)\n",
        "\n",
        "\n",
        "\n",
        "for item in keywordsTopic65 :\n",
        "  item = item.replace('[','')\n",
        "  item = item.replace(']','')\n",
        "  item = item.replace(\"'\",'')\n",
        "  item = item.replace(\",\",'')\n",
        "  inferred_docvecPos = positiveModel.encode(item, convert_to_numpy=True)\n",
        "  inferred_docvecNeg = negativeModel.encode(item, convert_to_numpy=True)\n",
        "\n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecPos, positiveEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicPos = dfSimTopicPos.append({\"docid\": idx, \"SimilarityScore\": score, \"Text\":allPositiveReviews[idx]}, ignore_index = True)\n",
        "\n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecNeg, negativeEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicNeg = dfSimTopicNeg.append({\"docid\": idx + 283300, \"SimilarityScore\": score, \"Text\":allNegativeReviews[idx]}, ignore_index = True)\n",
        "\n",
        "\n",
        "\n",
        "  #end of for\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Number of unique Positive documents\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "dfSimTopicNeg.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "\n",
        "print(\"Number of unique Positive documents after droping duplicates\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents after droping duplicates\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "#Sampling 1000 positive and 1000 negatives\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos = dfSimTopicPos.iloc[0:1000, :]\n",
        "dfSimTopicNeg = dfSimTopicNeg.iloc[0:1000, :]\n",
        "\n",
        "#end Sampling 1000 positive and 1000 negatives\n",
        "\n",
        "\n",
        "print(\"Max Positive:\" , max(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Max Negatives:\" , max(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Min Positive:\" , min(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Min Negatives:\" , min(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Mean Positive:\", dfSimTopicPos[\"SimilarityScore\"].mean())\n",
        "print(\"Mean Positive:\", dfSimTopicNeg[\"SimilarityScore\"].mean())\n",
        "\n",
        "print(\"Std Positive:\",dfSimTopicPos[\"SimilarityScore\"].std())\n",
        "print(\"Std Negative:\",dfSimTopicNeg[\"SimilarityScore\"].std())\n",
        "\n",
        "\n",
        "print(\"len Positive:\" , len(dfSimTopicPos))\n",
        "print(\"len Negatives:\" , len(dfSimTopicNeg))\n",
        "\n",
        "dfAll65 = dfSimTopicNeg.append(dfSimTopicPos)\n",
        "dfAll65.to_csv(csvTopic65MostSimilar, header=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RHcSo4-Fa_a"
      },
      "source": [
        "# Find the most similar docs tn = 70"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgopwngQqKuk"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "\n",
        "top_k = min(500, len(allPositiveReviews))\n",
        "\n",
        "dfTopic70 = pd.read_csv(csvTopic70)\n",
        "print(dfTopic70.shape)\n",
        "dfTopic70 = dfTopic70.dropna()\n",
        "dfSimTopic70 = pd.DataFrame()\n",
        "keywordsTopic70 = []\n",
        "\n",
        "keywordsTopic70 = dfTopic70['Keywords']\n",
        "\n",
        "dfSimTopicPos = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorPos = np.zeros(768)\n",
        "\n",
        "dfSimTopicNeg = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorNeg = np.zeros(768)\n",
        "\n",
        "\n",
        "\n",
        "for item in keywordsTopic70 :\n",
        "  item = item.replace('[','')\n",
        "  item = item.replace(']','')\n",
        "  item = item.replace(\"'\",'')\n",
        "  item = item.replace(\",\",'')\n",
        "  inferred_docvecPos = positiveModel.encode(item, convert_to_numpy=True)\n",
        "  inferred_docvecNeg = negativeModel.encode(item, convert_to_numpy=True)\n",
        "\n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecPos, positiveEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicPos = dfSimTopicPos.append({\"docid\": idx, \"SimilarityScore\": score, \"Text\":allPositiveReviews[idx]}, ignore_index = True)\n",
        "\n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecNeg, negativeEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicNeg = dfSimTopicNeg.append({\"docid\": idx + 283300, \"SimilarityScore\": score, \"Text\":allNegativeReviews[idx]}, ignore_index = True)\n",
        "\n",
        "\n",
        "\n",
        "  #end of for\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Number of unique Positive documents\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "dfSimTopicNeg.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "\n",
        "print(\"Number of unique Positive documents after droping duplicates\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents after droping duplicates\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "#Sampling 1000 positive and 1000 negatives\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos = dfSimTopicPos.iloc[0:1000, :]\n",
        "dfSimTopicNeg = dfSimTopicNeg.iloc[0:1000, :]\n",
        "\n",
        "#end Sampling 1000 positive and 1000 negatives\n",
        "\n",
        "\n",
        "print(\"Max Positive:\" , max(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Max Negatives:\" , max(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Min Positive:\" , min(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Min Negatives:\" , min(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Mean Positive:\", dfSimTopicPos[\"SimilarityScore\"].mean())\n",
        "print(\"Mean Positive:\", dfSimTopicNeg[\"SimilarityScore\"].mean())\n",
        "\n",
        "print(\"Std Positive:\",dfSimTopicPos[\"SimilarityScore\"].std())\n",
        "print(\"Std Negative:\",dfSimTopicNeg[\"SimilarityScore\"].std())\n",
        "\n",
        "\n",
        "print(\"len Positive:\" , len(dfSimTopicPos))\n",
        "print(\"len Negatives:\" , len(dfSimTopicNeg))\n",
        "\n",
        "dfAll70 = dfSimTopicNeg.append(dfSimTopicPos)\n",
        "dfAll70.to_csv(csvTopic70MostSimilar, header=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAWPmqdjFcjw"
      },
      "source": [
        "# Find the most similar docs tn = 80"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6Fvh6CmqjbE"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "\n",
        "top_k = min(500, len(allPositiveReviews))\n",
        "\n",
        "\n",
        "\n",
        "dfTopic80 = pd.read_csv(csvTopic80)\n",
        "print(dfTopic80.shape)\n",
        "dfTopic80 = dfTopic80.dropna()\n",
        "dfSimTopic80 = pd.DataFrame()\n",
        "keywordsTopic80 = []\n",
        "\n",
        "keywordsTopic80 = dfTopic80['Keywords']\n",
        "\n",
        "dfSimTopicPos = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorPos = np.zeros(768)\n",
        "\n",
        "dfSimTopicNeg = pd.DataFrame(columns=[\"docid\",\"SimilarityScore\"])\n",
        "totalVectorNeg = np.zeros(768)\n",
        "\n",
        "\n",
        "\n",
        "for item in keywordsTopic80 :\n",
        "  item = item.replace('[','')\n",
        "  item = item.replace(']','')\n",
        "  item = item.replace(\"'\",'')\n",
        "  item = item.replace(\",\",'')\n",
        "  inferred_docvecPos = positiveModel.encode(item, convert_to_numpy=True)\n",
        "  inferred_docvecNeg = negativeModel.encode(item, convert_to_numpy=True)\n",
        "\n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecPos, positiveEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicPos = dfSimTopicPos.append({\"docid\": idx, \"SimilarityScore\": score, \"Text\":allPositiveReviews[idx]}, ignore_index = True)\n",
        "\n",
        "\n",
        "  cos_scores = util.pytorch_cos_sim(inferred_docvecNeg, negativeEmbeddings)[0]\n",
        "  top_results = torch.topk(cos_scores, k=top_k)\n",
        "  for score, idx in zip(top_results[0], top_results[1]):\n",
        "    dfSimTopicNeg = dfSimTopicNeg.append({\"docid\": idx + 283300, \"SimilarityScore\": score, \"Text\":allNegativeReviews[idx]}, ignore_index = True)\n",
        "\n",
        "\n",
        "\n",
        "print(\"end of for\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Number of unique Positive documents\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "dfSimTopicNeg.drop_duplicates(subset=[\"docid\"], keep='first', inplace = True)\n",
        "\n",
        "print(\"Number of unique Positive documents after droping duplicates\", dfSimTopicPos[\"docid\"].nunique())\n",
        "print(\"Number of unique Negative documents after droping duplicates\", dfSimTopicNeg[\"docid\"].nunique())\n",
        "\n",
        "#Sampling 1000 positive and 1000 negatives\n",
        "dfSimTopicPos.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "dfSimTopicNeg.sort_values(by='SimilarityScore', ascending=False, inplace=True)\n",
        "\n",
        "dfSimTopicPos = dfSimTopicPos.iloc[0:1000, :]\n",
        "dfSimTopicNeg = dfSimTopicNeg.iloc[0:1000, :]\n",
        "\n",
        "#end Sampling 1000 positive and 1000 negatives\n",
        "\n",
        "\n",
        "print(\"Max Positive:\" , max(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Max Negatives:\" , max(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Min Positive:\" , min(dfSimTopicPos[\"SimilarityScore\"]))\n",
        "print(\"Min Negatives:\" , min(dfSimTopicNeg[\"SimilarityScore\"]))\n",
        "\n",
        "print(\"Mean Positive:\", dfSimTopicPos[\"SimilarityScore\"].mean())\n",
        "print(\"Mean Positive:\", dfSimTopicNeg[\"SimilarityScore\"].mean())\n",
        "\n",
        "print(\"Std Positive:\",dfSimTopicPos[\"SimilarityScore\"].std())\n",
        "print(\"Std Negative:\",dfSimTopicNeg[\"SimilarityScore\"].std())\n",
        "\n",
        "\n",
        "print(\"len Positive:\" , len(dfSimTopicPos))\n",
        "print(\"len Negatives:\" , len(dfSimTopicNeg))\n",
        "\n",
        "dfAll80 = dfSimTopicNeg.append(dfSimTopicPos)\n",
        "dfAll80.to_csv(csvTopic80MostSimilar, header=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bGC0gx3uTF3"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}